{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "# *                   _oo0oo_\n",
    "# *                  o8888888o\n",
    "# *                  88\" . \"88\n",
    "# *                  (| -_- |)\n",
    "# *                  0\\  =  /0\n",
    "# *                ___/`---'\\___\n",
    "# *              .' \\\\|     |// '.\n",
    "# *             / \\\\|||  :  |||// \\\n",
    "# *            / _||||| -:- |||||- \\\n",
    "# *           |   | \\\\\\  -  /// |   |\n",
    "# *           | \\_|  ''\\---/''  |_/ |\n",
    "# *           \\  .-\\__  '-'  ___/-. /\n",
    "# *         ___'. .'  /--.--\\  `. .'___\n",
    "# *      .\"\" '<  `.___\\_<|>_/___.' >' \"\".\n",
    "# *     | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
    "# *     \\  \\ `_.   \\_ __\\ /__ _/   .-` /  /\n",
    "# * =====`-.____`.___ \\_____/___.-`___.-'=====\n",
    "# *                   `=---='\n",
    "# *\n",
    "# *\n",
    "# * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# *\n",
    "# *   Buddha blesses your code to be bug free\n",
    "# */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4071cf9f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7626e981",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from helpers import createDFFromFileAndSchema, clean_special_letters, clean_special_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed236bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae6ee91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Clean up the data and perform the queries').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb68a75d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://t-193.vc-graz.ac.at:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x113ad8130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062ec083",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMAS_FOLDER = './schemas/'\n",
    "FILES_FOLDER = './assets/parsedData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92dff5",
   "metadata": {},
   "source": [
    "# Load and clean Paper DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f871ce",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/papers.csv, schema path: ./schemas/paper.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n",
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|Direct file organ...|1984|\n",
      "|     130|An introduction t...|1983|\n",
      "|     195|On solving almost...|1984|\n",
      "|     260|Connections betwe...|1984|\n",
      "|     325|Computers and pen...|1984|\n",
      "|     390|Relativizations c...|1984|\n",
      "|     455|On the optimum ch...|1984|\n",
      "|     520|All points addres...|1984|\n",
      "|     585|Optimum Head Sepa...|1984|\n",
      "|     650|A parallel-design...|1984|\n",
      "|     715|Computer - IEEE C...|1984|\n",
      "|     780|Experience with G...|1984|\n",
      "|     845|Code generation a...|1984|\n",
      "|     910|On estimating acc...|1984|\n",
      "|     975|A distributed alt...|1985|\n",
      "|    1040|A comparison of t...|1984|\n",
      "|    1105|Generalizing spec...|1985|\n",
      "|    1170|Real time graphic...|1984|\n",
      "|    1235|Common and uncomm...|1984|\n",
      "|    1300|Foundations of co...|1985|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load paper csv into schema\n",
    "paper_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}papers.csv', f'{SCHEMAS_FOLDER}paper.csv')\n",
    "paper_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a7cc",
   "metadata": {},
   "source": [
    "### Data cleaning for paper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3054c0b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove spaces from values of the columns\n",
    "paper_df = paper_df.withColumn(\"title\", trim(paper_df.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285bb60f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check for the correct data types\n",
    "paper_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fc4cf2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_paper_df = paper_df.select(\n",
    "    [count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_df.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2652fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+\n",
      "|paper_id|title|year|\n",
      "+--------+-----+----+\n",
      "|       0|   24| 157|\n",
      "+--------+-----+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_values_paper_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbdfb814",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### after checking the below dataframes,\n",
    "### we have seen that all papers, whose title is missing, have the authors (besides paper_id = 748056)\n",
    "### Decision: fill missing titles with: \"Missing Title\"\n",
    "\n",
    "paper_df=paper_df.na.fill('Missing Title', ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f62d8e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "paper_df=clean_special_character(paper_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b78e5ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+-------------------+\n",
      "|paper_id|               title|year|Duplicate_indicator|\n",
      "+--------+--------------------+----+-------------------+\n",
      "|       3|The verification ...|1984|                  0|\n",
      "|       5|Entityrelationshi...|1984|                  0|\n",
      "|      22|On two more Eigen...|1984|                  0|\n",
      "|      27|Frame theory and ...|1984|                  0|\n",
      "|      41|ELSA  an extensib...|1983|                  0|\n",
      "|      44|ADA Concurrent Pr...|1984|                  0|\n",
      "|      52|Automated microco...|1984|                  0|\n",
      "|      58|The application o...|1983|                  0|\n",
      "|      61|The DISS methodol...|1984|                  0|\n",
      "|      66|Soft evaluation o...|1984|                  0|\n",
      "|      77|The influence of ...|1984|                  0|\n",
      "|      80|Smalltalk80 bits ...|1983|                  0|\n",
      "|      91|Design of optimal...|1982|                  0|\n",
      "|     103|Smalltalk80 the l...|1983|                  0|\n",
      "|     107|Deterministic pro...|1984|                  0|\n",
      "|     113|From logic to com...|1983|                  0|\n",
      "|     114|A first course in...|1983|                  0|\n",
      "|     126|Evaluation of ari...|1983|                  0|\n",
      "|     134|       MATRIX PASCAL|1983|                  0|\n",
      "|     139|    Programming in C|1983|                  0|\n",
      "+--------+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|paper_id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate rows\n",
    "paper_df.join(\n",
    "    paper_df\n",
    "        .groupBy(paper_df.columns) \\\n",
    "        .agg((F.count(\"*\")>1) \\\n",
    "        .cast(\"int\") \\\n",
    "        .alias(\"Duplicate_indicator\")), \\\n",
    "        on=paper_df.columns,how=\"inner\") \\\n",
    "    .show()\n",
    "### from the dataframe view, we can see that there are no duplicates\n",
    "paper_df.groupby(['paper_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b03384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092356"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check for the number of paper entries\n",
    "paper_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f7c3d",
   "metadata": {},
   "source": [
    "# Load and clean paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82641fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load paper_authors csv into schema\n",
    "paper_author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}paper_authors.csv', f'{SCHEMAS_FOLDER}paper_authors.csv')\n",
    "paper_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba688b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "paper_author_df = paper_author_df.withColumn(\"authors\", trim(paper_author_df.authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### verify schema\n",
    "paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special letters\n",
    "paper_author_df=clean_special_letters(paper_author_df, 'authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DELETE - ?\n",
    "### check if authors are missing as well for the ids whose title was missing in paper_df\n",
    "### for rows in paper_author_df.select(\"authors\",\"paper_id\").collect():\n",
    "###    if rows[1] in null_paper_ids_list:\n",
    "###        print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split authors so we can have clean data and separate records { paper_id; author }\n",
    "unique_paper_author_df = paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"authors\"),\";\")).alias(\"author\"))\n",
    "\n",
    "unique_paper_author_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72771502",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"author\", trim(unique_paper_author_df.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9143e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_paper_author_df=clean_special_character(unique_paper_author_df, 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', lower(col('author')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_paper_author_df \\\n",
    "    .groupby(['paper_id', 'author']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()\n",
    "\n",
    "### drop duplicate rows since here we need unique paper-author relation\n",
    "unique_paper_author_df = unique_paper_author_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split author-name so we keep only the surname\n",
    "### This decision was made because there are a lot of disrepancies in full names,\n",
    "### and later on we need the clean and nice surnames for correct joining of the tables by paper_id + surname.\n",
    "unique_paper_author_cleaned_df = unique_paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.trim(F.element_at (F.split(F.col(\"author\"),\" \"),-1)).alias('name'))\n",
    "\n",
    "unique_paper_author_cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check how many entries there are in unique_paper_author_cleaned_df\n",
    "unique_paper_author_cleaned_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af545918",
   "metadata": {},
   "source": [
    "# Clean and Load Authors df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8661121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load author csv into schema\n",
    "author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}authors.csv', f'{SCHEMAS_FOLDER}author.csv')\n",
    "author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove spaces from values of the column\n",
    "author_df = author_df.withColumn(\"name\", trim(author_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8eff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for nonsense null data (filtering will be done later)\n",
    "null_values_author_df = author_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns])\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e750c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill empty paper_count, citation_count, h_index to 0 (just one author)\n",
    "author_df=author_df.na.fill(value=0, subset='paper_count')\n",
    "author_df=author_df.na.fill(value=0, subset='citation_count')\n",
    "author_df=author_df.na.fill(value=0, subset='h_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters like í, â, é\n",
    "author_df=clean_special_letters(author_df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf02fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "author_df=clean_special_character(author_df,'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "author_df=author_df.withColumn('name', lower(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if there are duplicate author_ids\n",
    "author_df.groupby(['author_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145eb93",
   "metadata": {},
   "source": [
    "# Join author and paper dataframes to ensure consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4d547",
   "metadata": {},
   "source": [
    "Load and clean Author2Paper (from the supplement txt file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16366740",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load paper_author_id csv into schema\n",
    "dtypes = pd.read_csv('./schemas/paper_author_id.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "author_id_2_paper_id_df = spark.read.options(delimiter='\\t').csv('./assets/AMiner-Author2Paper.txt', header=False,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check how many entries there are\n",
    "author_id_2_paper_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c69330",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for duplicates between paper_id and author_id\n",
    "author_id_2_paper_id_df \\\n",
    "    .groupby(['author_id', 'paper_id']) \\\n",
    "    .count().where('count > 1') \\\n",
    "    .sort('count', ascending=False).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84081c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the suplementary author_id_2_paper_id_df df with author_df\n",
    "author_id_2_paper_id_extended_df = author_id_2_paper_id_df.join(author_df, 'author_id', 'left').drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the author-name to keep only the surname ---> cleaning data\n",
    "author_id_2_paper_id_cleaned_df = author_id_2_paper_id_extended_df \\\n",
    "    .select( \\\n",
    "        F.col(\"paper_id\"), \\\n",
    "        F.col(\"author_id\"), \\\n",
    "        F.col(\"citation_count\"), \\\n",
    "        F.col(\"h_index\"), \\\n",
    "        F.col(\"paper_count\"), \\\n",
    "        F.trim(F.element_at(F.split(F.col(\"name\"),\" \"),-1)).alias('name') \\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the cleaned paper_2_author_cleaned_df to unique_paper_author_cleaned_df\n",
    "final_paper_author_id_df = unique_paper_author_cleaned_df \\\n",
    "    .join(author_id_2_paper_id_cleaned_df, ['name', 'paper_id'], 'inner') \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37905ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check how many entries there are in the final dataframe\n",
    "final_paper_author_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_paper_author_id_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7b6c",
   "metadata": {},
   "source": [
    "# Load and clean Affiliations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d4c21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### load affiliation csv into schema\n",
    "affiliation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}affiliations.csv', f'{SCHEMAS_FOLDER}affiliation.csv')\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab85ad4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "affiliation_df = affiliation_df.withColumn(\"affiliations\", trim(affiliation_df.affiliations))\n",
    "\n",
    "affiliation_df.printSchema()\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1159c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values in the affiliations column\n",
    "### we can see, that there are many rows with null affiliations\n",
    "### these rows will be cleaned up further\n",
    "null_values_affiliations=affiliation_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in affiliation_df.columns])\n",
    "print(null_values_affiliations.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5fdc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### This df will in the end be used to count papers per unique affiliation,\n",
    "### so if the affiliation is missing, it doesnt make sense to keep the row\n",
    "### Decision: drop all rows where affiliation is null\n",
    "affiliation_df=affiliation_df.na.drop(how=\"any\", subset=['affiliations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8504dda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split affiliations so we can have clean data and separate records { paper_id; affiliation }\n",
    "unique_affiliations_df = affiliation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"affiliations\"),\";\")) \\\n",
    "    .alias(\"affiliation\"))\n",
    "unique_affiliations_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195d7d4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for special nonsense characters \"-\" and filter them out\n",
    "### If the affiliation is missing, there is no point of keeping the rows\n",
    "unique_affiliations_df = unique_affiliations_df.where(unique_affiliations_df.affiliation != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3c444",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62eeaed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df \\\n",
    "    .groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbf49b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique affiliations\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55ad40",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_affiliations_df = clean_special_character(unique_affiliations_df, 'affiliation')\n",
    "### remove special letters\n",
    "unique_affiliations_df = clean_special_letters(unique_affiliations_df, 'affiliation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase the affiliation col values\n",
    "unique_affiliations_df = unique_affiliations_df.withColumn('affiliation', lower(col('affiliation')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d2b75",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df.groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855886fd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0083171",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### filter out affiliations that are not part of the final_paper_author_id_df\n",
    "final_affiliations_df = unique_affiliations_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('affiliation')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1855220",
   "metadata": {},
   "source": [
    "# Load and clean Publication_venues df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25f590",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### load publication_venues into schema\n",
    "publication_venue_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}publication_venues.csv', f'{SCHEMAS_FOLDER}publication_venues.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026166d7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### trim publication_venue\n",
    "publication_venue_df = publication_venue_df.withColumn( \\\n",
    "    \"publication_venue\", trim(publication_venue_df.publication_venue) \\\n",
    ")\n",
    "publication_venue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa39b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values inside publication venues dataframe\n",
    "null_values_publication_venue = publication_venue_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in publication_venue_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_publication_venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3dd2b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop null values \n",
    "publication_venue_df=publication_venue_df.na.drop(how=\"any\", subset=['publication_venue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0c6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "publication_venue_df \\\n",
    "    .groupby(['paper_id', 'publication_venue']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ddef7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### join publication_venue_df with final_paper_author_id_df\n",
    "### to remove publication venues of paper ids which are not part of final_paper_author_id_df\n",
    "final_publication_venues_df = publication_venue_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('publication_venue')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6ec60",
   "metadata": {},
   "source": [
    "# Load and clean Citations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24ec61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### load affiliation csv into schema\n",
    "citation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}citations.csv', f'{SCHEMAS_FOLDER}citations.csv')\n",
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f0ac2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "citation_df = citation_df.withColumn(\"ref_ids\", trim(citation_df.ref_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30286e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show how many paper ids are present in citation_df\n",
    "citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe6f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "citation_df.groupby(['paper_id', 'ref_ids']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c54e1c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split citations so we can have clean data and seperate records {paper_id; ref_id}\n",
    "unique_citation_df = citation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode_outer(F.split(F.col(\"ref_ids\"),\";\")).alias(\"ref_id\"))\n",
    "unique_citation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691822fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the number of unique papers in unique_citation_df dataframe\n",
    "unique_citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d01f0e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\", trim(unique_citation_df.ref_id))\n",
    "### change data type of ref_id to Integer\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\",unique_citation_df[\"ref_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb73e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_citation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89c12f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_citation_df.groupby(['paper_id', 'ref_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da1d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check whether some papers have null ref_ids\n",
    "### (those papers will still be kept in the dataframe for consistency)\n",
    "unique_citation_df.filter(unique_citation_df['ref_id'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207d516",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### clean up ref ids if their paper_id is not a part of final_paper_author_id_df\n",
    "final_citation_df = unique_citation_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('ref_id')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066b305",
   "metadata": {},
   "source": [
    "# Load and Research_interests in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c387e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### load research_interests csv into schema\n",
    "research_interests_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}research_interests.csv', f'{SCHEMAS_FOLDER}research_interests.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ee220",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "research_interests_df = research_interests_df \\\n",
    "    .withColumn(\"research_interests\", trim(research_interests_df.research_interests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967513d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values in the affiliations column\n",
    "research_interests_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in research_interests_df.columns]).show()\n",
    "### drop null values (it is safe since we dont need research_interests for any computation)\n",
    "research_interests_df = research_interests_df.na.drop(how=\"any\", subset=['research_interests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4995ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_interests_df.printSchema()\n",
    "research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf3d09",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split research interests\n",
    "### so we can have clean data and separate records { paper_id; research_interest }\n",
    "unique_research_interests_df = research_interests_df \\\n",
    "    .select(F.col(\"author_id\"), F.explode(F.split(F.col(\"research_interests\"),\";\")) \\\n",
    "    .alias(\"research_interest\"))\n",
    "\n",
    "unique_research_interests_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef0111",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn(\"research_interest\", trim(unique_research_interests_df.research_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacff62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### clean special characters and special letters\n",
    "unique_research_interests_df = clean_special_character(unique_research_interests_df, 'research_interest')\n",
    "unique_research_interests_df = clean_special_letters(unique_research_interests_df, 'research_interest')\n",
    "### lowercase research_interests\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn('research_interest', lower(col('research_interest')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ca185",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_research_interests_df \\\n",
    "    .groupby(['author_id', 'research_interest']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855bc9f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_research_interests_df=unique_research_interests_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ed493",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# clean up research interests if their author id is not a part of final_paper_author_id_df\n",
    "final_research_interests_df = unique_research_interests_df \\\n",
    "    .join(final_paper_author_id_df, ['author_id'], 'inner') \\\n",
    "    .select(F.col('author_id'), F.col('research_interest')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10818814",
   "metadata": {},
   "source": [
    "# Run Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36310d",
   "metadata": {},
   "source": [
    "### Q1.2 Compute paper count per unique affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3126d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "paper_count_per_affiliation_df = final_affiliations_df \\\n",
    "    .groupBy('affiliation') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"papers_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ce4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### count the number of results\n",
    "paper_count_per_affiliation_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041807a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_count_per_affiliation_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc2f1",
   "metadata": {},
   "source": [
    "### Q1.1 Validate precomputed paper counts, citation (ref) counts and h-indexes (per author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb36be",
   "metadata": {},
   "source": [
    "#### How to compute h-index for a specific author\n",
    "1. Retrieve all publications of the author\n",
    "2. Calculate the number of references per publication\n",
    "3. Sort the results in descending order\n",
    "4. Find a threshold N, where N top publications have at least N references each. N is the h-index of the author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4fe33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 1-2 Calculate the number of references per publication\n",
    "refs_per_paper_count_df = final_citation_df \\\n",
    "    .groupBy(\"paper_id\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\",\"paper_references\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_per_paper_count_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2dc42a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### 3 Join [papers per author] with [references per paper] and sort the results in descending order\n",
    "author_papers_with_ref_count = final_paper_author_id_df.join(refs_per_paper_count_df, 'paper_id') \\\n",
    "    .sort(col(\"paper_references\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_papers_with_ref_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a90c3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### add index column to table to ease h-index calculation\n",
    "window = Window.partitionBy(author_papers_with_ref_count['author_id']) \\\n",
    "    .orderBy(desc(\"paper_references\"), desc(\"paper_id\"))\n",
    "\n",
    "indexed_grouped_papers_df = author_papers_with_ref_count.select('*', rank().over(window).alias('index'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670dbb5c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_papers = indexed_grouped_papers_df \\\n",
    "    .withColumn(\"possible_h_index\", \\\n",
    "                when( \\\n",
    "                    indexed_grouped_papers_df.index <= indexed_grouped_papers_df.paper_references, \\\n",
    "                    indexed_grouped_papers_df.index \\\n",
    "                    ).otherwise(0) \\\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_indexed_papers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8143a56",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_grouped_by_author_papers_df = h_indexed_papers.groupBy('author_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa8f6e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_aggregated_papers_df = h_indexed_grouped_by_author_papers_df.agg( \\\n",
    "        F.count(\"paper_id\").alias(\"validated_paper_count\"),\n",
    "        F.sum(\"paper_references\").alias(\"validated_citation_count\"),\n",
    "        F.max(\"possible_h_index\").alias(\"validated_h_index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5123f",
   "metadata": {},
   "source": [
    "#### Computed results for `validated_paper_count`, `validated_paper_count` and `validated_h_index`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b40ed9",
   "metadata": {},
   "source": [
    "__Final resulting dataframe is unique_authors_with_validated_cols_df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join the computation results with author dataframe\n",
    "### to be able to compare received values with the precomputed values\n",
    "unique_authors_with_validated_cols_df = h_indexed_aggregated_papers_df.join(author_df, 'author_id', 'inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61de01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### count the number of entries\n",
    "unique_authors_with_validated_cols_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_with_validated_cols_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac42142",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed h-indexes differ from the validated h-indexes\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_h_index\"] != unique_authors_with_validated_cols_df[\"h_index\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed author citation counts differ from the validated citation counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_citation_count\"] != unique_authors_with_validated_cols_df[\"citation_count\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed author paper counts differ from the validated paper counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_paper_count\"] != unique_authors_with_validated_cols_df[\"paper_count\"]\n",
    "unique_authors_with_validated_cols_df.filter(filter_condition).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a64b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06577cfd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Save cleaned & computed data into the csv files (for T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a89293",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DATA_FOLDER = './assets/cleanedDFsData/'\n",
    "def saveDFIntoCSVFolder(df, folderName, pathToFolder):\n",
    "    # Save data to csv file\n",
    "    df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(f'{CLEAN_DATA_FOLDER}{folderName}')\n",
    "def moveFileToCorrectFolder(folderName, pathToFolder):\n",
    "    filename = glob.glob(f'{CLEAN_DATA_FOLDER}{folderName}/*.csv')[0]\n",
    "    shutil.move(filename, f'{CLEAN_DATA_FOLDER}{folderName}_ds.csv')\n",
    "    \n",
    "# After saving of the data to csv we have to call moveFileToCorrectFolder,\n",
    "# because saveDFIntoCSVFolder actually saves the data into the folder with a csv file inside.\n",
    "# moveFileToCorrectFolder moves the file to the correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d402cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving cleaned & unique paper author data\n",
    "saveDFIntoCSVFolder(final_paper_author_id_df, 'paper_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('paper_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cleaned & unique affiliations data with computed paper_count\n",
    "saveDFIntoCSVFolder(final_affiliations_df, 'affiliations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d41ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('affiliations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbe0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cleaned & unique publication venues data \n",
    "saveDFIntoCSVFolder(final_publication_venues_df, 'publication_venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('publication_venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cleaned & computed & research interests data\n",
    "saveDFIntoCSVFolder(final_research_interests_df, 'research_interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('research_interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad745a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "saveDFIntoCSVFolder(paper_df, 'papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2c964fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11c328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
