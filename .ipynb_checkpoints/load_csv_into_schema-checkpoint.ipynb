{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4071cf9f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7626e981",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#FixMe: some imports are doubled, we have to check and fix them\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from helpers import createDFFromFileAndSchema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae6ee91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('read data through spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb68a75d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x110e39130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca129df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMAS_FOLDER = './schemas/'\n",
    "FILES_FOLDER = './assets/parsedData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92dff5",
   "metadata": {},
   "source": [
    "# Load and clean Paper DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f871ce",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/papers.csv, schema path: ./schemas/paper.csv\n",
      "[('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n",
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|Direct file organ...|1984|\n",
      "|     130|An introduction t...|1983|\n",
      "|     195|On solving almost...|1984|\n",
      "|     260|Connections betwe...|1984|\n",
      "|     325|Computers and pen...|1984|\n",
      "|     390|Relativizations c...|1984|\n",
      "|     455|On the optimum ch...|1984|\n",
      "|     520|All points addres...|1984|\n",
      "|     585|Optimum Head Sepa...|1984|\n",
      "|     650|A parallel-design...|1984|\n",
      "|     715|Computer - IEEE C...|1984|\n",
      "|     780|Experience with G...|1984|\n",
      "|     845|Code generation a...|1984|\n",
      "|     910|On estimating acc...|1984|\n",
      "|     975|A distributed alt...|1985|\n",
      "|    1040|A comparison of t...|1984|\n",
      "|    1105|Generalizing spec...|1985|\n",
      "|    1170|Real time graphic...|1984|\n",
      "|    1235|Common and uncomm...|1984|\n",
      "|    1300|Foundations of co...|1985|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load paper into schema\n",
    "paper_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}papers.csv', f'{SCHEMAS_FOLDER}paper.csv')\n",
    "paper_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/paper.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# paper_df = spark.read.option('header', 'true').csv('./assets/parsedData/papers.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6715de",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paper_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054c0b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### data cleaning for paper schema\n",
    "\n",
    "### remove spaces from values of the columns\n",
    "paper_df = paper_df.withColumn(\"paper_id\", trim(paper_df.paper_id))\n",
    "paper_df = paper_df.withColumn(\"title\", trim(paper_df.title))\n",
    "paper_df = paper_df.withColumn(\"year\", trim(paper_df.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285bb60f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for the data types\n",
    "paper_df.printSchema()\n",
    "### change the data type of year to Integer\n",
    "paper_df = paper_df.withColumn(\"year\",paper_df[\"year\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc4cf2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_paper_df = paper_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_df.columns]\n",
    "   )\n",
    "### save the ids of papers whose title is missing to clean up the other dataframes\n",
    "null_paper_ids = paper_df.filter(paper_df['title'].isNull())\n",
    "null_paper_ids_list=null_paper_ids.select('paper_id').rdd.flatMap(lambda x: x).collect()\n",
    "null_paper_ids_list = [int(item) for item in null_paper_ids_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfb814",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### after checking the below dataframes, all papers whose title is missing have the authors besides paper_id = 748056\n",
    "### decision: fill missing titles with : Missing Title\n",
    "\n",
    "paper_df=paper_df.na.fill('Missing Title', ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f62d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\"', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', ';', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', ':', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\}', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\{', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\~', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\{', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\{', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0f49a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "paper_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78e5ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check if there are duplicate rows\n",
    "paper_df.join(paper_df.groupBy(paper_df.columns).agg((F.count(\"*\")>1).cast(\"int\").alias(\"Duplicate_indicator\")),\n",
    "on=paper_df.columns,how=\"inner\").show()\n",
    "###there are no duplicates\n",
    "paper_df.groupby(['paper_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50d456",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# paper_df.filter(unique_paper_author_df['title'].like(\"%%\")).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7b6c",
   "metadata": {},
   "source": [
    "# Load and clean Affiliations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a7d4c21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/affiliations.csv, schema path: ./schemas/affiliation.csv\n",
      "[('affiliations', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation into schema\n",
    "\n",
    "affiliation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}affiliations.csv', f'{SCHEMAS_FOLDER}affiliation.csv')\n",
    "affiliation_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/affiliation.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# affiliation_df = spark.read.option('header', 'true').csv('./assets/parsedData/affiliations.csv', header=True, schema=schema)\n",
    "# affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab85ad4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "affiliation_df = affiliation_df.withColumn(\"affiliations\", trim(affiliation_df.affiliations))\n",
    "affiliation_df = affiliation_df.withColumn(\"paper_id\", trim(affiliation_df.paper_id))\n",
    "affiliation_df = affiliation_df.withColumn(\"paper_id\",affiliation_df[\"paper_id\"].cast(IntegerType()))\n",
    "\n",
    "affiliation_df.printSchema()\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1159c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values in the affiliations column\n",
    "null_values_affiliations=affiliation_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in affiliation_df.columns]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5fdc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### This df is used to count papers per unique affiliation, so if the affiliation is missing, it doesnt make sense\n",
    "### drop all rows where affiliation is null\n",
    "\n",
    "affiliation_df=affiliation_df.na.drop(how=\"any\", subset=['affiliations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1018dd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "affiliation_df.filter(affiliation_df.affiliations.contains('-')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a272c4e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ### check if affiliations are missing as well for the ids whose title was missing in paper_df\n",
    "# for rows in affiliation_df.select(\"affiliations\",\"paper_id\").collect():\n",
    "#     if rows[1] in null_paper_ids_list:\n",
    "#         print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8504dda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split affiliations so we can have clean data and seperate records {paper_id; affiliations}\n",
    "unique_affiliations_df = affiliation_df.select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"affiliations\"),\";\")).alias(\"affiliation\"))\n",
    "unique_affiliations_df.show(20, False)\n",
    "affiliation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195d7d4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for special nonsense characters \"-\", If the affiliation is missing, there is no point of keeping the rows\n",
    "###unique_affiliations_df.filter(unique_affiliations_df.affiliations=='-').collect()\n",
    "unique_affiliations_df=unique_affiliations_df.where(unique_affiliations_df.affiliation!='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3c444",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62eeaed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_affiliations_df.groupby(['paper_id', 'affiliation']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbf49b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique affiliations\n",
    "unique_affiliations_df=unique_affiliations_df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d2b75",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855886fd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0083171",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d6238",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a05c0c",
   "metadata": {},
   "source": [
    "# Load and clean paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a52ef00",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/paper_authors.csv, schema path: ./schemas/paper_authors.csv\n",
      "[('authors', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|             authors|paper_id|\n",
      "+--------------------+--------+\n",
      "| K Devine;F J. Smith|      65|\n",
      "|J Wolff von Guden...|     130|\n",
      "|J. K. Reid;A. Jen...|     195|\n",
      "|William G. Golson...|     260|\n",
      "|    Stein Schjolberg|     325|\n",
      "|W Ian Gasarch;Ste...|     390|\n",
      "|Sam Toueg;Özalp B...|     455|\n",
      "|Frederick H. Dill...|     520|\n",
      "|A. R. Calderbank;...|     585|\n",
      "|         Uzi Vishkin|     650|\n",
      "|      Stephen S. Yau|     715|\n",
      "|Michael D. Schroe...|     780|\n",
      "|         S L. Graham|     845|\n",
      "|D Maio;M R. Scala...|     910|\n",
      "|         Pamela Zave|     975|\n",
      "|G. Salton;E. Voor...|    1040|\n",
      "|Douglas D. Dunlop...|    1105|\n",
      "|Patrick Peruch;Vi...|    1170|\n",
      "| Robert J. Sternberg|    1235|\n",
      "|Curtis Roads;John...|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load paper_authors into schema\n",
    "paper_author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}paper_authors.csv', f'{SCHEMAS_FOLDER}paper_authors.csv')\n",
    "paper_author_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/paper_authors.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# paper_author_df = spark.read.option('header', 'true').csv('./assets/parsedData/paper_authors.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47851ec9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "paper_author_df = paper_author_df.withColumn(\"authors\", trim(paper_author_df.authors))\n",
    "paper_author_df = paper_author_df.withColumn(\"paper_id\", trim(paper_author_df.paper_id))\n",
    "\n",
    "### change data type for paper_id to Integer\n",
    "paper_author_df = paper_author_df.withColumn(\"paper_id\",paper_author_df[\"paper_id\"].cast(IntegerType()))\n",
    "\n",
    "paper_author_df.show()\n",
    "paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special letters\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'íîìïīį', 'i'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÎÏÍĪĮÌ', 'I'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'àáâäæãåā', 'a'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÀÁÂÄÆÃÅĀ', 'A'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'èéêëēėę', 'e'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÈÉÊËĒĖĘ', 'E'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ûüùúū', 'u'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÛÜÙÚŪ', 'U'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÔÖÒÓŒØŌÕ', 'O'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'Ÿ', 'Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221572c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "null_values_paper_authors=paper_author_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_author_df.columns]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef567a85",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check if authors are missing as well for the ids whose title was missing in paper_df\n",
    "###for rows in paper_author_df.select(\"authors\",\"paper_id\").collect():\n",
    "###    if rows[1] in null_paper_ids_list:\n",
    "###        print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55522a82",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split authors so we can have clean data and seperate records {paper_id; author}\n",
    "unique_paper_author_df = paper_author_df.select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"authors\"),\";\")).alias(\"author\"))\n",
    "unique_paper_author_df.show(20, False)\n",
    "paper_author_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15561fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"author\", trim(unique_paper_author_df.author))\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"paper_id\", trim(unique_paper_author_df.paper_id))\n",
    "### change data type for paper_id to Integer\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"paper_id\",unique_paper_author_df[\"paper_id\"].cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\"', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', ';', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', ':', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\}', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\{', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\~', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\{', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\{', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d03e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7140f1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_paper_author_df.groupby(['paper_id', 'author']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2a640",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique paper-author relation\n",
    "unique_paper_author_df=unique_paper_author_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72777581",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_paper_author_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c7031",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d4afe",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab611b13",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b4f5d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1855220",
   "metadata": {},
   "source": [
    "# Load and clean Publication_venues df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d25f590",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/publication_venues.csv, schema path: ./schemas/publication_venues.csv\n",
      "[('paper_id', 'Integer'), ('publication_venue', 'String')]\n",
      "+--------+--------------------+\n",
      "|paper_id|   publication_venue|\n",
      "+--------+--------------------+\n",
      "|      65|Information Techn...|\n",
      "|     130|Proc. of the symp...|\n",
      "|     195|ACM Transactions ...|\n",
      "|     260|Information and C...|\n",
      "|     325|Computers and pen...|\n",
      "|     390|Information and C...|\n",
      "|     455|SIAM Journal on C...|\n",
      "|     520|IBM Journal of Re...|\n",
      "|     585|Journal of the AC...|\n",
      "|     650|Theoretical Compu...|\n",
      "|     715|            Computer|\n",
      "|     780|ACM Transactions ...|\n",
      "|     845|Methods and tools...|\n",
      "|     910|Information Proce...|\n",
      "|     975|ACM Transactions ...|\n",
      "|    1040|Information Proce...|\n",
      "|    1105|ACM Transactions ...|\n",
      "|    1170|Proc. of the 2nd ...|\n",
      "|    1235|Proc. of the inte...|\n",
      "|    1300|Foundations of co...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load publication_venues into schema\n",
    "\n",
    "publication_venue_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}publication_venues.csv', f'{SCHEMAS_FOLDER}publication_venues.csv')\n",
    "publication_venue_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/publication_venues.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# publication_venue_df = spark.read.option('header', 'true').csv('./assets/parsedData/publication_venues.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026166d7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "publication_venue_df = publication_venue_df.withColumn(\"publication_venue\", trim(publication_venue_df.publication_venue))\n",
    "publication_venue_df = publication_venue_df.withColumn(\"paper_id\", trim(publication_venue_df.paper_id))\n",
    "publication_venue_df = publication_venue_df.withColumn(\"paper_id\",publication_venue_df[\"paper_id\"].cast(IntegerType()))\n",
    "publication_venue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa39b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "null_values_publication_venue=publication_venue_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in publication_venue_df.columns]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3dd2b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "publication_venue_df.filter(publication_venue_df['publication_venue'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0c6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a6ec60",
   "metadata": {},
   "source": [
    "# Load and clean Citations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d24ec61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/citations.csv, schema path: ./schemas/citations.csv\n",
      "[('paper_id', 'Integer'), ('ref_ids', 'String')]\n",
      "+--------+--------------------+\n",
      "|paper_id|             ref_ids|\n",
      "+--------+--------------------+\n",
      "|      65|                null|\n",
      "|     130|                null|\n",
      "|     195|317424;317425;317573|\n",
      "|     260|                null|\n",
      "|     325|                null|\n",
      "|     390|                null|\n",
      "|     455|                null|\n",
      "|     520|       318368;323493|\n",
      "|     585|                null|\n",
      "|     650|                null|\n",
      "|     715|                null|\n",
      "|     780|318420;319233;319...|\n",
      "|     845|                null|\n",
      "|     910|                null|\n",
      "|     975|67604;318882;3718...|\n",
      "|    1040|                null|\n",
      "|    1105|289087;318014;318...|\n",
      "|    1170|                null|\n",
      "|    1235|                null|\n",
      "|    1300|                null|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation into schema\n",
    "\n",
    "citation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}citations.csv', f'{SCHEMAS_FOLDER}citations.csv')\n",
    "citation_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/citations.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# citation_df = spark.read.option('header', 'true').csv('./assets/parsedData/citations.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbf832",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f0ac2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "citation_df = citation_df.withColumn(\"ref_ids\", trim(citation_df.ref_ids))\n",
    "citation_df = citation_df.withColumn(\"paper_id\", trim(citation_df.paper_id))\n",
    "### change data type of paper_id to Integer\n",
    "citation_df = citation_df.withColumn(\"paper_id\",citation_df[\"paper_id\"].cast(IntegerType()))\n",
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe6f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "citation_df.groupby(['paper_id', 'ref_ids']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c54e1c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split citations so we can have clean data and seperate records {paper_id; ref_id}\n",
    "unique_citation_df = citation_df.select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"ref_ids\"),\";\")).alias(\"ref_id\"))\n",
    "unique_citation_df.show(20, False)\n",
    "citation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d01f0e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\", trim(unique_citation_df.ref_id))\n",
    "unique_citation_df = unique_citation_df.withColumn(\"paper_id\", trim(unique_citation_df.paper_id))\n",
    "### change datat type of ref_id to Integer\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\",unique_citation_df[\"ref_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb73e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_citation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89c12f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_citation_df.groupby(['paper_id', 'ref_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da1d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207d516",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "302c4be8",
   "metadata": {},
   "source": [
    "# Load and clean Author df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddcdc71c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/authors.csv, schema path: ./schemas/author.csv\n",
      "[('author_id', 'Integer'), ('citation_count', 'Integer'), ('h_index', 'Integer'), ('name', 'String'), ('paper_count', 'Integer')]\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|author_id|citation_count|h_index|                name|paper_count|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|       17|             0|      0|     J. Michael Howe|          1|\n",
      "|       34|             0|      0|        Haitham Gabr|          2|\n",
      "|       51|             4|      1|         Emma Tonkin|          8|\n",
      "|       68|             1|      1|        Woochul Shin|          4|\n",
      "|       85|             0|      0|           S Improta|          1|\n",
      "|      102|             8|      2|       Richard Ferri|          5|\n",
      "|      119|             0|      0|            Qing Liu|          1|\n",
      "|      136|             0|      0|      Artur Gramacki|          2|\n",
      "|      153|             0|      0|Olumuyiwa Oluwasanmi|          2|\n",
      "|      170|             0|      0|    Josef Willenborg|          1|\n",
      "|      187|             0|      0|            Qing Wei|          1|\n",
      "|      204|             4|      1|Jurey Ivanovich Z...|          1|\n",
      "|      221|            13|      1|             Anny Ng|          1|\n",
      "|      238|             2|      1|    Nikos B. Pronios|          3|\n",
      "|      255|             0|      0| Lourdes Fraga Alman|          1|\n",
      "|      272|             2|      1|       Junji Nishino|          7|\n",
      "|      289|             0|      0|       L. Dascalescu|          2|\n",
      "|      306|             0|      0|    Masakazu Nishino|          1|\n",
      "|      323|             4|      1|    Jean-Rémi Duquet|          2|\n",
      "|      340|             1|      1|     Brian A. Canada|          2|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load author into schema\n",
    "\n",
    "author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}authors.csv', f'{SCHEMAS_FOLDER}author.csv')\n",
    "author_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/author.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# author_df = spark.read.option('header', 'true').csv('./assets/parsedData/authors.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8008c66",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784e5f3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove spaces from values of the columns\n",
    "author_df = author_df.withColumn(\"author_id\", trim(author_df.author_id))\n",
    "author_df = author_df.withColumn(\"citation_count\", trim(author_df.citation_count))\n",
    "author_df = author_df.withColumn(\"h_index\", trim(author_df.h_index))\n",
    "author_df = author_df.withColumn(\"name\", trim(author_df.name))\n",
    "author_df = author_df.withColumn(\"paper_count\", trim(author_df.paper_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e844eb9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### change data type of author_id, paper_count, citation_count, h_index to Integer\n",
    "author_df = author_df.withColumn(\"author_id\",author_df[\"author_id\"].cast(IntegerType()))\n",
    "author_df = author_df.withColumn(\"citation_count\",author_df[\"citation_count\"].cast(IntegerType()))\n",
    "author_df = author_df.withColumn(\"h_index\",author_df[\"h_index\"].cast(IntegerType()))\n",
    "author_df = author_df.withColumn(\"paper_count\",author_df[\"paper_count\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397a083",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "author_df.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6acacf",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_author_df = author_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns]\n",
    "   )\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9c50b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### Decided to drop rows whose author--name is missing (2 authors)\n",
    "### At the moment we can evaluate precomputed paper_count and citation_count only if we have the author_names\n",
    "\n",
    "author_df=author_df.na.drop(how=\"any\", subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba6d65",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb3328",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### fill empty paper_count, citation_count, h_index to 0   (just one author)\n",
    "author_df=author_df.na.fill(value=0, subset='paper_count')\n",
    "author_df=author_df.na.fill(value=0, subset='citation_count')\n",
    "author_df=author_df.na.fill(value=0, subset='h_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf6772",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_author_df = author_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns]\n",
    "   )\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c31d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We noticed that there are many similar names using different symbols/characters like the example below {Antonio García, Antonio Garcia}\n",
    "author_df.filter(author_df['name'].like(\"%Ö%\")).show(20,False)\n",
    "\n",
    "### remove special characters like í, â, é\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "author_df=author_df.withColumn('name', translate('name', 'íîìïīį', 'i'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÎÏÍĪĮÌ', 'I'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'àáâäæãåā', 'a'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÀÁÂÄÆÃÅĀ', 'A'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'èéêëēėę', 'e'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÈÉÊËĒĖĘ', 'E'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ûüùúū', 'u'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÛÜÙÚŪ', 'U'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÔÖÒÓŒØŌÕ', 'O'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'Ÿ', 'Y')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b35691",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\"', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', ';', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', ':', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\}', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\{', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\~', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\{', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\{', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e302e8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check if there are duplicate author_ids\n",
    "author_df.groupby(['name']).count().where('count > 1').sort('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00929a7a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grouped_author_duplicates_df=author_df.groupby(['name'])\n",
    "unique_authors_df=grouped_author_duplicates_df.agg(\n",
    "    round(F.avg(\"paper_count\")).alias(\"paper_count\"),\n",
    "    round(F.avg(\"citation_count\")).alias(\"citation_count\"),\n",
    "    round(F.avg(\"h_index\")).alias(\"h_index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4e7e4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_authors_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd301c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9066b305",
   "metadata": {},
   "source": [
    "# Load and clean Research_interests in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065c387e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/research_interests.csv, schema path: ./schemas/research_interests.csv\n",
      "[('author_id', 'Integer'), ('research_interests', 'String')]\n",
      "+---------+--------------------+\n",
      "|author_id|  research_interests|\n",
      "+---------+--------------------+\n",
      "|       17|HIV disease;Inter...|\n",
      "|       34|associate polynom...|\n",
      "|       51|metadata element;...|\n",
      "|       68|Web Service;conte...|\n",
      "|       85|intermediate key;...|\n",
      "|      102|feedback loop;dif...|\n",
      "|      119|Rough Set;nomal C...|\n",
      "|      136|MATLAB toolbox;li...|\n",
      "|      153|Byzantine agreeme...|\n",
      "|      170|Ein objektorienti...|\n",
      "|      187|portable device;A...|\n",
      "|      204|Integer-valued pr...|\n",
      "|      221|stock price;stock...|\n",
      "|      238|Hypermedia Synchr...|\n",
      "|      255|computer-mediated...|\n",
      "|      272|Dijkstra method;o...|\n",
      "|      289|low-frequency act...|\n",
      "|      306|copyright process...|\n",
      "|      323|uncertain informa...|\n",
      "|      340|histology image;s...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load research_interests into schema\n",
    "\n",
    "research_interests_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}research_interests.csv', f'{SCHEMAS_FOLDER}research_interests.csv')\n",
    "research_interests_df.show()\n",
    "\n",
    "# dtypes = pd.read_csv('./schemas/research_interests.csv').to_records(index=False).tolist()\n",
    "# print(dtypes)\n",
    "# fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "# schema = StructType(fields)\n",
    "# research_interests_df = spark.read.option('header', 'true').csv('./assets/parsedData/research_interests.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ee220",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "research_interests_df = research_interests_df.withColumn(\"author_id\", trim(research_interests_df.author_id))\n",
    "research_interests_df = research_interests_df.withColumn(\"research_interests\", trim(research_interests_df.research_interests))\n",
    "\n",
    "### change data type to Integer for author_id\n",
    "research_interests_df = research_interests_df.withColumn(\"author_id\",research_interests_df[\"author_id\"].cast(IntegerType()))\n",
    "\n",
    "research_interests_df.printSchema()\n",
    "research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967513d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values in the affiliations column\n",
    "research_interests_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in research_interests_df.columns]).show()\n",
    "### drop null values since we dont need research_interests for any computation\n",
    "research_interests_df=research_interests_df.na.drop(how=\"any\", subset=['research_interests'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf3d09",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split affiliations so we can have clean data and seperate records {paper_id; affiliations}\n",
    "unique_research_interests_df = research_interests_df.select(F.col(\"author_id\"), F.explode(F.split(F.col(\"research_interests\"),\";\")).alias(\"research_interest\"))\n",
    "unique_research_interests_df.show(20, False)\n",
    "research_interests_df.show(20, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### remove leading and trailing spaces\n",
    "unique_research_interests_df = unique_research_interests_df.withColumn(\"author_id\", trim(unique_research_interests_df.author_id))\n",
    "unique_research_interests_df = unique_research_interests_df.withColumn(\"research_interest\", trim(unique_research_interests_df.research_interests))\n",
    "\n",
    "# ### change data type to Integer for author_id\n",
    "unique_research_interests_df = unique_research_interests_df.withColumn(\"author_id\",unique_research_interests_df[\"author_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacff62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# unique_research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855bc9f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ### check for duplicate rows:\n",
    "# unique_research_interests_df.groupby(['author_id', 'research_interest']).count().where('count > 1').sort('count', ascending=False).show()\n",
    "# ### drop duplicates\n",
    "# unique_research_interests_df=unique_research_interests_df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1101afd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# unique_research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ed493",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738afbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10818814",
   "metadata": {},
   "source": [
    "# Run Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36310d",
   "metadata": {},
   "source": [
    "### Q1.2 Compute paper count per unique affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fact table\n",
    "unique_affiliations_with_paper_count_df = unique_affiliations_df\\\n",
    "    .groupBy('affiliation')\\\n",
    "    .count()\\\n",
    "    .withColumnRenamed(\"count\", \"papers_count\")\n",
    "print(unique_affiliations_with_paper_count_df.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc2f1",
   "metadata": {},
   "source": [
    "### Q1.1 Validate precomputed paper counts, citation (ref) counts and h-indexes (per author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb36be",
   "metadata": {},
   "source": [
    "#### How to compute h-index for a specific author\n",
    "1. Retrieve all publications of the author (in unique_paper_author_df)\n",
    "2. Calculate the number of references per publication\n",
    "3. Sort the results in descending order\n",
    "4. Find a threshold N, where N top publications have at least N references each. N is the h-index of the author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of references per publication\n",
    "refs_per_paper_count_df = unique_citation_df.groupBy(\"paper_id\").count().withColumnRenamed(\"count\",\"paper_references\")\n",
    "print(refs_per_paper_count_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2dc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join [papers per author] with [references per paper] and sort the results in descending order\n",
    "author_papers_with_ref_count = unique_paper_author_df.join(refs_per_paper_count_df, 'paper_id').sort(col(\"paper_references\").desc())\n",
    "print(author_papers_with_ref_count.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(author_papers_with_ref_count['author']).orderBy(desc(\"paper_references\"), desc(\"paper_id\"))\n",
    "indexed_grouped_papers_df = author_papers_with_ref_count.select('*', rank().over(window).alias('index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670dbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_indexed_papers = indexed_grouped_papers_df.withColumn(\"possible_h_index\", when(indexed_grouped_papers_df.index <= indexed_grouped_papers_df.paper_references, indexed_grouped_papers_df.index).otherwise(0))\n",
    "print(h_indexed_papers.show(100, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_indexed_grouped_by_author_papers_df = h_indexed_papers.groupBy('author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_indexed_aggregated_papers_df = h_indexed_grouped_by_author_papers_df.agg(\\\n",
    "        F.count(\"paper_id\").alias(\"computed_paper_count\"),\n",
    "        F.sum(\"paper_references\").alias(\"computed_citation_count\"),\n",
    "        F.max(\"possible_h_index\").alias(\"computed_h_index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325bbf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_indexed_aggregated_papers_df = h_indexed_aggregated_papers_df.withColumnRenamed(\"author\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join the real authors with the validated data from paper dataset\n",
    "unique_authors_with_validated_cols_df = unique_authors_df.join(h_indexed_aggregated_papers_df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_authors_with_validated_cols_df.show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e05ae",
   "metadata": {},
   "source": [
    "# Save cleaned & computed data into the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DATA_FOLDER = './assets/cleanedDFsData/'\n",
    "def saveDFIntoCSVFile(df, fileName):\n",
    "#     df = sqlContext.createDataFrame(dictsArray)\n",
    "    print(df.show())\n",
    "    # Save data to csv file\n",
    "    df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & unique papers data\n",
    "saveDFIntoCSVFile(paper_df, f'{CLEAN_DATA_FOLDER}papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & unique paper author data\n",
    "saveDFIntoCSVFile(unique_paper_author_df, f'{CLEAN_DATA_FOLDER}paper_author.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64923593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & unique affiliations data with computed paper_count\n",
    "saveDFIntoCSVFile(unique_affiliations_with_paper_count_df, f'{CLEAN_DATA_FOLDER}affiliations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & unique publication venues data \n",
    "saveDFIntoCSVFile(publication_venue_df, f'{CLEAN_DATA_FOLDER}publication_venues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51522c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & unique citations data\n",
    "saveDFIntoCSVFile(unique_citation_df, f'{CLEAN_DATA_FOLDER}citations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74797d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & computed & unique authors data\n",
    "saveDFIntoCSVFile(unique_authors_with_validated_cols_df, f'{CLEAN_DATA_FOLDER}authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned & computed & research interests data\n",
    "saveDFIntoCSVFile(unique_research_interests_df, f'{CLEAN_DATA_FOLDER}research_interests.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
