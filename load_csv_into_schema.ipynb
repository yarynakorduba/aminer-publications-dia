{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4071cf9f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae6ee91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('read data through spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb68a75d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.104:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>read data through spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa180d4d6d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7626e981",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92dff5",
   "metadata": {},
   "source": [
    "# Load and clean Paper DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f2f871ce",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n"
     ]
    }
   ],
   "source": [
    "### load paper into schema\n",
    "dtypes = pd.read_csv('./schemas/paper.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "paper_df = spark.read.option('header', 'true').csv('./assets/parsedData/papers.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1c6715de",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|                null|null|\n",
      "|     130|                null|null|\n",
      "|     195|317424;317425;317573|null|\n",
      "|     260|                null|null|\n",
      "|     325|                null|null|\n",
      "|     390|                null|null|\n",
      "|     455|                null|null|\n",
      "|     520|       318368;323493|null|\n",
      "|     585|                null|null|\n",
      "|     650|                null|null|\n",
      "|     715|                null|null|\n",
      "|     780|318420;319233;319...|null|\n",
      "|     845|                null|null|\n",
      "|     910|                null|null|\n",
      "|     975|67604;318882;3718...|null|\n",
      "|    1040|                null|null|\n",
      "|    1105|289087;318014;318...|null|\n",
      "|    1170|                null|null|\n",
      "|    1235|                null|null|\n",
      "|    1300|                null|null|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/17 19:10:46 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 4, schema size: 3\n",
      "CSV file: file:///Users/user/PycharmProjects/aminer-publications-dia/assets/parsedData/papers.csv\n"
     ]
    }
   ],
   "source": [
    "paper_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3054c0b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### data cleaning for paper schema\n",
    "\n",
    "### remove spaces from values of the columns\n",
    "paper_df = paper_df.withColumn(\"paper_id\", trim(paper_df.paper_id))\n",
    "paper_df = paper_df.withColumn(\"title\", trim(paper_df.title))\n",
    "paper_df = paper_df.withColumn(\"year\", trim(paper_df.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "285bb60f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check for the data types\n",
    "paper_df.printSchema()\n",
    "### change the data type of year to Integer\n",
    "paper_df = paper_df.withColumn(\"year\",paper_df[\"year\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "40fc4cf2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/17 19:10:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: paper_id, ref_ids\n",
      " Schema: paper_id, title\n",
      "Expected: title but found: ref_ids\n",
      "CSV file: file:///Users/user/PycharmProjects/aminer-publications-dia/assets/parsedData/papers.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for nonsense null data\n",
    "null_values_paper_df = paper_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_df.columns]\n",
    "   )\n",
    "### save the ids of papers whose title is missing to clean up the other dataframes\n",
    "null_paper_ids = paper_df.filter(paper_df['title'].isNull())\n",
    "null_paper_ids_list=null_paper_ids.select('paper_id').rdd.flatMap(lambda x: x).collect()\n",
    "null_paper_ids_list = [int(item) for item in null_paper_ids_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fbdfb814",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### after checking the below dataframes, all papers whose title is missing have the authors besides paper_id = 748056\n",
    "### decision: fill missing titles with : Missing Title\n",
    "\n",
    "paper_df=paper_df.na.fill('Missing Title', ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f62d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\"', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', ';', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', ':', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\}', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\{', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\~', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\{', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\{', ''))\n",
    "paper_df=paper_df.withColumn('title', regexp_replace('title', '\\/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "53f0f49a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper_id', 'title', 'year']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6b78e5ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/17 19:11:04 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 4, schema size: 3\n",
      "CSV file: file:///Users/user/PycharmProjects/aminer-publications-dia/assets/parsedData/papers.csv\n",
      "22/01/17 19:11:19 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 4, schema size: 3\n",
      "CSV file: file:///Users/user/PycharmProjects/aminer-publications-dia/assets/parsedData/papers.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----+-------------------+\n",
      "|paper_id|        title|year|Duplicate_indicator|\n",
      "+--------+-------------+----+-------------------+\n",
      "|  372592|Missing Title|  38|                  0|\n",
      "|  989909|Missing Title| 300|                  0|\n",
      "|  989911|Missing Title|  49|                  0|\n",
      "|  989912|Missing Title|8848|                  0|\n",
      "| 1802227|Missing Title|1976|                  0|\n",
      "|  904713|Missing Title|1630|                  0|\n",
      "| 1999888|Missing Title|   1|                  0|\n",
      "| 1082418|Missing Title| 893|                  0|\n",
      "| 1053960|Missing Title|2008|                  0|\n",
      "|  153257|Missing Title|1993|                  0|\n",
      "+--------+-------------+----+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 160:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|paper_id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate rows\n",
    "paper_df.join(paper_df.groupBy(paper_df.columns).agg((F.count(\"*\")>1).cast(\"int\").alias(\"Duplicate_indicator\")),\n",
    "on=paper_df.columns,how=\"inner\").show()\n",
    "###there are no duplicates\n",
    "paper_df.groupby(['paper_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df50d456",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot resolve column name \"title\" among (paper_id, author)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/sh/b6zycc1x343374cxzxzb0ymw0000gn/T/ipykernel_12434/1649048211.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpaper_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munique_paper_author_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'title'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlike\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"%\"\u001B[0m\u001B[0;34m\"%\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m   1634\u001B[0m         \"\"\"\n\u001B[1;32m   1635\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1636\u001B[0;31m             \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1637\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1638\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mColumn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1308\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1309\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1310\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1311\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: Cannot resolve column name \"title\" among (paper_id, author)"
     ]
    }
   ],
   "source": [
    "paper_df.filter(unique_paper_author_df['title'].like(\"%%\")).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7b6c",
   "metadata": {},
   "source": [
    "# Load and clean Affiliations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d4c21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### load affiliation into schema\n",
    "dtypes = pd.read_csv('./schemas/affiliation.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "affiliation_df = spark.read.option('header', 'true').csv('./assets/parsedData/affiliations.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab85ad4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "affiliation_df = affiliation_df.withColumn(\"affiliations\", trim(affiliation_df.affiliations))\n",
    "affiliation_df = affiliation_df.withColumn(\"paper_id\", trim(affiliation_df.paper_id))\n",
    "affiliation_df = affiliation_df.withColumn(\"paper_id\",affiliation_df[\"paper_id\"].cast(IntegerType()))\n",
    "\n",
    "affiliation_df.printSchema()\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1159c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values in the affiliations column\n",
    "null_values_affiliations=affiliation_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in affiliation_df.columns]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5fdc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### This df is used to count papers per unique affiliation, so if the affiliation is missing, it doesnt make sense\n",
    "### drop all rows where affiliation is null\n",
    "\n",
    "affiliation_df=affiliation_df.na.drop(how=\"any\", subset=['affiliations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1018dd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "affiliation_df.filter(affiliation_df.affiliations.contains('-')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a272c4e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check if affiliations are missing as well for the ids whose title was missing in paper_df\n",
    "for rows in affiliation_df.select(\"affiliations\",\"paper_id\").collect():\n",
    "    if rows[1] in null_paper_ids_list:\n",
    "        print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8504dda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split affiliations so we can have clean data and seperate records {paper_id; affiliations}\n",
    "unique_affiliations_df = affiliation_df.select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"affiliations\"),\";\")).alias(\"affiliation\"))\n",
    "unique_affiliations_df.show(20, False)\n",
    "affiliation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195d7d4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for special nonsense characters \"-\", If the affiliation is missing, there is no point of keeping the rows\n",
    "###unique_affiliations_df.filter(unique_affiliations_df.affiliations=='-').collect()\n",
    "unique_affiliations_df=unique_affiliations_df.where(unique_affiliations_df.affiliation!='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3c444",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62eeaed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_affiliations_df.groupby(['paper_id', 'affiliation']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbf49b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique affiliations\n",
    "unique_affiliations_df=unique_affiliations_df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d2b75",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855886fd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0083171",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d6238",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a05c0c",
   "metadata": {},
   "source": [
    "# Load and clean paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4a52ef00",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('authors', 'String'), ('paper_id', 'Integer')]\n"
     ]
    }
   ],
   "source": [
    "### load paper_authors into schema\n",
    "dtypes = pd.read_csv('./schemas/paper_authors.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "paper_author_df = spark.read.option('header', 'true').csv('./assets/parsedData/paper_authors.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "47851ec9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             authors|paper_id|\n",
      "+--------------------+--------+\n",
      "| K Devine;F J. Smith|      65|\n",
      "|J Wolff von Guden...|     130|\n",
      "|J. K. Reid;A. Jen...|     195|\n",
      "|William G. Golson...|     260|\n",
      "|    Stein Schjolberg|     325|\n",
      "|W Ian Gasarch;Ste...|     390|\n",
      "|Sam Toueg;Özalp B...|     455|\n",
      "|Frederick H. Dill...|     520|\n",
      "|A. R. Calderbank;...|     585|\n",
      "|         Uzi Vishkin|     650|\n",
      "|      Stephen S. Yau|     715|\n",
      "|Michael D. Schroe...|     780|\n",
      "|         S L. Graham|     845|\n",
      "|D Maio;M R. Scala...|     910|\n",
      "|         Pamela Zave|     975|\n",
      "|G. Salton;E. Voor...|    1040|\n",
      "|Douglas D. Dunlop...|    1105|\n",
      "|Patrick Peruch;Vi...|    1170|\n",
      "| Robert J. Sternberg|    1235|\n",
      "|Curtis Roads;John...|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- authors: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### remove leadind and trailing spaces\n",
    "paper_author_df = paper_author_df.withColumn(\"authors\", trim(paper_author_df.authors))\n",
    "paper_author_df = paper_author_df.withColumn(\"paper_id\", trim(paper_author_df.paper_id))\n",
    "\n",
    "### change data type for paper_id to Integer\n",
    "paper_author_df = paper_author_df.withColumn(\"paper_id\",paper_author_df[\"paper_id\"].cast(IntegerType()))\n",
    "\n",
    "paper_author_df.show()\n",
    "paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "73be8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special letters\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'íîìïīį', 'i'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÎÏÍĪĮÌ', 'I'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'àáâäæãåā', 'a'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÀÁÂÄÆÃÅĀ', 'A'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'èéêëēėę', 'e'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÈÉÊËĒĖĘ', 'E'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ûüùúū', 'u'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÛÜÙÚŪ', 'U'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'ÔÖÒÓŒØŌÕ', 'O'))\n",
    "paper_author_df=paper_author_df.withColumn('authors', translate('authors', 'Ÿ', 'Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e221572c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "null_values_paper_authors=paper_author_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_author_df.columns]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ef567a85",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'null_paper_ids_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/sh/b6zycc1x343374cxzxzb0ymw0000gn/T/ipykernel_12434/56912069.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m### check if authors are missing as well for the ids whose title was missing in paper_df\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mrows\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpaper_author_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"authors\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"paper_id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0mrows\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnull_paper_ids_list\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrows\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrows\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'null_paper_ids_list' is not defined"
     ]
    }
   ],
   "source": [
    "### check if authors are missing as well for the ids whose title was missing in paper_df\n",
    "###for rows in paper_author_df.select(\"authors\",\"paper_id\").collect():\n",
    "###    if rows[1] in null_paper_ids_list:\n",
    "###        print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "55522a82",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+\n",
      "|paper_id|author               |\n",
      "+--------+---------------------+\n",
      "|65      |K Devine             |\n",
      "|65      |F J. Smith           |\n",
      "|130     |J Wolff von Gudenberg|\n",
      "|195     |J. K. Reid           |\n",
      "|195     |A. Jennings          |\n",
      "|260     |William G. Golson    |\n",
      "|260     |William C. Rounds    |\n",
      "|325     |Stein Schjolberg     |\n",
      "|390     |W Ian Gasarch        |\n",
      "|390     |Steven Homer         |\n",
      "|455     |Sam Toueg            |\n",
      "|455     |zalp Babaoğlu        |\n",
      "|520     |Frederick H. Dill    |\n",
      "|520     |Satish Gupta         |\n",
      "|520     |Daniel T. Ling       |\n",
      "|520     |Richard E. Matick    |\n",
      "|585     |A. R. Calderbank     |\n",
      "|585     |E. G. Coffman, Jr.   |\n",
      "|585     |L. Flatto            |\n",
      "|650     |Uzi Vishkin          |\n",
      "+--------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------------------------------------------------------+--------+\n",
      "|authors                                                        |paper_id|\n",
      "+---------------------------------------------------------------+--------+\n",
      "|K Devine;F J. Smith                                            |65      |\n",
      "|J Wolff von Gudenberg                                          |130     |\n",
      "|J. K. Reid;A. Jennings                                         |195     |\n",
      "|William G. Golson;William C. Rounds                            |260     |\n",
      "|Stein Schjolberg                                               |325     |\n",
      "|W Ian Gasarch;Steven Homer                                     |390     |\n",
      "|Sam Toueg;zalp Babaoğlu                                        |455     |\n",
      "|Frederick H. Dill;Satish Gupta;Daniel T. Ling;Richard E. Matick|520     |\n",
      "|A. R. Calderbank;E. G. Coffman, Jr.;L. Flatto                  |585     |\n",
      "|Uzi Vishkin                                                    |650     |\n",
      "|Stephen S. Yau                                                 |715     |\n",
      "|Michael D. Schroeder;Andrew D. Birrell;Roger M. Needham        |780     |\n",
      "|S L. Graham                                                    |845     |\n",
      "|D Maio;M R. Scalas;P Tiberio                                   |910     |\n",
      "|Pamela Zave                                                    |975     |\n",
      "|G. Salton;E. Voorhees;E. A. Fox                                |1040    |\n",
      "|Douglas D. Dunlop;Victor R. Basili                             |1105    |\n",
      "|Patrick Peruch;Viola Cavallo;Christian Deutsch;Jean Pailhous   |1170    |\n",
      "|Robert J. Sternberg                                            |1235    |\n",
      "|Curtis Roads;John Strawn                                       |1300    |\n",
      "+---------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split authors so we can have clean data and seperate records {paper_id; author}\n",
    "unique_paper_author_df = paper_author_df.select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"authors\"),\";\")).alias(\"author\"))\n",
    "unique_paper_author_df.show(20, False)\n",
    "paper_author_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f15561fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"author\", trim(unique_paper_author_df.author))\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"paper_id\", trim(unique_paper_author_df.paper_id))\n",
    "### change data type for paper_id to Integer\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"paper_id\",unique_paper_author_df[\"paper_id\"].cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75be0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\"', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', ';', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', ':', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\}', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\{', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\~', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\{', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\{', ''))\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', regexp_replace('author', '\\/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75d03e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a7140f1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/17 18:28:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:28:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:28:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:28:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/17 18:29:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+\n",
      "|paper_id|           author|count|\n",
      "+--------+-----------------+-----+\n",
      "| 1523221|     Dongkun Shin|    4|\n",
      "| 2059316|    Han Chuanfeng|    3|\n",
      "| 1202294|        N. Sharma|    3|\n",
      "| 2040206|     Anchun Cheng|    3|\n",
      "| 2040206|     Mingshu Wang|    3|\n",
      "| 2042230|          Lu Leng|    3|\n",
      "| 1864850| Pauline C. Reich|    2|\n",
      "| 1198485|  Nedeljko Cvejic|    2|\n",
      "| 1989466|    Morris Riedel|    2|\n",
      "| 1586139|     Hector Zenil|    2|\n",
      "| 1198797| Alladi Venkatesh|    2|\n",
      "| 1434302|        Meir Russ|    2|\n",
      "| 1167730|  Max A. Woodbury|    2|\n",
      "| 1071070| Thorbjrn Knudsen|    2|\n",
      "| 1966201|           Bo Liu|    2|\n",
      "| 1612982|         A. Klemm|    2|\n",
      "| 1297077|           Bei Yu|    2|\n",
      "| 1443917|      Lingli Zhao|    2|\n",
      "| 1947014| Steven Warburton|    2|\n",
      "|  581650|J. Howard Johnson|    2|\n",
      "+--------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows:\n",
    "unique_paper_author_df.groupby(['paper_id', 'author']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80d2a640",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique paper-author relation\n",
    "unique_paper_author_df=unique_paper_author_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72777581",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|paper_id|author             |\n",
      "+--------+-------------------+\n",
      "|1117    |Benjamin Kuipers   |\n",
      "|1574    |J. G. Brookshear   |\n",
      "|1707    |C. Ghezzi          |\n",
      "|1829    |Peter M. Stephan   |\n",
      "|2080    |Matthew L. Ginsberg|\n",
      "|2222    |Nissim Francez     |\n",
      "|2615    |Dan Benanav        |\n",
      "|2872    |Trevor J. Bentley  |\n",
      "|2996    |Martin T. Sullivan |\n",
      "|3185    |William B. Robinson|\n",
      "|3261    |Guy Lapalme        |\n",
      "|3584    |L. Egghe           |\n",
      "|4362    |C-T Liou           |\n",
      "|4369    |Y-C Chen           |\n",
      "|4424    |Ron M Roth         |\n",
      "|5735    |D Eyre             |\n",
      "|5860    |S Makridakis       |\n",
      "|6181    |W J Baggaley       |\n",
      "|6247    |Ravi B Boppana     |\n",
      "|6700    |Tomas Hirschfeld   |\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_paper_author_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c7031",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d4afe",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab611b13",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b4f5d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1855220",
   "metadata": {},
   "source": [
    "# Load and clean Publication_venues df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25f590",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### load publication_venues into schema\n",
    "dtypes = pd.read_csv('./schemas/publication_venues.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "publication_venue_df = spark.read.option('header', 'true').csv('./assets/parsedData/publication_venues.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026166d7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "publication_venue_df = publication_venue_df.withColumn(\"publication_venue\", trim(publication_venue_df.publication_venue))\n",
    "publication_venue_df = publication_venue_df.withColumn(\"paper_id\", trim(publication_venue_df.paper_id))\n",
    "publication_venue_df = publication_venue_df.withColumn(\"paper_id\",publication_venue_df[\"paper_id\"].cast(IntegerType()))\n",
    "publication_venue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa39b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "null_values_publication_venue=publication_venue_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in publication_venue_df.columns]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3dd2b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "publication_venue_df.filter(publication_venue_df['publication_venue'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0c6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a6ec60",
   "metadata": {},
   "source": [
    "# Load and clean Citations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24ec61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### load affiliation into schema\n",
    "dtypes = pd.read_csv('./schemas/citations.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "citation_df = spark.read.option('header', 'true').csv('./assets/parsedData/citations.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbf832",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f0ac2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "citation_df = citation_df.withColumn(\"ref_ids\", trim(citation_df.ref_ids))\n",
    "citation_df = citation_df.withColumn(\"paper_id\", trim(citation_df.paper_id))\n",
    "### change data type of paper_id to Integer\n",
    "citation_df = citation_df.withColumn(\"paper_id\",citation_df[\"paper_id\"].cast(IntegerType()))\n",
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe6f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "citation_df.groupby(['paper_id', 'ref_ids']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c54e1c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split citations so we can have clean data and seperate records {paper_id; ref_id}\n",
    "unique_citation_df = citation_df.select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"ref_ids\"),\";\")).alias(\"ref_id\"))\n",
    "unique_citation_df.show(20, False)\n",
    "citation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d01f0e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\", trim(unique_citation_df.ref_id))\n",
    "unique_citation_df = unique_citation_df.withColumn(\"paper_id\", trim(unique_citation_df.paper_id))\n",
    "### change datat type of ref_id to Integer\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\",unique_citation_df[\"ref_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb73e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_citation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89c12f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_citation_df.groupby(['paper_id', 'ref_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da1d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207d516",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "302c4be8",
   "metadata": {},
   "source": [
    "# Load and clean Author df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddcdc71c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('author_id', 'Integer'), ('citation_count', 'Integer'), ('h_index', 'Integer'), ('name', 'String'), ('paper_count', 'Integer')]\n"
     ]
    }
   ],
   "source": [
    "### load author into schema\n",
    "dtypes = pd.read_csv('./schemas/author.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "author_df = spark.read.option('header', 'true').csv('./assets/parsedData/authors.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8008c66",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- citation_count: integer (nullable = true)\n",
      " |-- h_index: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- paper_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0784e5f3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove spaces from values of the columns\n",
    "author_df = author_df.withColumn(\"author_id\", trim(author_df.author_id))\n",
    "author_df = author_df.withColumn(\"citation_count\", trim(author_df.citation_count))\n",
    "author_df = author_df.withColumn(\"h_index\", trim(author_df.h_index))\n",
    "author_df = author_df.withColumn(\"name\", trim(author_df.name))\n",
    "author_df = author_df.withColumn(\"paper_count\", trim(author_df.paper_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e844eb9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### change data type of author_id, paper_count, citation_count, h_index to Integer\n",
    "author_df = author_df.withColumn(\"author_id\",author_df[\"author_id\"].cast(IntegerType()))\n",
    "author_df = author_df.withColumn(\"citation_count\",author_df[\"citation_count\"].cast(IntegerType()))\n",
    "author_df = author_df.withColumn(\"h_index\",author_df[\"h_index\"].cast(IntegerType()))\n",
    "author_df = author_df.withColumn(\"paper_count\",author_df[\"paper_count\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8397a083",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+-------------------------+-----------+\n",
      "|author_id|citation_count|h_index|name                     |paper_count|\n",
      "+---------+--------------+-------+-------------------------+-----------+\n",
      "|17       |0             |0      |J. Michael Howe          |1          |\n",
      "|34       |0             |0      |Haitham Gabr             |2          |\n",
      "|51       |4             |1      |Emma Tonkin              |8          |\n",
      "|68       |1             |1      |Woochul Shin             |4          |\n",
      "|85       |0             |0      |S Improta                |1          |\n",
      "|102      |8             |2      |Richard Ferri            |5          |\n",
      "|119      |0             |0      |Qing Liu                 |1          |\n",
      "|136      |0             |0      |Artur Gramacki           |2          |\n",
      "|153      |0             |0      |Olumuyiwa Oluwasanmi     |2          |\n",
      "|170      |0             |0      |Josef Willenborg         |1          |\n",
      "|187      |0             |0      |Qing Wei                 |1          |\n",
      "|204      |4             |1      |Jurey Ivanovich Zhuravlev|1          |\n",
      "|221      |13            |1      |Anny Ng                  |1          |\n",
      "|238      |2             |1      |Nikos B. Pronios         |3          |\n",
      "|255      |0             |0      |Lourdes Fraga Alman      |1          |\n",
      "|272      |2             |1      |Junji Nishino            |7          |\n",
      "|289      |0             |0      |L. Dascalescu            |2          |\n",
      "|306      |0             |0      |Masakazu Nishino         |1          |\n",
      "|323      |4             |1      |Jean-Rémi Duquet         |2          |\n",
      "|340      |1             |1      |Brian A. Canada          |2          |\n",
      "+---------+--------------+-------+-------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author_df.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6acacf",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_author_df = author_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns]\n",
    "   )\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7c9c50b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### Decided to drop rows whose author--name is missing (2 authors)\n",
    "### At the moment we can evaluate precomputed paper_count and citation_count only if we have the author_names\n",
    "\n",
    "author_df=author_df.na.drop(how=\"any\", subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8ba6d65",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- citation_count: integer (nullable = true)\n",
      " |-- h_index: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- paper_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fdb3328",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### fill empty paper_count, citation_count, h_index to 0   (just one author)\n",
    "author_df=author_df.na.fill(value=0, subset='paper_count')\n",
    "author_df=author_df.na.fill(value=0, subset='citation_count')\n",
    "author_df=author_df.na.fill(value=0, subset='h_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf6772",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_author_df = author_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns]\n",
    "   )\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32c31d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+----+-----------+\n",
      "|author_id|citation_count|h_index|name|paper_count|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "+---------+--------------+-------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 70:======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### We noticed that there are many similar names using different symbols/characters like the example below {Antonio García, Antonio Garcia}\n",
    "author_df.filter(author_df['name'].like(\"%Ö%\")).show(20,False)\n",
    "\n",
    "### remove special characters like í, â, é\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "author_df=author_df.withColumn('name', translate('name', 'íîìïīį', 'i'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÎÏÍĪĮÌ', 'I'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'àáâäæãåā', 'a'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÀÁÂÄÆÃÅĀ', 'A'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'èéêëēėę', 'e'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÈÉÊËĒĖĘ', 'E'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ûüùúū', 'u'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÛÜÙÚŪ', 'U'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'ÔÖÒÓŒØŌÕ', 'O'))\n",
    "author_df=author_df.withColumn('name', translate('name', 'Ÿ', 'Y')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "35b35691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 162:===================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+------------------+-----------+\n",
      "|author_id|citation_count|h_index|name              |paper_count|\n",
      "+---------+--------------+-------+------------------+-----------+\n",
      "|1021498  |0             |0      |Osman Og~uz       |1          |\n",
      "|898419   |0             |0      |David Ria~{n}o    |1          |\n",
      "|1248891  |0             |0      |A. Del~Bimbo      |1          |\n",
      "|898713   |0             |0      |David Ria~{n}o    |1          |\n",
      "|1315421  |3             |1      |Katia S. Guimar~es|1          |\n",
      "|49348    |1             |1      |S. H. ~Son        |1          |\n",
      "|1430854  |0             |0      |Jo~ao Sequeira    |1          |\n",
      "|1519119  |8             |1      |M. ~Fujita        |1          |\n",
      "+---------+--------------+-------+------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 162:======================================>                  (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### remove special characters\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\"', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', ';', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', ':', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\}', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\{', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\~', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\{', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\{', ''))\n",
    "author_df=author_df.withColumn('name', regexp_replace('name', '\\/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e302e8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check if there are duplicate author_ids\n",
    "author_df.groupby(['name']).count().where('count > 1').sort('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "00929a7a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "duplicated_authors=author_df.groupby(['name'])\n",
    "unique_duplicated_authors=duplicated_authors.agg(\n",
    "    round(F.avg(\"paper_count\")).alias(\"paper_count\"),\n",
    "    round(F.avg(\"citation_count\")).alias(\"citation_count\"),\n",
    "    round(F.avg(\"h_index\")).alias(\"h_index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "35e4e7e4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1287001"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_duplicated_authors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd301c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9066b305",
   "metadata": {},
   "source": [
    "# Load and Research_interests in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c387e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### load research_interests into schema\n",
    "dtypes = pd.read_csv('./schemas/research_interests.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "research_interests_df = spark.read.option('header', 'true').csv('./assets/parsedData/research_interests.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ee220",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "research_interests_df = research_interests_df.withColumn(\"author_id\", trim(research_interests_df.author_id))\n",
    "research_interests_df = research_interests_df.withColumn(\"research_interests\", trim(research_interests_df.research_interests))\n",
    "\n",
    "### change data type to Integer for author_id\n",
    "research_interests_df = research_interests_df.withColumn(\"author_id\",research_interests_df[\"author_id\"].cast(IntegerType()))\n",
    "\n",
    "research_interests_df.printSchema()\n",
    "research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967513d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values in the affiliations column\n",
    "research_interests_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in research_interests_df.columns]).show()\n",
    "### drop null values since we dont need research_interests for any computation\n",
    "research_interests_df=research_interests_df.na.drop(how=\"any\", subset=['research_interests'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf3d09",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### split affiliations so we can have clean data and seperate records {paper_id; affiliations}\n",
    "unique_research_interests_df = research_interests_df.select(F.col(\"author_id\"), F.explode(F.split(F.col(\"research_interests\"),\";\")).alias(\"research_interest\"))\n",
    "unique_research_interests_df.show(20, False)\n",
    "research_interests_df.show(20, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_research_interests_df = unique_research_interests_df.withColumn(\"author_id\", trim(unique_research_interests_df.author_id))\n",
    "unique_research_interests_df = unique_research_interests_df.withColumn(\"research_interest\", trim(unique_research_interests_df.research_interests))\n",
    "\n",
    "### change data type to Integer for author_id\n",
    "unique_research_interests_df = unique_research_interests_df.withColumn(\"author_id\",unique_research_interests_df[\"author_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacff62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855bc9f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_research_interests_df.groupby(['author_id', 'research_interest']).count().where('count > 1').sort('count', ascending=False).show()\n",
    "### drop duplicates\n",
    "unique_research_interests_df=unique_research_interests_df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1101afd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ed493",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}