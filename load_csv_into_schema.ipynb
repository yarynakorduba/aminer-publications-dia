{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "# *                   _oo0oo_\n",
    "# *                  o8888888o\n",
    "# *                  88\" . \"88\n",
    "# *                  (| -_- |)\n",
    "# *                  0\\  =  /0\n",
    "# *                ___/`---'\\___\n",
    "# *              .' \\\\|     |// '.\n",
    "# *             / \\\\|||  :  |||// \\\n",
    "# *            / _||||| -:- |||||- \\\n",
    "# *           |   | \\\\\\  -  /// |   |\n",
    "# *           | \\_|  ''\\---/''  |_/ |\n",
    "# *           \\  .-\\__  '-'  ___/-. /\n",
    "# *         ___'. .'  /--.--\\  `. .'___\n",
    "# *      .\"\" '<  `.___\\_<|>_/___.' >' \"\".\n",
    "# *     | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
    "# *     \\  \\ `_.   \\_ __\\ /__ _/   .-` /  /\n",
    "# * =====`-.____`.___ \\_____/___.-`___.-'=====\n",
    "# *                   `=---='\n",
    "# *\n",
    "# *\n",
    "# * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# *\n",
    "# *   Buddha blesses your code to be bug free\n",
    "# */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4071cf9f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7626e981",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from helpers import createDFFromFileAndSchema, clean_special_letters, clean_special_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7eb9c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae6ee91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Clean up the data and perform the queries').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb68a75d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://t-193.vc-graz.ac.at:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ec86130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062ec083",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMAS_FOLDER = './schemas/'\n",
    "FILES_FOLDER = './assets/parsedData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92dff5",
   "metadata": {},
   "source": [
    "# Load and clean Paper DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f871ce",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/papers.csv, schema path: ./schemas/paper.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n",
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|Direct file organ...|1984|\n",
      "|     130|An introduction t...|1983|\n",
      "|     195|On solving almost...|1984|\n",
      "|     260|Connections betwe...|1984|\n",
      "|     325|Computers and pen...|1984|\n",
      "|     390|Relativizations c...|1984|\n",
      "|     455|On the optimum ch...|1984|\n",
      "|     520|All points addres...|1984|\n",
      "|     585|Optimum Head Sepa...|1984|\n",
      "|     650|A parallel-design...|1984|\n",
      "|     715|Computer - IEEE C...|1984|\n",
      "|     780|Experience with G...|1984|\n",
      "|     845|Code generation a...|1984|\n",
      "|     910|On estimating acc...|1984|\n",
      "|     975|A distributed alt...|1985|\n",
      "|    1040|A comparison of t...|1984|\n",
      "|    1105|Generalizing spec...|1985|\n",
      "|    1170|Real time graphic...|1984|\n",
      "|    1235|Common and uncomm...|1984|\n",
      "|    1300|Foundations of co...|1985|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load paper csv into schema\n",
    "paper_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}papers.csv', f'{SCHEMAS_FOLDER}paper.csv')\n",
    "paper_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a7cc",
   "metadata": {},
   "source": [
    "### Data cleaning for paper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3054c0b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove spaces from values of the columns\n",
    "paper_df = paper_df.withColumn(\"title\", trim(paper_df.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285bb60f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check for the correct data types\n",
    "paper_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fc4cf2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_paper_df = paper_df.select(\n",
    "    [count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_df.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_paper_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbdfb814",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### after checking the below dataframes,\n",
    "### we have seen that all papers, whose title is missing, have the authors (besides paper_id = 748056)\n",
    "### Decision: fill missing titles with: \"Missing Title\"\n",
    "\n",
    "paper_df=paper_df.na.fill('Missing Title', ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f62d8e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "paper_df=clean_special_character(paper_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b78e5ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+-------------------+\n",
      "|paper_id|               title|year|Duplicate_indicator|\n",
      "+--------+--------------------+----+-------------------+\n",
      "|      22|On two more Eigen...|1984|                  0|\n",
      "|      27|Frame theory and ...|1984|                  0|\n",
      "|      30|Stationary wave s...|1984|                  0|\n",
      "|      32|Proc. IFIP workin...|1983|                  0|\n",
      "|      44|ADA Concurrent Pr...|1984|                  0|\n",
      "|      52|Automated microco...|1984|                  0|\n",
      "|      58|The application o...|1983|                  0|\n",
      "|      61|The DISS methodol...|1984|                  0|\n",
      "|      66|Soft evaluation o...|1984|                  0|\n",
      "|      91|Design of optimal...|1982|                  0|\n",
      "|     107|Deterministic pro...|1984|                  0|\n",
      "|     113|From logic to com...|1983|                  0|\n",
      "|     114|A first course in...|1983|                  0|\n",
      "|     122|Proc. of the symp...|1983|                  0|\n",
      "|     126|Evaluation of ari...|1983|                  0|\n",
      "|     134|       MATRIX PASCAL|1983|                  0|\n",
      "|     139|    Programming in C|1983|                  0|\n",
      "|     151|An extension of c...|1984|                  0|\n",
      "|     154|Database manageme...|1984|                  0|\n",
      "|     165|A quadratically c...|1984|                  0|\n",
      "+--------+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|paper_id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate rows\n",
    "paper_df.join(\n",
    "    paper_df\n",
    "        .groupBy(paper_df.columns) \\\n",
    "        .agg((F.count(\"*\")>1) \\\n",
    "        .cast(\"int\") \\\n",
    "        .alias(\"Duplicate_indicator\")), \\\n",
    "        on=paper_df.columns,how=\"inner\") \\\n",
    "    .show()\n",
    "### from the dataframe view, we can see that there are no duplicates\n",
    "paper_df.groupby(['paper_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b03384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092356"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check for the number of paper entries\n",
    "paper_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f7c3d",
   "metadata": {},
   "source": [
    "# Load and clean paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82641fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/paper_authors.csv, schema path: ./schemas/paper_authors.csv\n",
      "Types from schema: [('authors', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|             authors|paper_id|\n",
      "+--------------------+--------+\n",
      "| K Devine;F J. Smith|      65|\n",
      "|J Wolff von Guden...|     130|\n",
      "|J. K. Reid;A. Jen...|     195|\n",
      "|William G. Golson...|     260|\n",
      "|    Stein Schjolberg|     325|\n",
      "|W Ian Gasarch;Ste...|     390|\n",
      "|Sam Toueg;Özalp B...|     455|\n",
      "|Frederick H. Dill...|     520|\n",
      "|A. R. Calderbank;...|     585|\n",
      "|         Uzi Vishkin|     650|\n",
      "|      Stephen S. Yau|     715|\n",
      "|Michael D. Schroe...|     780|\n",
      "|         S L. Graham|     845|\n",
      "|D Maio;M R. Scala...|     910|\n",
      "|         Pamela Zave|     975|\n",
      "|G. Salton;E. Voor...|    1040|\n",
      "|Douglas D. Dunlop...|    1105|\n",
      "|Patrick Peruch;Vi...|    1170|\n",
      "| Robert J. Sternberg|    1235|\n",
      "|Curtis Roads;John...|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load paper_authors csv into schema\n",
    "paper_author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}paper_authors.csv', f'{SCHEMAS_FOLDER}paper_authors.csv')\n",
    "paper_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba688b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "paper_author_df = paper_author_df.withColumn(\"authors\", trim(paper_author_df.authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be0d595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- authors: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### verify schema\n",
    "paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e465de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special letters\n",
    "paper_author_df=clean_special_letters(paper_author_df, 'authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "141e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DELETE - ?\n",
    "### check if authors are missing as well for the ids whose title was missing in paper_df\n",
    "### for rows in paper_author_df.select(\"authors\",\"paper_id\").collect():\n",
    "###    if rows[1] in null_paper_ids_list:\n",
    "###        print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbebb1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+\n",
      "|paper_id|author               |\n",
      "+--------+---------------------+\n",
      "|65      |K Devine             |\n",
      "|65      |F J. Smith           |\n",
      "|130     |J Wolff von Gudenberg|\n",
      "|195     |J. K. Reid           |\n",
      "|195     |A. Jennings          |\n",
      "|260     |William G. Golson    |\n",
      "|260     |William C. Rounds    |\n",
      "|325     |Stein Schjolberg     |\n",
      "|390     |W Ian Gasarch        |\n",
      "|390     |Steven Homer         |\n",
      "|455     |Sam Toueg            |\n",
      "|455     |zalp Babaoğlu        |\n",
      "|520     |Frederick H. Dill    |\n",
      "|520     |Satish Gupta         |\n",
      "|520     |Daniel T. Ling       |\n",
      "|520     |Richard E. Matick    |\n",
      "|585     |A. R. Calderbank     |\n",
      "|585     |E. G. Coffman, Jr.   |\n",
      "|585     |L. Flatto            |\n",
      "|650     |Uzi Vishkin          |\n",
      "+--------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split authors so we can have clean data and separate records { paper_id; author }\n",
    "unique_paper_author_df = paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"authors\"),\";\")).alias(\"author\"))\n",
    "\n",
    "unique_paper_author_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72771502",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"author\", trim(unique_paper_author_df.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7037057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9143e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_paper_author_df=clean_special_character(unique_paper_author_df, 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cf076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', lower(col('author')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b220b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 14:16:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:16:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+\n",
      "|paper_id|           author|count|\n",
      "+--------+-----------------+-----+\n",
      "| 1523221|     dongkun shin|    4|\n",
      "| 2059316|    han chuanfeng|    3|\n",
      "| 2040206|     mingshu wang|    3|\n",
      "| 1202294|        n. sharma|    3|\n",
      "| 2042230|          lu leng|    3|\n",
      "| 2040206|     anchun cheng|    3|\n",
      "| 1070921|     joseph turow|    2|\n",
      "|  384591| simon st laurent|    2|\n",
      "| 1936484|    jiangxia duan|    2|\n",
      "| 1070928|  federico rajola|    2|\n",
      "| 1778146|  luis m. vaquero|    2|\n",
      "| 1867844|m. h. chehreghani|    2|\n",
      "| 1612982|       a. mammoli|    2|\n",
      "| 1070951| alexander horsch|    2|\n",
      "|  393283|  jeffrey richter|    2|\n",
      "| 1058622|  yehuda e. kalay|    2|\n",
      "| 1065597|       philip bos|    2|\n",
      "| 1069185|    danica kragic|    2|\n",
      "| 1069190|    mick kerrigan|    2|\n",
      "| 1070401|    arieh iserles|    2|\n",
      "+--------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:==========================>                                (4 + 5) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows:\n",
    "unique_paper_author_df \\\n",
    "    .groupby(['paper_id', 'author']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()\n",
    "\n",
    "### drop duplicate rows since here we need unique paper-author relation\n",
    "unique_paper_author_df = unique_paper_author_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41e1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|paper_id|        name|\n",
      "+--------+------------+\n",
      "|    1821|        suri|\n",
      "|    3582|    williams|\n",
      "|    8388|        huet|\n",
      "|    8581|    stoddart|\n",
      "|   11188|        maio|\n",
      "|   11703|      landau|\n",
      "|   11831|      reeves|\n",
      "|   13267|     searles|\n",
      "|   16580|      mettke|\n",
      "|   16965|schuitemaker|\n",
      "|   18077|      buxton|\n",
      "|   18141|  hemmerling|\n",
      "|   18208|  linebarger|\n",
      "|   18530|      millen|\n",
      "|   19959|         jr.|\n",
      "|   20152|      soupos|\n",
      "|   25486|      mazaud|\n",
      "|   25614|      mccain|\n",
      "|   26522| jagannathan|\n",
      "|   26783|       sheil|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### split author-name so we keep only the surname\n",
    "### This decision was made because there are a lot of disrepancies in full names,\n",
    "### and later on we need the clean and nice surnames for correct joining of the tables by paper_id + surname.\n",
    "unique_paper_author_cleaned_df = unique_paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.trim(F.element_at (F.split(F.col(\"author\"),\" \"),-1)).alias('name'))\n",
    "\n",
    "unique_paper_author_cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check how many entries there are in unique_paper_author_cleaned_df\n",
    "unique_paper_author_cleaned_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af545918",
   "metadata": {},
   "source": [
    "# Clean and Load Authors df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8661121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/authors.csv, schema path: ./schemas/author.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('citation_count', 'Integer'), ('h_index', 'Integer'), ('name', 'String'), ('paper_count', 'Integer')]\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|author_id|citation_count|h_index|                name|paper_count|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|       17|             0|      0|     J. Michael Howe|          1|\n",
      "|       34|             0|      0|        Haitham Gabr|          2|\n",
      "|       51|             4|      1|         Emma Tonkin|          8|\n",
      "|       68|             1|      1|        Woochul Shin|          4|\n",
      "|       85|             0|      0|           S Improta|          1|\n",
      "|      102|             8|      2|       Richard Ferri|          5|\n",
      "|      119|             0|      0|            Qing Liu|          1|\n",
      "|      136|             0|      0|      Artur Gramacki|          2|\n",
      "|      153|             0|      0|Olumuyiwa Oluwasanmi|          2|\n",
      "|      170|             0|      0|    Josef Willenborg|          1|\n",
      "|      187|             0|      0|            Qing Wei|          1|\n",
      "|      204|             4|      1|Jurey Ivanovich Z...|          1|\n",
      "|      221|            13|      1|             Anny Ng|          1|\n",
      "|      238|             2|      1|    Nikos B. Pronios|          3|\n",
      "|      255|             0|      0| Lourdes Fraga Alman|          1|\n",
      "|      272|             2|      1|       Junji Nishino|          7|\n",
      "|      289|             0|      0|       L. Dascalescu|          2|\n",
      "|      306|             0|      0|    Masakazu Nishino|          1|\n",
      "|      323|             4|      1|    Jean-Rémi Duquet|          2|\n",
      "|      340|             1|      1|     Brian A. Canada|          2|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load author csv into schema\n",
    "author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}authors.csv', f'{SCHEMAS_FOLDER}author.csv')\n",
    "author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d7cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove spaces from values of the column\n",
    "author_df = author_df.withColumn(\"name\", trim(author_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b8eff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+----+-----------+\n",
      "|author_id|citation_count|h_index|name|paper_count|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "|        0|             2|      2|   3|          2|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:=====================>                                    (3 + 5) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for nonsense null data (filtering will be done later)\n",
    "null_values_author_df = author_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns])\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e750c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill empty paper_count, citation_count, h_index to 0 (just one author)\n",
    "author_df=author_df.na.fill(value=0, subset='paper_count')\n",
    "author_df=author_df.na.fill(value=0, subset='citation_count')\n",
    "author_df=author_df.na.fill(value=0, subset='h_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a733b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters like í, â, é\n",
    "author_df=clean_special_letters(author_df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cf02fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "author_df=clean_special_character(author_df,'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "948b875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "author_df=author_df.withColumn('name', lower(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece8ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|author_id|count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate author_ids\n",
    "author_df.groupby(['author_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145eb93",
   "metadata": {},
   "source": [
    "# Join author and paper dataframes to ensure consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4d547",
   "metadata": {},
   "source": [
    "Load and clean Author2Paper (from the supplement txt file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16366740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('index', 'Integer'), ('author_id', 'Integer'), ('paper_id', 'Integer'), ('author_position', 'Integer')]\n"
     ]
    }
   ],
   "source": [
    "### load paper_author_id csv into schema\n",
    "dtypes = pd.read_csv('./schemas/paper_author_id.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "author_id_2_paper_id_df = spark.read.options(delimiter='\\t').csv('./assets/AMiner-Author2Paper.txt', header=False,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c9d84a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:=======>                                                  (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5192998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are\n",
    "author_id_2_paper_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81c69330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 14:18:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|author_id|paper_id|count|\n",
      "+---------+--------+-----+\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicates between paper_id and author_id\n",
    "author_id_2_paper_id_df \\\n",
    "    .groupby(['author_id', 'paper_id']) \\\n",
    "    .count().where('count > 1') \\\n",
    "    .sort('count', ascending=False).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e84081c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the suplementary author_id_2_paper_id_df df with author_df\n",
    "author_id_2_paper_id_extended_df = author_id_2_paper_id_df.join(author_df, 'author_id', 'left').drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09d402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the author-name to keep only the surname ---> cleaning data\n",
    "author_id_2_paper_id_cleaned_df = author_id_2_paper_id_extended_df \\\n",
    "    .select( \\\n",
    "        F.col(\"paper_id\"), \\\n",
    "        F.col(\"author_id\"), \\\n",
    "        F.col(\"citation_count\"), \\\n",
    "        F.col(\"h_index\"), \\\n",
    "        F.col(\"paper_count\"), \\\n",
    "        F.trim(F.element_at(F.split(F.col(\"name\"),\" \"),-1)).alias('name') \\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad95fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the cleaned paper_2_author_cleaned_df to unique_paper_author_cleaned_df\n",
    "final_paper_author_id_df = unique_paper_author_cleaned_df \\\n",
    "    .join(author_id_2_paper_id_cleaned_df, ['name', 'paper_id'], 'inner') \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37905ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292.095s][warning][gc,alloc] Executor task launch worker for task 2.0 in stage 55.0 (TID 194): Retried waiting for GCLocker too often allocating 1048578 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:54:32 WARN TaskMemoryManager: Failed to allocate a page (8388608 bytes), try again.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5114352"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are in the final dataframe\n",
    "final_paper_author_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_paper_author_id_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7b6c",
   "metadata": {},
   "source": [
    "# Load and clean Affiliations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a7d4c21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/affiliations.csv, schema path: ./schemas/affiliation.csv\n",
      "Types from schema: [('affiliations', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation csv into schema\n",
    "affiliation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}affiliations.csv', f'{SCHEMAS_FOLDER}affiliation.csv')\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bab85ad4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### remove leading and trailing spaces\n",
    "affiliation_df = affiliation_df.withColumn(\"affiliations\", trim(affiliation_df.affiliations))\n",
    "\n",
    "affiliation_df.printSchema()\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af1159c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|affiliations|paper_id|\n",
      "+------------+--------+\n",
      "|       37499|       0|\n",
      "+------------+--------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:==============>                                           (2 + 6) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values in the affiliations column\n",
    "### we can see, that there are many rows with null affiliations\n",
    "### these rows will be cleaned up further\n",
    "null_values_affiliations=affiliation_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in affiliation_df.columns])\n",
    "print(null_values_affiliations.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9b5fdc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### This df will in the end be used to count papers per unique affiliation,\n",
    "### so if the affiliation is missing, it doesnt make sense to keep the row\n",
    "### Decision: drop all rows where affiliation is null\n",
    "affiliation_df=affiliation_df.na.drop(how=\"any\", subset=['affiliations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8504dda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------+\n",
      "|paper_id|affiliation                                           |\n",
      "+--------+------------------------------------------------------+\n",
      "|65      |The Queen's University of Belfast, Belfast, UK        |\n",
      "|65      |The Queen's University of Belfast, Belfast, UK        |\n",
      "|130     |Univ. of Karlsruhe, Karlsruhe, West Germany           |\n",
      "|195     |AERE Harwell Laboratory, Oxon, UK                     |\n",
      "|195     |Queen's Univ., Belfast, Northern Ireland              |\n",
      "|260     |University of Michigan, Ann Arbor, MI                 |\n",
      "|260     |University of Michigan, Ann Arbor, MI                 |\n",
      "|325     |Oslo politikammer, Oslo, Norway                       |\n",
      "|390     |Harvard Univ., Cambridge, MA                          |\n",
      "|390     |Boston Univ., Boston, MA                              |\n",
      "|455     |Cornell Univ., Ithaca, NY                             |\n",
      "|455     |Cornell Univ., Ithaca, NY                             |\n",
      "|520     |IBM General Technology Division, Hopewell Junction, NY|\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|585     |-                                                     |\n",
      "|585     |-                                                     |\n",
      "|585     |-                                                     |\n",
      "|650     |New York Univ., New York, NY                          |\n",
      "+--------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split affiliations so we can have clean data and separate records { paper_id; affiliation }\n",
    "unique_affiliations_df = affiliation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"affiliations\"),\";\")) \\\n",
    "    .alias(\"affiliation\"))\n",
    "unique_affiliations_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3195d7d4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for special nonsense characters \"-\" and filter them out\n",
    "### If the affiliation is missing, there is no point of keeping the rows\n",
    "unique_affiliations_df = unique_affiliations_df.where(unique_affiliations_df.affiliation != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3c444",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62eeaed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df \\\n",
    "    .groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3fbf49b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique affiliations\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e55ad40",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_affiliations_df = clean_special_character(unique_affiliations_df, 'affiliation')\n",
    "### remove special letters\n",
    "unique_affiliations_df = clean_special_letters(unique_affiliations_df, 'affiliation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "042f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase the affiliation col values\n",
    "unique_affiliations_df = unique_affiliations_df.withColumn('affiliation', lower(col('affiliation')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d2b75",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df.groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "855886fd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0083171",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### filter out affiliations that are not part of the final_paper_author_id_df\n",
    "final_affiliations_df = unique_affiliations_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('affiliation')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1855220",
   "metadata": {},
   "source": [
    "# Load and clean Publication_venues df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d25f590",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/publication_venues.csv, schema path: ./schemas/publication_venues.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('publication_venue', 'String')]\n"
     ]
    }
   ],
   "source": [
    "### load publication_venues into schema\n",
    "publication_venue_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}publication_venues.csv', f'{SCHEMAS_FOLDER}publication_venues.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "026166d7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|   publication_venue|\n",
      "+--------+--------------------+\n",
      "|      65|Information Techn...|\n",
      "|     130|Proc. of the symp...|\n",
      "|     195|ACM Transactions ...|\n",
      "|     260|Information and C...|\n",
      "|     325|Computers and pen...|\n",
      "|     390|Information and C...|\n",
      "|     455|SIAM Journal on C...|\n",
      "|     520|IBM Journal of Re...|\n",
      "|     585|Journal of the AC...|\n",
      "|     650|Theoretical Compu...|\n",
      "|     715|            Computer|\n",
      "|     780|ACM Transactions ...|\n",
      "|     845|Methods and tools...|\n",
      "|     910|Information Proce...|\n",
      "|     975|ACM Transactions ...|\n",
      "|    1040|Information Proce...|\n",
      "|    1105|ACM Transactions ...|\n",
      "|    1170|Proc. of the 2nd ...|\n",
      "|    1235|Proc. of the inte...|\n",
      "|    1300|Foundations of co...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### trim publication_venue\n",
    "publication_venue_df = publication_venue_df.withColumn( \\\n",
    "    \"publication_venue\", trim(publication_venue_df.publication_venue) \\\n",
    ")\n",
    "publication_venue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6daa39b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values inside publication venues dataframe\n",
    "null_values_publication_venue = publication_venue_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in publication_venue_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b4e8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|paper_id|publication_venue|\n",
      "+--------+-----------------+\n",
      "|       0|              148|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_values_publication_venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eef3dd2b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop null values \n",
    "publication_venue_df=publication_venue_df.na.drop(how=\"any\", subset=['publication_venue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0c6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "publication_venue_df \\\n",
    "    .groupby(['paper_id', 'publication_venue']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a55ddef7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### join publication_venue_df with final_paper_author_id_df\n",
    "### to remove publication venues of paper ids which are not part of final_paper_author_id_df\n",
    "final_publication_venues_df = publication_venue_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('publication_venue')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6ec60",
   "metadata": {},
   "source": [
    "# Load and clean Citations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d24ec61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/citations.csv, schema path: ./schemas/citations.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('ref_ids', 'String')]\n",
      "+--------+--------------------+\n",
      "|paper_id|             ref_ids|\n",
      "+--------+--------------------+\n",
      "|      65|                null|\n",
      "|     130|                null|\n",
      "|     195|317424;317425;317573|\n",
      "|     260|                null|\n",
      "|     325|                null|\n",
      "|     390|                null|\n",
      "|     455|                null|\n",
      "|     520|       318368;323493|\n",
      "|     585|                null|\n",
      "|     650|                null|\n",
      "|     715|                null|\n",
      "|     780|318420;319233;319...|\n",
      "|     845|                null|\n",
      "|     910|                null|\n",
      "|     975|67604;318882;3718...|\n",
      "|    1040|                null|\n",
      "|    1105|289087;318014;318...|\n",
      "|    1170|                null|\n",
      "|    1235|                null|\n",
      "|    1300|                null|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation csv into schema\n",
    "citation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}citations.csv', f'{SCHEMAS_FOLDER}citations.csv')\n",
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "509f0ac2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "citation_df = citation_df.withColumn(\"ref_ids\", trim(citation_df.ref_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30286e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show how many paper ids are present in citation_df\n",
    "citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe6f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "citation_df.groupby(['paper_id', 'ref_ids']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5c54e1c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|paper_id|ref_id|\n",
      "+--------+------+\n",
      "|65      |null  |\n",
      "|130     |null  |\n",
      "|195     |317424|\n",
      "|195     |317425|\n",
      "|195     |317573|\n",
      "|260     |null  |\n",
      "|325     |null  |\n",
      "|390     |null  |\n",
      "|455     |null  |\n",
      "|520     |318368|\n",
      "|520     |323493|\n",
      "|585     |null  |\n",
      "|650     |null  |\n",
      "|715     |null  |\n",
      "|780     |318420|\n",
      "|780     |319233|\n",
      "|780     |319290|\n",
      "|780     |319579|\n",
      "|780     |320813|\n",
      "|845     |null  |\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split citations so we can have clean data and seperate records {paper_id; ref_id}\n",
    "unique_citation_df = citation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode_outer(F.split(F.col(\"ref_ids\"),\";\")).alias(\"ref_id\"))\n",
    "unique_citation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691822fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the number of unique papers in unique_citation_df dataframe\n",
    "unique_citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32d01f0e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\", trim(unique_citation_df.ref_id))\n",
    "### change data type of ref_id to Integer\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\",unique_citation_df[\"ref_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb73e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_citation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89c12f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for duplicate rows\n",
    "unique_citation_df.groupby(['paper_id', 'ref_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da1d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check whether some papers have null ref_ids\n",
    "### (those papers will still be kept in the dataframe for consistency)\n",
    "unique_citation_df.filter(unique_citation_df['ref_id'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c207d516",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### clean up ref ids if their paper_id is not a part of final_paper_author_id_df\n",
    "final_citation_df = unique_citation_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('ref_id')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066b305",
   "metadata": {},
   "source": [
    "# Load and Research_interests in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "065c387e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/research_interests.csv, schema path: ./schemas/research_interests.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('research_interests', 'String')]\n"
     ]
    }
   ],
   "source": [
    "### load research_interests csv into schema\n",
    "research_interests_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}research_interests.csv', f'{SCHEMAS_FOLDER}research_interests.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "296ee220",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "research_interests_df = research_interests_df \\\n",
    "    .withColumn(\"research_interests\", trim(research_interests_df.research_interests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b967513d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 76:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|author_id|research_interests|\n",
      "+---------+------------------+\n",
      "|        0|             15398|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 76:=======>                                                  (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values in the affiliations column\n",
    "research_interests_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in research_interests_df.columns]).show()\n",
    "### drop null values (it is safe since we dont need research_interests for any computation)\n",
    "research_interests_df = research_interests_df.na.drop(how=\"any\", subset=['research_interests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_interests_df.printSchema()\n",
    "research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16cf3d09",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------------+\n",
      "|author_id|research_interest                        |\n",
      "+---------+-----------------------------------------+\n",
      "|17       |HIV disease                              |\n",
      "|17       |Internet resource                        |\n",
      "|17       |World-Wide Web                           |\n",
      "|17       |clinical management                      |\n",
      "|34       |associate polynomial term                |\n",
      "|34       |bivariate polynomial                     |\n",
      "|34       |difficult computational problem          |\n",
      "|34       |novel polynomial                         |\n",
      "|34       |polynomial multiplication problem        |\n",
      "|34       |polynomial term                          |\n",
      "|34       |reachability problem                     |\n",
      "|34       |Probabilistic Reachability               |\n",
      "|34       |Reachability analysis                    |\n",
      "|34       |better time complexity                   |\n",
      "|51       |metadata element                         |\n",
      "|51       |metadata record                          |\n",
      "|51       |Dublin Core metadata                     |\n",
      "|51       |PaperBase extracts metadata              |\n",
      "|51       |Semi automated metadata extraction       |\n",
      "|51       |applicationAs metadata providers increase|\n",
      "+---------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split research interests\n",
    "### so we can have clean data and separate records { paper_id; research_interest }\n",
    "unique_research_interests_df = research_interests_df \\\n",
    "    .select(F.col(\"author_id\"), F.explode(F.split(F.col(\"research_interests\"),\";\")) \\\n",
    "    .alias(\"research_interest\"))\n",
    "\n",
    "unique_research_interests_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00ef0111",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn(\"research_interest\", trim(unique_research_interests_df.research_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cacff62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### clean special characters and special letters\n",
    "unique_research_interests_df = clean_special_character(unique_research_interests_df, 'research_interest')\n",
    "unique_research_interests_df = clean_special_letters(unique_research_interests_df, 'research_interest')\n",
    "### lowercase research_interests\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn('research_interest', lower(col('research_interest')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for duplicate rows:\n",
    "unique_research_interests_df \\\n",
    "    .groupby(['author_id', 'research_interest']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d855bc9f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_research_interests_df=unique_research_interests_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c32ed493",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# clean up research interests if their author id is not a part of final_paper_author_id_df\n",
    "final_research_interests_df = unique_research_interests_df \\\n",
    "    .join(final_paper_author_id_df, ['author_id'], 'inner') \\\n",
    "    .select(F.col('author_id'), F.col('research_interest')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10818814",
   "metadata": {},
   "source": [
    "# Run Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36310d",
   "metadata": {},
   "source": [
    "### Q1.2 Compute paper count per unique affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08f3126d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "paper_count_per_affiliation_df = final_affiliations_df \\\n",
    "    .groupBy('affiliation') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"papers_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ce4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### count the number of results\n",
    "paper_count_per_affiliation_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041807a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_count_per_affiliation_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc2f1",
   "metadata": {},
   "source": [
    "### Q1.1 Validate precomputed paper counts, citation (ref) counts and h-indexes (per author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb36be",
   "metadata": {},
   "source": [
    "#### How to compute h-index for a specific author\n",
    "1. Retrieve all publications of the author\n",
    "2. Calculate the number of references per publication\n",
    "3. Sort the results in descending order\n",
    "4. Find a threshold N, where N top publications have at least N references each. N is the h-index of the author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82c4fe33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 1-2 Calculate the number of references per publication\n",
    "refs_per_paper_count_df = final_citation_df \\\n",
    "    .groupBy(\"paper_id\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\",\"paper_references\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94d3e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2029262"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_per_paper_count_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d2dc42a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### 3 Join [papers per author] with [references per paper] and sort the results in descending order\n",
    "author_papers_with_ref_count = final_paper_author_id_df.join(refs_per_paper_count_df, 'paper_id') \\\n",
    "    .sort(col(\"paper_references\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_papers_with_ref_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "656a90c3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### add index column to table to ease h-index calculation\n",
    "window = Window.partitionBy(author_papers_with_ref_count['author_id']) \\\n",
    "    .orderBy(desc(\"paper_references\"), desc(\"paper_id\"))\n",
    "\n",
    "indexed_grouped_papers_df = author_papers_with_ref_count.select('*', rank().over(window).alias('index'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "670dbb5c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_papers = indexed_grouped_papers_df \\\n",
    "    .withColumn(\"possible_h_index\", \\\n",
    "                when( \\\n",
    "                    indexed_grouped_papers_df.index <= indexed_grouped_papers_df.paper_references, \\\n",
    "                    indexed_grouped_papers_df.index \\\n",
    "                    ).otherwise(0) \\\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_indexed_papers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8143a56",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_grouped_by_author_papers_df = h_indexed_papers.groupBy('author_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53fa8f6e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_aggregated_papers_df = h_indexed_grouped_by_author_papers_df.agg( \\\n",
    "        F.count(\"paper_id\").alias(\"validated_paper_count\"),\n",
    "        F.sum(\"paper_references\").alias(\"validated_citation_count\"),\n",
    "        F.max(\"possible_h_index\").alias(\"validated_h_index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5123f",
   "metadata": {},
   "source": [
    "#### Computed results for `validated_paper_count`, `validated_paper_count` and `validated_h_index`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b40ed9",
   "metadata": {},
   "source": [
    "__Final resulting dataframe is unique_authors_with_validated_cols_df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae0b318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join the computation results with author dataframe\n",
    "### to be able to compare received values with the precomputed values\n",
    "unique_authors_with_validated_cols_df = h_indexed_aggregated_papers_df.join(author_df, 'author_id', 'inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61de01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### count the number of entries\n",
    "unique_authors_with_validated_cols_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_with_validated_cols_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac42142",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed h-indexes differ from the validated h-indexes\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_h_index\"] != unique_authors_with_validated_cols_df[\"h_index\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed author citation counts differ from the validated citation counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_citation_count\"] != unique_authors_with_validated_cols_df[\"citation_count\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed author paper counts differ from the validated paper counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_paper_count\"] != unique_authors_with_validated_cols_df[\"paper_count\"]\n",
    "unique_authors_with_validated_cols_df.filter(filter_condition).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a64b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9da713f0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Save cleaned & computed data into the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f3a89293",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DATA_FOLDER = './assets/cleanedDFsData/'\n",
    "def saveDFIntoCSVFolder(df, folderName):\n",
    "    # Save data to csv file\n",
    "    df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(f'{CLEAN_DATA_FOLDER}{folderName}')\n",
    "def moveFileToCorrectFolder(folderName):\n",
    "    filename = glob.glob(f'{CLEAN_DATA_FOLDER}{folderName}/*.csv')[0]\n",
    "    shutil.move(filename, f'{CLEAN_DATA_FOLDER}{folderName}_ds.csv')\n",
    "    \n",
    "# After saving of the data to csv we have to call moveFileToCorrectFolder,\n",
    "# because saveDFIntoCSVFolder actually saves the data into the folder with a csv file inside.\n",
    "# moveFileToCorrectFolder moves the file to the correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74320b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving cleaned & unique paper author data\n",
    "saveDFIntoCSVFolder(final_paper_author_id_df, 'paper_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e876289",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('paper_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8848c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 15:18:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 15:18:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Saving cleaned & unique affiliations data with computed paper_count\n",
    "saveDFIntoCSVFolder(paper_count_per_affiliation_df, 'affiliation_paper_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "169ac7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('affiliation_paper_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29318e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Saving cleaned & unique affiliations data with computed paper_count\n",
    "saveDFIntoCSVFolder(final_affiliations_df, 'affiliations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e7a96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('affiliations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cleaned & unique publication venues data \n",
    "saveDFIntoCSVFolder(final_publication_venues_df, 'publication_venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4e35aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('publication_venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6f8885ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Saving cleaned & unique citations data\n",
    "saveDFIntoCSVFolder(final_citation_df, 'citations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "983d928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('citations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "26e62696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Saving cleaned & computed & research interests data\n",
    "saveDFIntoCSVFolder(final_research_interests_df, 'research_interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae0c1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('research_interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8332ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
