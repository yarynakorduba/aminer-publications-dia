{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "# *                   _oo0oo_\n",
    "# *                  o8888888o\n",
    "# *                  88\" . \"88\n",
    "# *                  (| -_- |)\n",
    "# *                  0\\  =  /0\n",
    "# *                ___/`---'\\___\n",
    "# *              .' \\\\|     |// '.\n",
    "# *             / \\\\|||  :  |||// \\\n",
    "# *            / _||||| -:- |||||- \\\n",
    "# *           |   | \\\\\\  -  /// |   |\n",
    "# *           | \\_|  ''\\---/''  |_/ |\n",
    "# *           \\  .-\\__  '-'  ___/-. /\n",
    "# *         ___'. .'  /--.--\\  `. .'___\n",
    "# *      .\"\" '<  `.___\\_<|>_/___.' >' \"\".\n",
    "# *     | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
    "# *     \\  \\ `_.   \\_ __\\ /__ _/   .-` /  /\n",
    "# * =====`-.____`.___ \\_____/___.-`___.-'=====\n",
    "# *                   `=---='\n",
    "# *\n",
    "# *\n",
    "# * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# *\n",
    "# *   Buddha blesses your code to be bug free\n",
    "# */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4071cf9f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7626e981",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from helpers import createDFFromFileAndSchema, clean_special_letters, clean_special_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed236bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae6ee91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/21 17:44:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('Clean up the data and perform the queries').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb68a75d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://o-152.vc-graz.ac.at:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Clean up the data and perform the queries</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7a1cba11c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062ec083",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMAS_FOLDER = './schemas/'\n",
    "FILES_FOLDER = './assets/parsedData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92dff5",
   "metadata": {},
   "source": [
    "# Load and clean Paper DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f871ce",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/papers.csv, schema path: ./schemas/paper.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|Direct file organ...|1984|\n",
      "|     130|An introduction t...|1983|\n",
      "|     195|On solving almost...|1984|\n",
      "|     260|Connections betwe...|1984|\n",
      "|     325|Computers and pen...|1984|\n",
      "|     390|Relativizations c...|1984|\n",
      "|     455|On the optimum ch...|1984|\n",
      "|     520|All points addres...|1984|\n",
      "|     585|Optimum Head Sepa...|1984|\n",
      "|     650|A parallel-design...|1984|\n",
      "|     715|Computer - IEEE C...|1984|\n",
      "|     780|Experience with G...|1984|\n",
      "|     845|Code generation a...|1984|\n",
      "|     910|On estimating acc...|1984|\n",
      "|     975|A distributed alt...|1985|\n",
      "|    1040|A comparison of t...|1984|\n",
      "|    1105|Generalizing spec...|1985|\n",
      "|    1170|Real time graphic...|1984|\n",
      "|    1235|Common and uncomm...|1984|\n",
      "|    1300|Foundations of co...|1985|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load paper csv into schema\n",
    "paper_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}papers.csv', f'{SCHEMAS_FOLDER}paper.csv')\n",
    "paper_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a7cc",
   "metadata": {},
   "source": [
    "### Data cleaning for paper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3054c0b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove spaces from values of the columns\n",
    "paper_df = paper_df.withColumn(\"title\", trim(paper_df.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285bb60f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check for the correct data types\n",
    "paper_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fc4cf2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for nonsense null data\n",
    "null_values_paper_df = paper_df.select(\n",
    "    [count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_df.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2652fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+\n",
      "|paper_id|title|year|\n",
      "+--------+-----+----+\n",
      "|       0|   24| 157|\n",
      "+--------+-----+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_values_paper_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbdfb814",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### after checking the below dataframes,\n",
    "### we have seen that all papers, whose title is missing, have the authors (besides paper_id = 748056)\n",
    "### Decision: fill missing titles with: \"Missing Title\"\n",
    "\n",
    "paper_df=paper_df.na.fill('Missing Title', ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f62d8e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "paper_df=clean_special_character(paper_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b78e5ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+-------------------+\n",
      "|paper_id|               title|year|Duplicate_indicator|\n",
      "+--------+--------------------+----+-------------------+\n",
      "|       3|The verification ...|1984|                  0|\n",
      "|       4|Another view of f...|1984|                  0|\n",
      "|       5|Entityrelationshi...|1984|                  0|\n",
      "|      10|The ThreeMachine ...|1984|                  0|\n",
      "|      13|The VLSI Complexi...|1984|                  0|\n",
      "|      14|Computability wit...|1984|                  0|\n",
      "|      16|The implication p...|1984|                  0|\n",
      "|      22|On two more Eigen...|1984|                  0|\n",
      "|      27|Frame theory and ...|1984|                  0|\n",
      "|      30|Stationary wave s...|1984|                  0|\n",
      "|      36|On the design of ...|1983|                  0|\n",
      "|      41|ELSA  an extensib...|1983|                  0|\n",
      "|      44|ADA Concurrent Pr...|1984|                  0|\n",
      "|      52|Automated microco...|1984|                  0|\n",
      "|      58|The application o...|1983|                  0|\n",
      "|      61|The DISS methodol...|1984|                  0|\n",
      "|      62|Information Techn...|1984|                  0|\n",
      "|      66|Soft evaluation o...|1984|                  0|\n",
      "|      75|A methodology for...|1984|                  0|\n",
      "|      77|The influence of ...|1984|                  0|\n",
      "+--------+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|paper_id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate rows\n",
    "paper_df.join(\n",
    "    paper_df\n",
    "        .groupBy(paper_df.columns) \\\n",
    "        .agg((F.count(\"*\")>1) \\\n",
    "        .cast(\"int\") \\\n",
    "        .alias(\"Duplicate_indicator\")), \\\n",
    "        on=paper_df.columns,how=\"inner\") \\\n",
    "    .show()\n",
    "### from the dataframe view, we can see that there are no duplicates\n",
    "paper_df.groupby(['paper_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b03384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2092356"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check for the number of paper entries\n",
    "paper_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f7c3d",
   "metadata": {},
   "source": [
    "# Load and clean paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82641fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/paper_authors.csv, schema path: ./schemas/paper_authors.csv\n",
      "Types from schema: [('authors', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|             authors|paper_id|\n",
      "+--------------------+--------+\n",
      "| K Devine;F J. Smith|      65|\n",
      "|J Wolff von Guden...|     130|\n",
      "|J. K. Reid;A. Jen...|     195|\n",
      "|William G. Golson...|     260|\n",
      "|    Stein Schjolberg|     325|\n",
      "|W Ian Gasarch;Ste...|     390|\n",
      "|Sam Toueg;Özalp B...|     455|\n",
      "|Frederick H. Dill...|     520|\n",
      "|A. R. Calderbank;...|     585|\n",
      "|         Uzi Vishkin|     650|\n",
      "|      Stephen S. Yau|     715|\n",
      "|Michael D. Schroe...|     780|\n",
      "|         S L. Graham|     845|\n",
      "|D Maio;M R. Scala...|     910|\n",
      "|         Pamela Zave|     975|\n",
      "|G. Salton;E. Voor...|    1040|\n",
      "|Douglas D. Dunlop...|    1105|\n",
      "|Patrick Peruch;Vi...|    1170|\n",
      "| Robert J. Sternberg|    1235|\n",
      "|Curtis Roads;John...|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load paper_authors csv into schema\n",
    "paper_author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}paper_authors.csv', f'{SCHEMAS_FOLDER}paper_authors.csv')\n",
    "paper_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba688b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "paper_author_df = paper_author_df.withColumn(\"authors\", trim(paper_author_df.authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0d595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- authors: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### verify schema\n",
    "paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e465de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special letters\n",
    "paper_author_df=clean_special_letters(paper_author_df, 'authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbebb1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+\n",
      "|paper_id|author               |\n",
      "+--------+---------------------+\n",
      "|65      |K Devine             |\n",
      "|65      |F J. Smith           |\n",
      "|130     |J Wolff von Gudenberg|\n",
      "|195     |J. K. Reid           |\n",
      "|195     |A. Jennings          |\n",
      "|260     |William G. Golson    |\n",
      "|260     |William C. Rounds    |\n",
      "|325     |Stein Schjolberg     |\n",
      "|390     |W Ian Gasarch        |\n",
      "|390     |Steven Homer         |\n",
      "|455     |Sam Toueg            |\n",
      "|455     |zalp Babaoğlu        |\n",
      "|520     |Frederick H. Dill    |\n",
      "|520     |Satish Gupta         |\n",
      "|520     |Daniel T. Ling       |\n",
      "|520     |Richard E. Matick    |\n",
      "|585     |A. R. Calderbank     |\n",
      "|585     |E. G. Coffman, Jr.   |\n",
      "|585     |L. Flatto            |\n",
      "|650     |Uzi Vishkin          |\n",
      "+--------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split authors so we can have clean data and separate records { paper_id; author }\n",
    "unique_paper_author_df = paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"authors\"),\";\")).alias(\"author\"))\n",
    "\n",
    "unique_paper_author_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72771502",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"author\", trim(unique_paper_author_df.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7037057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9143e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_paper_author_df=clean_special_character(unique_paper_author_df, 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09cf076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', lower(col('author')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b220b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 17:46:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:46:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:47:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|paper_id|              author|count|\n",
      "+--------+--------------------+-----+\n",
      "| 1523221|        dongkun shin|    4|\n",
      "| 2040206|        anchun cheng|    3|\n",
      "| 2059316|       han chuanfeng|    3|\n",
      "| 1202294|            n sharma|    3|\n",
      "| 2042230|             lu leng|    3|\n",
      "| 2040206|        mingshu wang|    3|\n",
      "|  390835|       jeff van west|    2|\n",
      "| 1900218|        dongqiang xu|    2|\n",
      "| 1423835|deogratias harori...|    2|\n",
      "|  412060|microsoft corpora...|    2|\n",
      "| 1221094|           w penczek|    2|\n",
      "| 1986411| vishanth weerakkody|    2|\n",
      "| 1668760|       pradeep kumar|    2|\n",
      "|  817145|     michael j quinn|    2|\n",
      "| 1498645|   emily s patterson|    2|\n",
      "| 1503841|     a a khoroshilov|    2|\n",
      "| 1423827|            xin geng|    2|\n",
      "| 1198797|    alladi venkatesh|    2|\n",
      "| 1221362|        steve clarke|    2|\n",
      "| 1899891|        wang rongxia|    2|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows:\n",
    "unique_paper_author_df \\\n",
    "    .groupby(['paper_id', 'author']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()\n",
    "\n",
    "### drop duplicate rows since here we need unique paper-author relation\n",
    "unique_paper_author_df = unique_paper_author_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41e1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|paper_id|     name|\n",
      "+--------+---------+\n",
      "|     470|soderlund|\n",
      "|    1821|     suri|\n",
      "|    1895|     plum|\n",
      "|    2145|  chamoux|\n",
      "|    3523| cardelli|\n",
      "|    3584|    egghe|\n",
      "|    5083|prodinger|\n",
      "|    5151|   verity|\n",
      "|    7290|  swieten|\n",
      "|    8388|     huet|\n",
      "|    8581| stoddart|\n",
      "|    9505| korfhage|\n",
      "|   10149| phillips|\n",
      "|   10610|     saad|\n",
      "|   11188|     maio|\n",
      "|   11391|    tracz|\n",
      "|   11831|   reeves|\n",
      "|   12039|       li|\n",
      "|   12427|     kitt|\n",
      "|   12561|overgaard|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### split author-name so we keep only the surname\n",
    "### This decision was made because there are a lot of disrepancies in full names,\n",
    "### and later on we need the clean and nice surnames for correct joining of the tables by paper_id + surname.\n",
    "unique_paper_author_cleaned_df = unique_paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.trim(F.element_at (F.split(F.col(\"author\"),\" \"),-1)).alias('name'))\n",
    "\n",
    "unique_paper_author_cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b41b1bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5237608"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are in unique_paper_author_cleaned_df\n",
    "unique_paper_author_cleaned_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af545918",
   "metadata": {},
   "source": [
    "# Clean and Load Authors df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8661121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/authors.csv, schema path: ./schemas/author.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('citation_count', 'Integer'), ('h_index', 'Integer'), ('name', 'String'), ('paper_count', 'Integer')]\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|author_id|citation_count|h_index|                name|paper_count|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|       17|             0|      0|     J. Michael Howe|          1|\n",
      "|       34|             0|      0|        Haitham Gabr|          2|\n",
      "|       51|             4|      1|         Emma Tonkin|          8|\n",
      "|       68|             1|      1|        Woochul Shin|          4|\n",
      "|       85|             0|      0|           S Improta|          1|\n",
      "|      102|             8|      2|       Richard Ferri|          5|\n",
      "|      119|             0|      0|            Qing Liu|          1|\n",
      "|      136|             0|      0|      Artur Gramacki|          2|\n",
      "|      153|             0|      0|Olumuyiwa Oluwasanmi|          2|\n",
      "|      170|             0|      0|    Josef Willenborg|          1|\n",
      "|      187|             0|      0|            Qing Wei|          1|\n",
      "|      204|             4|      1|Jurey Ivanovich Z...|          1|\n",
      "|      221|            13|      1|             Anny Ng|          1|\n",
      "|      238|             2|      1|    Nikos B. Pronios|          3|\n",
      "|      255|             0|      0| Lourdes Fraga Alman|          1|\n",
      "|      272|             2|      1|       Junji Nishino|          7|\n",
      "|      289|             0|      0|       L. Dascalescu|          2|\n",
      "|      306|             0|      0|    Masakazu Nishino|          1|\n",
      "|      323|             4|      1|    Jean-Rémi Duquet|          2|\n",
      "|      340|             1|      1|     Brian A. Canada|          2|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load author csv into schema\n",
    "author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}authors.csv', f'{SCHEMAS_FOLDER}author.csv')\n",
    "author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15d7cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove spaces from values of the column\n",
    "author_df = author_df.withColumn(\"name\", trim(author_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b8eff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+----+-----------+\n",
      "|author_id|citation_count|h_index|name|paper_count|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "|        0|             2|      2|   3|          2|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 30:=============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for nonsense null data (filtering will be done later)\n",
    "null_values_author_df = author_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns])\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e750c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill empty paper_count, citation_count, h_index to 0 (just one author)\n",
    "author_df=author_df.na.fill(value=0, subset='paper_count')\n",
    "author_df=author_df.na.fill(value=0, subset='citation_count')\n",
    "author_df=author_df.na.fill(value=0, subset='h_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a733b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters like í, â, é\n",
    "author_df=clean_special_letters(author_df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cf02fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "author_df=clean_special_character(author_df,'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "948b875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "author_df=author_df.withColumn('name', lower(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece8ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|author_id|count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 35:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate author_ids\n",
    "author_df.groupby(['author_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145eb93",
   "metadata": {},
   "source": [
    "# Join author and paper dataframes to ensure consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4d547",
   "metadata": {},
   "source": [
    "Load and clean Author2Paper (from the supplement txt file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16366740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('index', 'Integer'), ('author_id', 'Integer'), ('paper_id', 'Integer'), ('author_position', 'Integer')]\n"
     ]
    }
   ],
   "source": [
    "### load paper_author_id csv into schema\n",
    "dtypes = pd.read_csv('./schemas/paper_author_id.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "author_id_2_paper_id_df = spark.read.options(delimiter='\\t').csv('./assets/AMiner-Author2Paper.txt', header=False,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c9d84a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5192998"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are\n",
    "author_id_2_paper_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81c69330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 17:50:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:51:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|author_id|paper_id|count|\n",
      "+---------+--------+-----+\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicates between paper_id and author_id\n",
    "author_id_2_paper_id_df \\\n",
    "    .groupby(['author_id', 'paper_id']) \\\n",
    "    .count().where('count > 1') \\\n",
    "    .sort('count', ascending=False).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e84081c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the suplementary author_id_2_paper_id_df df with author_df\n",
    "author_id_2_paper_id_extended_df = author_id_2_paper_id_df.join(author_df, 'author_id', 'left').drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09d402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the author-name to keep only the surname ---> cleaning data\n",
    "author_id_2_paper_id_cleaned_df = author_id_2_paper_id_extended_df \\\n",
    "    .select( \\\n",
    "        F.col(\"paper_id\"), \\\n",
    "        F.col(\"author_id\"), \\\n",
    "        F.col(\"citation_count\"), \\\n",
    "        F.col(\"h_index\"), \\\n",
    "        F.col(\"paper_count\"), \\\n",
    "        F.trim(F.element_at(F.split(F.col(\"name\"),\" \"),-1)).alias('name') \\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad95fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the cleaned paper_2_author_cleaned_df to unique_paper_author_cleaned_df\n",
    "final_paper_author_id_df = unique_paper_author_cleaned_df \\\n",
    "    .join(author_id_2_paper_id_cleaned_df, ['name', 'paper_id'], 'inner') \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7b6c",
   "metadata": {},
   "source": [
    "# Load and clean Affiliations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a7d4c21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/affiliations.csv, schema path: ./schemas/affiliation.csv\n",
      "Types from schema: [('affiliations', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation csv into schema\n",
    "affiliation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}affiliations.csv', f'{SCHEMAS_FOLDER}affiliation.csv')\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab85ad4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### remove leading and trailing spaces\n",
    "affiliation_df = affiliation_df.withColumn(\"affiliations\", trim(affiliation_df.affiliations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af1159c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|affiliations|paper_id|\n",
      "+------------+--------+\n",
      "|       37499|       0|\n",
      "+------------+--------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 79:===========================================>              (3 + 1) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values in the affiliations column\n",
    "### we can see, that there are many rows with null affiliations\n",
    "### these rows will be cleaned up further\n",
    "null_values_affiliations=affiliation_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in affiliation_df.columns])\n",
    "print(null_values_affiliations.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9b5fdc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### This df will in the end be used to count papers per unique affiliation,\n",
    "### so if the affiliation is missing, it doesnt make sense to keep the row\n",
    "### Decision: drop all rows where affiliation is null\n",
    "affiliation_df=affiliation_df.na.drop(how=\"any\", subset=['affiliations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8504dda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------+\n",
      "|paper_id|affiliation                                           |\n",
      "+--------+------------------------------------------------------+\n",
      "|65      |The Queen's University of Belfast, Belfast, UK        |\n",
      "|65      |The Queen's University of Belfast, Belfast, UK        |\n",
      "|130     |Univ. of Karlsruhe, Karlsruhe, West Germany           |\n",
      "|195     |AERE Harwell Laboratory, Oxon, UK                     |\n",
      "|195     |Queen's Univ., Belfast, Northern Ireland              |\n",
      "|260     |University of Michigan, Ann Arbor, MI                 |\n",
      "|260     |University of Michigan, Ann Arbor, MI                 |\n",
      "|325     |Oslo politikammer, Oslo, Norway                       |\n",
      "|390     |Harvard Univ., Cambridge, MA                          |\n",
      "|390     |Boston Univ., Boston, MA                              |\n",
      "|455     |Cornell Univ., Ithaca, NY                             |\n",
      "|455     |Cornell Univ., Ithaca, NY                             |\n",
      "|520     |IBM General Technology Division, Hopewell Junction, NY|\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|585     |-                                                     |\n",
      "|585     |-                                                     |\n",
      "|585     |-                                                     |\n",
      "|650     |New York Univ., New York, NY                          |\n",
      "+--------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split affiliations so we can have clean data and separate records { paper_id; affiliation }\n",
    "unique_affiliations_df = affiliation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"affiliations\"),\";\")) \\\n",
    "    .alias(\"affiliation\"))\n",
    "unique_affiliations_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3195d7d4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for special nonsense characters \"-\" and filter them out\n",
    "### If the affiliation is missing, there is no point of keeping the rows\n",
    "unique_affiliations_df = unique_affiliations_df.where(unique_affiliations_df.affiliation != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f62eeaed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|paper_id|         affiliation|count|\n",
      "+--------+--------------------+-----+\n",
      "|  569905|IBM and Universit...|   91|\n",
      "| 1202294|Open Grid Forum—G...|   88|\n",
      "| 1542970|University of Ten...|   65|\n",
      "|  418817|Humanoid Robotics...|   62|\n",
      "| 1731577|IBM Semiconductor...|   59|\n",
      "|  772121|IBM Research Divi...|   52|\n",
      "| 1038111|IBM Thomas J. Wat...|   46|\n",
      "| 1241693|INFN-CNAF V.le Be...|   44|\n",
      "| 1633898|NASA Goddard Spac...|   31|\n",
      "| 1077644|Carnegie Mellon U...|   31|\n",
      "|  864278|Dept. of Electr. ...|   29|\n",
      "| 1229219|    No Affiliations,|   29|\n",
      "| 1210078|IMEC, Kapeldreef ...|   29|\n",
      "|  994444|Lehrstuhl fur Ope...|   29|\n",
      "| 1423217|Shanghai Astronom...|   28|\n",
      "|  827034|The Artist Educat...|   28|\n",
      "|  771289|IBM Research Divi...|   28|\n",
      "| 1312394|Atheros Communica...|   27|\n",
      "| 1972771|LinkedIn, Inc, Mo...|   27|\n",
      "| 1625041|           Microsoft|   27|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df \\\n",
    "    .groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3fbf49b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique affiliations\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e55ad40",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_affiliations_df = clean_special_character(unique_affiliations_df, 'affiliation')\n",
    "### remove special letters\n",
    "unique_affiliations_df = clean_special_letters(unique_affiliations_df, 'affiliation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "042f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase the affiliation col values\n",
    "unique_affiliations_df = unique_affiliations_df.withColumn('affiliation', lower(col('affiliation')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "855886fd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0083171",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### filter out affiliations that are not part of the final_paper_author_id_df\n",
    "final_affiliations_df = unique_affiliations_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('affiliation')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1855220",
   "metadata": {},
   "source": [
    "# Load and clean Publication_venues df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d25f590",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/publication_venues.csv, schema path: ./schemas/publication_venues.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('publication_venue', 'String')]\n"
     ]
    }
   ],
   "source": [
    "### load publication_venues into schema\n",
    "publication_venue_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}publication_venues.csv', f'{SCHEMAS_FOLDER}publication_venues.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "026166d7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|   publication_venue|\n",
      "+--------+--------------------+\n",
      "|      65|Information Techn...|\n",
      "|     130|Proc. of the symp...|\n",
      "|     195|ACM Transactions ...|\n",
      "|     260|Information and C...|\n",
      "|     325|Computers and pen...|\n",
      "|     390|Information and C...|\n",
      "|     455|SIAM Journal on C...|\n",
      "|     520|IBM Journal of Re...|\n",
      "|     585|Journal of the AC...|\n",
      "|     650|Theoretical Compu...|\n",
      "|     715|            Computer|\n",
      "|     780|ACM Transactions ...|\n",
      "|     845|Methods and tools...|\n",
      "|     910|Information Proce...|\n",
      "|     975|ACM Transactions ...|\n",
      "|    1040|Information Proce...|\n",
      "|    1105|ACM Transactions ...|\n",
      "|    1170|Proc. of the 2nd ...|\n",
      "|    1235|Proc. of the inte...|\n",
      "|    1300|Foundations of co...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### trim publication_venue\n",
    "publication_venue_df = publication_venue_df.withColumn( \\\n",
    "    \"publication_venue\", trim(publication_venue_df.publication_venue) \\\n",
    ")\n",
    "publication_venue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6daa39b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for null values inside publication venues dataframe\n",
    "null_values_publication_venue = publication_venue_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in publication_venue_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbe1b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|paper_id|publication_venue|\n",
      "+--------+-----------------+\n",
      "|       0|              148|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 94:===========================================>              (3 + 1) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_values_publication_venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eef3dd2b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop null values \n",
    "publication_venue_df=publication_venue_df.na.drop(how=\"any\", subset=['publication_venue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61aa0c6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+\n",
      "|paper_id|publication_venue|count|\n",
      "+--------+-----------------+-----+\n",
      "+--------+-----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "publication_venue_df \\\n",
    "    .groupby(['paper_id', 'publication_venue']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a55ddef7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### join publication_venue_df with final_paper_author_id_df\n",
    "### to remove publication venues of paper ids which are not part of final_paper_author_id_df\n",
    "final_publication_venues_df = publication_venue_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('publication_venue')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6ec60",
   "metadata": {},
   "source": [
    "# Load and clean Citations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d24ec61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/citations.csv, schema path: ./schemas/citations.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('ref_ids', 'String')]\n",
      "+--------+--------------------+\n",
      "|paper_id|             ref_ids|\n",
      "+--------+--------------------+\n",
      "|      65|                null|\n",
      "|     130|                null|\n",
      "|     195|317424;317425;317573|\n",
      "|     260|                null|\n",
      "|     325|                null|\n",
      "|     390|                null|\n",
      "|     455|                null|\n",
      "|     520|       318368;323493|\n",
      "|     585|                null|\n",
      "|     650|                null|\n",
      "|     715|                null|\n",
      "|     780|318420;319233;319...|\n",
      "|     845|                null|\n",
      "|     910|                null|\n",
      "|     975|67604;318882;3718...|\n",
      "|    1040|                null|\n",
      "|    1105|289087;318014;318...|\n",
      "|    1170|                null|\n",
      "|    1235|                null|\n",
      "|    1300|                null|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation csv into schema\n",
    "citation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}citations.csv', f'{SCHEMAS_FOLDER}citations.csv')\n",
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "509f0ac2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "citation_df = citation_df.withColumn(\"ref_ids\", trim(citation_df.ref_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30286e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT paper_id)|\n",
      "+------------------------+\n",
      "|                 2092356|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### show how many paper ids are present in citation_df\n",
    "citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1afe6f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+\n",
      "|paper_id|ref_ids|count|\n",
      "+--------+-------+-----+\n",
      "+--------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "citation_df.groupby(['paper_id', 'ref_ids']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5c54e1c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|paper_id|ref_id|\n",
      "+--------+------+\n",
      "|65      |null  |\n",
      "|130     |null  |\n",
      "|195     |317424|\n",
      "|195     |317425|\n",
      "|195     |317573|\n",
      "|260     |null  |\n",
      "|325     |null  |\n",
      "|390     |null  |\n",
      "|455     |null  |\n",
      "|520     |318368|\n",
      "|520     |323493|\n",
      "|585     |null  |\n",
      "|650     |null  |\n",
      "|715     |null  |\n",
      "|780     |318420|\n",
      "|780     |319233|\n",
      "|780     |319290|\n",
      "|780     |319579|\n",
      "|780     |320813|\n",
      "|845     |null  |\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split citations so we can have clean data and seperate records {paper_id; ref_id}\n",
    "unique_citation_df = citation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode_outer(F.split(F.col(\"ref_ids\"),\";\")).alias(\"ref_id\"))\n",
    "unique_citation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32d01f0e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\", trim(unique_citation_df.ref_id))\n",
    "### change data type of ref_id to Integer\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\",unique_citation_df[\"ref_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "037eb73e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- ref_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_citation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce89c12f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 17:57:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|paper_id|ref_id|count|\n",
      "+--------+------+-----+\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows\n",
    "unique_citation_df.groupby(['paper_id', 'ref_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "995da1d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|paper_id|ref_id|\n",
      "+--------+------+\n",
      "|      65|  null|\n",
      "|     130|  null|\n",
      "|     260|  null|\n",
      "|     325|  null|\n",
      "|     390|  null|\n",
      "|     455|  null|\n",
      "|     585|  null|\n",
      "|     650|  null|\n",
      "|     715|  null|\n",
      "|     845|  null|\n",
      "|     910|  null|\n",
      "|    1040|  null|\n",
      "|    1170|  null|\n",
      "|    1235|  null|\n",
      "|    1300|  null|\n",
      "|    1365|  null|\n",
      "|    1430|  null|\n",
      "|    1495|  null|\n",
      "|    1560|  null|\n",
      "|    1625|  null|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check whether some papers have null ref_ids\n",
    "### (those papers will still be kept in the dataframe for consistency)\n",
    "unique_citation_df.filter(unique_citation_df['ref_id'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c207d516",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### clean up ref ids if their paper_id is not a part of final_paper_author_id_df\n",
    "final_citation_df = unique_citation_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('ref_id')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066b305",
   "metadata": {},
   "source": [
    "# Load and Research_interests in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "065c387e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/research_interests.csv, schema path: ./schemas/research_interests.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('research_interests', 'String')]\n"
     ]
    }
   ],
   "source": [
    "### load research_interests csv into schema\n",
    "research_interests_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}research_interests.csv', f'{SCHEMAS_FOLDER}research_interests.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "296ee220",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "research_interests_df = research_interests_df \\\n",
    "    .withColumn(\"research_interests\", trim(research_interests_df.research_interests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b967513d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|author_id|research_interests|\n",
      "+---------+------------------+\n",
      "|        0|             15399|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values in the affiliations column\n",
    "research_interests_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in research_interests_df.columns]).show()\n",
    "### drop null values (it is safe since we dont need research_interests for any computation)\n",
    "research_interests_df = research_interests_df.na.drop(how=\"any\", subset=['research_interests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4995ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- research_interests: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+\n",
      "|author_id|  research_interests|\n",
      "+---------+--------------------+\n",
      "|       17|HIV disease;Inter...|\n",
      "|       34|associate polynom...|\n",
      "|       51|metadata element;...|\n",
      "|       68|Web Service;conte...|\n",
      "|       85|intermediate key;...|\n",
      "|      102|feedback loop;dif...|\n",
      "|      119|Rough Set;nomal C...|\n",
      "|      136|MATLAB toolbox;li...|\n",
      "|      153|Byzantine agreeme...|\n",
      "|      170|Ein objektorienti...|\n",
      "|      187|portable device;A...|\n",
      "|      204|Integer-valued pr...|\n",
      "|      221|stock price;stock...|\n",
      "|      238|Hypermedia Synchr...|\n",
      "|      255|computer-mediated...|\n",
      "|      272|Dijkstra method;o...|\n",
      "|      289|low-frequency act...|\n",
      "|      306|copyright process...|\n",
      "|      323|uncertain informa...|\n",
      "|      340|histology image;s...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "research_interests_df.printSchema()\n",
    "research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16cf3d09",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------------+\n",
      "|author_id|research_interest                        |\n",
      "+---------+-----------------------------------------+\n",
      "|17       |HIV disease                              |\n",
      "|17       |Internet resource                        |\n",
      "|17       |World-Wide Web                           |\n",
      "|17       |clinical management                      |\n",
      "|34       |associate polynomial term                |\n",
      "|34       |bivariate polynomial                     |\n",
      "|34       |difficult computational problem          |\n",
      "|34       |novel polynomial                         |\n",
      "|34       |polynomial multiplication problem        |\n",
      "|34       |polynomial term                          |\n",
      "|34       |reachability problem                     |\n",
      "|34       |Probabilistic Reachability               |\n",
      "|34       |Reachability analysis                    |\n",
      "|34       |better time complexity                   |\n",
      "|51       |metadata element                         |\n",
      "|51       |metadata record                          |\n",
      "|51       |Dublin Core metadata                     |\n",
      "|51       |PaperBase extracts metadata              |\n",
      "|51       |Semi automated metadata extraction       |\n",
      "|51       |applicationAs metadata providers increase|\n",
      "+---------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split research interests\n",
    "### so we can have clean data and separate records { paper_id; research_interest }\n",
    "unique_research_interests_df = research_interests_df \\\n",
    "    .select(F.col(\"author_id\"), F.explode(F.split(F.col(\"research_interests\"),\";\")) \\\n",
    "    .alias(\"research_interest\"))\n",
    "\n",
    "unique_research_interests_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00ef0111",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn(\"research_interest\", trim(unique_research_interests_df.research_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4cacff62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### clean special characters and special letters\n",
    "unique_research_interests_df = clean_special_character(unique_research_interests_df, 'research_interest')\n",
    "unique_research_interests_df = clean_special_letters(unique_research_interests_df, 'research_interest')\n",
    "### lowercase research_interests\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn('research_interest', lower(col('research_interest')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d855bc9f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_research_interests_df=unique_research_interests_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c32ed493",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# clean up research interests if their author id is not a part of final_paper_author_id_df\n",
    "final_research_interests_df = unique_research_interests_df \\\n",
    "    .join(final_paper_author_id_df, ['author_id'], 'inner') \\\n",
    "    .select(F.col('author_id'), F.col('research_interest')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10818814",
   "metadata": {},
   "source": [
    "# Run Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36310d",
   "metadata": {},
   "source": [
    "### Q1.2 Compute paper count per unique affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08f3126d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "paper_count_per_affiliation_df = final_affiliations_df \\\n",
    "    .groupBy('affiliation') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"papers_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "041807a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 18:08:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:08:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:08:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:08:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|         affiliation|papers_count|\n",
      "+--------------------+------------+\n",
      "|nagoya univ, nago...|          30|\n",
      "|nam kwang enginee...|           1|\n",
      "|univ of technolog...|           6|\n",
      "|univ of texas at ...|          41|\n",
      "|purdue univ, west...|         389|\n",
      "|laboratoires de m...|           3|\n",
      "|padova  univ, pad...|           1|\n",
      "|royal swedish aca...|           1|\n",
      "|dept of ee  cs, u...|           1|\n",
      "|loughborough univ...|           1|\n",
      "|univ of quebec at...|           1|\n",
      "|shanghai jiaotong...|           4|\n",
      "|univ of aberdeen,...|           5|\n",
      "|department of ele...|          20|\n",
      "|beyond words publ...|           1|\n",
      "|western illinois ...|           5|\n",
      "|the bdm corporati...|           1|\n",
      "|the university of...|           2|\n",
      "|university of mia...|          45|\n",
      "|baylor college of...|          11|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paper_count_per_affiliation_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc2f1",
   "metadata": {},
   "source": [
    "### Q1.1 Validate precomputed paper counts, citation (ref) counts and h-indexes (per author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb36be",
   "metadata": {},
   "source": [
    "#### How to compute h-index for a specific author\n",
    "1. Retrieve all publications of the author\n",
    "2. Calculate the number of references per publication\n",
    "3. Sort the results in descending order\n",
    "4. Find a threshold N, where N top publications have at least N references each. N is the h-index of the author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82c4fe33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 1-2 Calculate the number of references per publication\n",
    "refs_per_paper_count_df = final_citation_df \\\n",
    "    .groupBy(\"paper_id\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\",\"paper_references\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d2dc42a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### 3 Join [papers per author] with [references per paper] and sort the results in descending order\n",
    "author_papers_with_ref_count = final_paper_author_id_df.join(refs_per_paper_count_df, 'paper_id') \\\n",
    "    .sort(col(\"paper_references\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "656a90c3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### add index column to table to ease h-index calculation\n",
    "window = Window.partitionBy(author_papers_with_ref_count['author_id']) \\\n",
    "    .orderBy(desc(\"paper_references\"), desc(\"paper_id\"))\n",
    "\n",
    "indexed_grouped_papers_df = author_papers_with_ref_count.select('*', rank().over(window).alias('index'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "670dbb5c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_papers = indexed_grouped_papers_df \\\n",
    "    .withColumn(\"possible_h_index\", \\\n",
    "                when( \\\n",
    "                    indexed_grouped_papers_df.index <= indexed_grouped_papers_df.paper_references, \\\n",
    "                    indexed_grouped_papers_df.index \\\n",
    "                    ).otherwise(0) \\\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8143a56",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_grouped_by_author_papers_df = h_indexed_papers.groupBy('author_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53fa8f6e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_aggregated_papers_df = h_indexed_grouped_by_author_papers_df.agg( \\\n",
    "        F.count(\"paper_id\").alias(\"validated_paper_count\"),\n",
    "        F.sum(\"paper_references\").alias(\"validated_citation_count\"),\n",
    "        F.max(\"possible_h_index\").alias(\"validated_h_index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5123f",
   "metadata": {},
   "source": [
    "#### Computed results for `validated_paper_count`, `validated_paper_count` and `validated_h_index`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b40ed9",
   "metadata": {},
   "source": [
    "__Final resulting dataframe is unique_authors_with_validated_cols_df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae0b318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join the computation results with author dataframe\n",
    "### to be able to compare received values with the precomputed values\n",
    "unique_authors_with_validated_cols_df = h_indexed_aggregated_papers_df.join(author_df, 'author_id', 'inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93ea21c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1712364"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_authors_with_validated_cols_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60baef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_with_validated_cols_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ac42142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 18:22:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:22:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:23:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1230051"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For the info: check how many precomputed h-indexes differ from the validated h-indexes\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_h_index\"] != unique_authors_with_validated_cols_df[\"h_index\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd8fa789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 18:25:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 18:25:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:25:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1601563"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For the info: check how many precomputed author citation counts differ from the validated citation counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_citation_count\"] != unique_authors_with_validated_cols_df[\"citation_count\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4b9fb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 18:28:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 18:28:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19934"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For the info: check how many precomputed author paper counts differ from the validated paper counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_paper_count\"] != unique_authors_with_validated_cols_df[\"paper_count\"]\n",
    "unique_authors_with_validated_cols_df.filter(filter_condition).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06577cfd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Save cleaned & computed data into the csv files (all data needed for T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3a89293",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DATA_FOLDER = './assets/cleanedDFsData/'\n",
    "def saveDFIntoCSVFolder(df, folderName, pathToFolder):\n",
    "    # Save data to csv file\n",
    "    df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(f'{CLEAN_DATA_FOLDER}{folderName}')\n",
    "def moveFileToCorrectFolder(folderName, pathToFolder):\n",
    "    filename = glob.glob(f'{CLEAN_DATA_FOLDER}{folderName}/*.csv')[0]\n",
    "    shutil.move(filename, f'{CLEAN_DATA_FOLDER}{folderName}_ds.csv')\n",
    "    \n",
    "# After saving of the data to csv we have to call moveFileToCorrectFolder,\n",
    "# because saveDFIntoCSVFolder actually saves the data into the folder with a csv file inside.\n",
    "# moveFileToCorrectFolder moves the file to the correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43d402cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Saving cleaned & unique paper author data\n",
    "saveDFIntoCSVFolder(final_paper_author_id_df, 'paper_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53e5e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('paper_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 624:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "## Saving cleaned & unique affiliations data with computed paper_count\n",
    "saveDFIntoCSVFolder(final_affiliations_df, 'affiliations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d41ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('affiliations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbe0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cleaned & unique publication venues data \n",
    "saveDFIntoCSVFolder(final_publication_venues_df, 'publication_venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('publication_venues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving cleaned & computed & research interests data\n",
    "saveDFIntoCSVFolder(final_research_interests_df, 'research_interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('research_interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad745a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDFIntoCSVFolder(paper_df, 'papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c964fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "moveFileToCorrectFolder('papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11c328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
