{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "987dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "# *                   _oo0oo_\n",
    "# *                  o8888888o\n",
    "# *                  88\" . \"88\n",
    "# *                  (| -_- |)\n",
    "# *                  0\\  =  /0\n",
    "# *                ___/`---'\\___\n",
    "# *              .' \\\\|     |// '.\n",
    "# *             / \\\\|||  :  |||// \\\n",
    "# *            / _||||| -:- |||||- \\\n",
    "# *           |   | \\\\\\  -  /// |   |\n",
    "# *           | \\_|  ''\\---/''  |_/ |\n",
    "# *           \\  .-\\__  '-'  ___/-. /\n",
    "# *         ___'. .'  /--.--\\  `. .'___\n",
    "# *      .\"\" '<  `.___\\_<|>_/___.' >' \"\".\n",
    "# *     | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
    "# *     \\  \\ `_.   \\_ __\\ /__ _/   .-` /  /\n",
    "# * =====`-.____`.___ \\_____/___.-`___.-'=====\n",
    "# *                   `=---='\n",
    "# *\n",
    "# *\n",
    "# * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# *\n",
    "# *   Buddha blesses your code to be bug free\n",
    "# */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4071cf9f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7626e981",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from helpers import createDFFromFileAndSchema, clean_special_letters, clean_special_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae6ee91",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Clean up the data and perform the queries').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb68a75d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://t-193.vc-graz.ac.at:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x113034130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062ec083",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMAS_FOLDER = './schemas/'\n",
    "FILES_FOLDER = './assets/parsedData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92dff5",
   "metadata": {},
   "source": [
    "# Load and clean Paper DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f871ce",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/papers.csv, schema path: ./schemas/paper.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n",
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|Direct file organ...|1984|\n",
      "|     130|An introduction t...|1983|\n",
      "|     195|On solving almost...|1984|\n",
      "|     260|Connections betwe...|1984|\n",
      "|     325|Computers and pen...|1984|\n",
      "|     390|Relativizations c...|1984|\n",
      "|     455|On the optimum ch...|1984|\n",
      "|     520|All points addres...|1984|\n",
      "|     585|Optimum Head Sepa...|1984|\n",
      "|     650|A parallel-design...|1984|\n",
      "|     715|Computer - IEEE C...|1984|\n",
      "|     780|Experience with G...|1984|\n",
      "|     845|Code generation a...|1984|\n",
      "|     910|On estimating acc...|1984|\n",
      "|     975|A distributed alt...|1985|\n",
      "|    1040|A comparison of t...|1984|\n",
      "|    1105|Generalizing spec...|1985|\n",
      "|    1170|Real time graphic...|1984|\n",
      "|    1235|Common and uncomm...|1984|\n",
      "|    1300|Foundations of co...|1985|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load paper csv into schema\n",
    "paper_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}papers.csv', f'{SCHEMAS_FOLDER}paper.csv')\n",
    "paper_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a7cc",
   "metadata": {},
   "source": [
    "### Data cleaning for paper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3054c0b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove spaces from values of the columns\n",
    "paper_df = paper_df.withColumn(\"title\", trim(paper_df.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285bb60f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check for the correct data types\n",
    "paper_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40fc4cf2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:======================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+\n",
      "|paper_id|title|year|\n",
      "+--------+-----+----+\n",
      "|       0|   24| 157|\n",
      "+--------+-----+----+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:============================================>              (6 + 2) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for nonsense null data\n",
    "null_values_paper_df = paper_df.select(\n",
    "    [count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in paper_df.columns]\n",
    ")\n",
    "print(null_values_paper_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbdfb814",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### after checking the below dataframes,\n",
    "### we have seen that all papers, whose title is missing, have the authors (besides paper_id = 748056)\n",
    "### Decision: fill missing titles with: \"Missing Title\"\n",
    "\n",
    "paper_df=paper_df.na.fill('Missing Title', ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12f62d8e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "paper_df=clean_special_character(paper_df,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b78e5ec",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+-------------------+\n",
      "|paper_id|               title|year|Duplicate_indicator|\n",
      "+--------+--------------------+----+-------------------+\n",
      "|      22|On two more Eigen...|1984|                  0|\n",
      "|      27|Frame theory and ...|1984|                  0|\n",
      "|      30|Stationary wave s...|1984|                  0|\n",
      "|      32|Proc. IFIP workin...|1983|                  0|\n",
      "|      44|ADA Concurrent Pr...|1984|                  0|\n",
      "|      52|Automated microco...|1984|                  0|\n",
      "|      58|The application o...|1983|                  0|\n",
      "|      61|The DISS methodol...|1984|                  0|\n",
      "|      66|Soft evaluation o...|1984|                  0|\n",
      "|      91|Design of optimal...|1982|                  0|\n",
      "|     107|Deterministic pro...|1984|                  0|\n",
      "|     113|From logic to com...|1983|                  0|\n",
      "|     114|A first course in...|1983|                  0|\n",
      "|     122|Proc. of the symp...|1983|                  0|\n",
      "|     126|Evaluation of ari...|1983|                  0|\n",
      "|     134|       MATRIX PASCAL|1983|                  0|\n",
      "|     139|    Programming in C|1983|                  0|\n",
      "|     151|An extension of c...|1984|                  0|\n",
      "|     154|Database manageme...|1984|                  0|\n",
      "|     165|A quadratically c...|1984|                  0|\n",
      "+--------+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|paper_id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate rows\n",
    "paper_df.join(\n",
    "    paper_df\n",
    "        .groupBy(paper_df.columns) \\\n",
    "        .agg((F.count(\"*\")>1) \\\n",
    "        .cast(\"int\") \\\n",
    "        .alias(\"Duplicate_indicator\")), \\\n",
    "        on=paper_df.columns,how=\"inner\") \\\n",
    "    .show()\n",
    "### from the dataframe view, we can see that there are no duplicates\n",
    "paper_df.groupby(['paper_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b03384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092356"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check for the number of paper entries\n",
    "paper_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f7c3d",
   "metadata": {},
   "source": [
    "# Load and clean paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82641fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/paper_authors.csv, schema path: ./schemas/paper_authors.csv\n",
      "Types from schema: [('authors', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|             authors|paper_id|\n",
      "+--------------------+--------+\n",
      "| K Devine;F J. Smith|      65|\n",
      "|J Wolff von Guden...|     130|\n",
      "|J. K. Reid;A. Jen...|     195|\n",
      "|William G. Golson...|     260|\n",
      "|    Stein Schjolberg|     325|\n",
      "|W Ian Gasarch;Ste...|     390|\n",
      "|Sam Toueg;Özalp B...|     455|\n",
      "|Frederick H. Dill...|     520|\n",
      "|A. R. Calderbank;...|     585|\n",
      "|         Uzi Vishkin|     650|\n",
      "|      Stephen S. Yau|     715|\n",
      "|Michael D. Schroe...|     780|\n",
      "|         S L. Graham|     845|\n",
      "|D Maio;M R. Scala...|     910|\n",
      "|         Pamela Zave|     975|\n",
      "|G. Salton;E. Voor...|    1040|\n",
      "|Douglas D. Dunlop...|    1105|\n",
      "|Patrick Peruch;Vi...|    1170|\n",
      "| Robert J. Sternberg|    1235|\n",
      "|Curtis Roads;John...|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load paper_authors csv into schema\n",
    "paper_author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}paper_authors.csv', f'{SCHEMAS_FOLDER}paper_authors.csv')\n",
    "paper_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba688b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "paper_author_df = paper_author_df.withColumn(\"authors\", trim(paper_author_df.authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0d595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- authors: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### verify schema\n",
    "paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e465de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special letters\n",
    "paper_author_df=clean_special_letters(paper_author_df, 'authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "141e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DELETE - ?\n",
    "### check if authors are missing as well for the ids whose title was missing in paper_df\n",
    "### for rows in paper_author_df.select(\"authors\",\"paper_id\").collect():\n",
    "###    if rows[1] in null_paper_ids_list:\n",
    "###        print(rows[0], rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbebb1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+\n",
      "|paper_id|author               |\n",
      "+--------+---------------------+\n",
      "|65      |K Devine             |\n",
      "|65      |F J. Smith           |\n",
      "|130     |J Wolff von Gudenberg|\n",
      "|195     |J. K. Reid           |\n",
      "|195     |A. Jennings          |\n",
      "|260     |William G. Golson    |\n",
      "|260     |William C. Rounds    |\n",
      "|325     |Stein Schjolberg     |\n",
      "|390     |W Ian Gasarch        |\n",
      "|390     |Steven Homer         |\n",
      "|455     |Sam Toueg            |\n",
      "|455     |zalp Babaoğlu        |\n",
      "|520     |Frederick H. Dill    |\n",
      "|520     |Satish Gupta         |\n",
      "|520     |Daniel T. Ling       |\n",
      "|520     |Richard E. Matick    |\n",
      "|585     |A. R. Calderbank     |\n",
      "|585     |E. G. Coffman, Jr.   |\n",
      "|585     |L. Flatto            |\n",
      "|650     |Uzi Vishkin          |\n",
      "+--------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split authors so we can have clean data and separate records { paper_id; author }\n",
    "unique_paper_author_df = paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"authors\"),\";\")).alias(\"author\"))\n",
    "\n",
    "unique_paper_author_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72771502",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove leadind and trailing spaces\n",
    "unique_paper_author_df = unique_paper_author_df.withColumn(\"author\", trim(unique_paper_author_df.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7037057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_paper_author_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9143e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_paper_author_df=clean_special_character(unique_paper_author_df, 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09cf076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "unique_paper_author_df=unique_paper_author_df.withColumn('author', lower(col('author')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b220b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 12:59:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|paper_id|              author|count|\n",
      "+--------+--------------------+-----+\n",
      "| 1523221|        dongkun shin|    4|\n",
      "| 2040206|        mingshu wang|    3|\n",
      "| 2040206|        anchun cheng|    3|\n",
      "| 2059316|       han chuanfeng|    3|\n",
      "| 1202294|           n. sharma|    3|\n",
      "| 2042230|             lu leng|    3|\n",
      "| 1071392|      jeremy golding|    2|\n",
      "| 1071003|       gnther fliedl|    2|\n",
      "| 1485517|       anupam shukla|    2|\n",
      "| 1071566|      d. d. hamilton|    2|\n",
      "|  393645|   michael luckevich|    2|\n",
      "|  581650|   j. howard johnson|    2|\n",
      "|  817145|    michael j. quinn|    2|\n",
      "| 1084827|             m beigl|    2|\n",
      "| 1071070|    thorbjrn knudsen|    2|\n",
      "| 1071200|         russ rogers|    2|\n",
      "| 1071235|          olaf jacob|    2|\n",
      "| 1071236|      antonio chella|    2|\n",
      "| 1071255|allan kang ying wong|    2|\n",
      "| 1071285|hilde g. corneliu...|    2|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:======>                                                   (1 + 8) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows:\n",
    "unique_paper_author_df \\\n",
    "    .groupby(['paper_id', 'author']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()\n",
    "\n",
    "### drop duplicate rows since here we need unique paper-author relation\n",
    "unique_paper_author_df = unique_paper_author_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c41e1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|paper_id|        name|\n",
      "+--------+------------+\n",
      "|    1821|        suri|\n",
      "|    3582|    williams|\n",
      "|    8388|        huet|\n",
      "|    8581|    stoddart|\n",
      "|   11188|        maio|\n",
      "|   11703|      landau|\n",
      "|   11831|      reeves|\n",
      "|   13267|     searles|\n",
      "|   16580|      mettke|\n",
      "|   16965|schuitemaker|\n",
      "|   18077|      buxton|\n",
      "|   18141|  hemmerling|\n",
      "|   18208|  linebarger|\n",
      "|   18530|      millen|\n",
      "|   19112|    ad'yutov|\n",
      "|   19959|         jr.|\n",
      "|   20152|      soupos|\n",
      "|   25486|      mazaud|\n",
      "|   25614|      mccain|\n",
      "|   26522| jagannathan|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### split author-name so we keep only the surname\n",
    "### This decision was made because there are a lot of disrepancies in full names,\n",
    "### and later on we need the clean and nice surnames for correct joining of the tables by paper_id + surname.\n",
    "unique_paper_author_cleaned_df = unique_paper_author_df \\\n",
    "    .select(F.col(\"paper_id\"), F.trim(F.element_at (F.split(F.col(\"author\"),\" \"),-1)).alias('name'))\n",
    "\n",
    "unique_paper_author_cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43deef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|paper_id|author             |\n",
      "+--------+-------------------+\n",
      "|1821    |rajan suri         |\n",
      "|3582    |martha e. williams |\n",
      "|8388    |g huet             |\n",
      "|8581    |bill stoddart      |\n",
      "|11188   |d maio             |\n",
      "|11703   |marie-claude landau|\n",
      "|11831   |thomas c reeves    |\n",
      "|13267   |john searles       |\n",
      "|16580   |holger mettke      |\n",
      "|16965   |p schuitemaker     |\n",
      "|18077   |w. buxton          |\n",
      "|18141   |a hemmerling       |\n",
      "|18208   |robert n linebarger|\n",
      "|18530   |jonathan k. millen |\n",
      "|19112   |m m ad'yutov       |\n",
      "|19959   |w m coughran, jr.  |\n",
      "|20152   |r soupos           |\n",
      "|25486   |m. mazaud          |\n",
      "|25614   |r. a. mccain       |\n",
      "|26522   |v. jagannathan     |\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_paper_author_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b41b1bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5237613"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are in unique_paper_author_cleaned_df\n",
    "unique_paper_author_cleaned_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af545918",
   "metadata": {},
   "source": [
    "# Clean and Load Authors df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8661121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/authors.csv, schema path: ./schemas/author.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('citation_count', 'Integer'), ('h_index', 'Integer'), ('name', 'String'), ('paper_count', 'Integer')]\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|author_id|citation_count|h_index|                name|paper_count|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "|       17|             0|      0|     J. Michael Howe|          1|\n",
      "|       34|             0|      0|        Haitham Gabr|          2|\n",
      "|       51|             4|      1|         Emma Tonkin|          8|\n",
      "|       68|             1|      1|        Woochul Shin|          4|\n",
      "|       85|             0|      0|           S Improta|          1|\n",
      "|      102|             8|      2|       Richard Ferri|          5|\n",
      "|      119|             0|      0|            Qing Liu|          1|\n",
      "|      136|             0|      0|      Artur Gramacki|          2|\n",
      "|      153|             0|      0|Olumuyiwa Oluwasanmi|          2|\n",
      "|      170|             0|      0|    Josef Willenborg|          1|\n",
      "|      187|             0|      0|            Qing Wei|          1|\n",
      "|      204|             4|      1|Jurey Ivanovich Z...|          1|\n",
      "|      221|            13|      1|             Anny Ng|          1|\n",
      "|      238|             2|      1|    Nikos B. Pronios|          3|\n",
      "|      255|             0|      0| Lourdes Fraga Alman|          1|\n",
      "|      272|             2|      1|       Junji Nishino|          7|\n",
      "|      289|             0|      0|       L. Dascalescu|          2|\n",
      "|      306|             0|      0|    Masakazu Nishino|          1|\n",
      "|      323|             4|      1|    Jean-Rémi Duquet|          2|\n",
      "|      340|             1|      1|     Brian A. Canada|          2|\n",
      "+---------+--------------+-------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load author csv into schema\n",
    "author_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}authors.csv', f'{SCHEMAS_FOLDER}author.csv')\n",
    "author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15d7cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove spaces from values of the column\n",
    "author_df = author_df.withColumn(\"name\", trim(author_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b8eff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+----+-----------+\n",
      "|author_id|citation_count|h_index|name|paper_count|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "|        0|             2|      2|   3|          2|\n",
      "+---------+--------------+-------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for nonsense null data (filtering will be done later)\n",
    "null_values_author_df = author_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in author_df.columns])\n",
    "null_values_author_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e750c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill empty paper_count, citation_count, h_index to 0 (just one author)\n",
    "author_df=author_df.na.fill(value=0, subset='paper_count')\n",
    "author_df=author_df.na.fill(value=0, subset='citation_count')\n",
    "author_df=author_df.na.fill(value=0, subset='h_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a733b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters like í, â, é\n",
    "author_df=clean_special_letters(author_df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cf02fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "author_df=clean_special_character(author_df,'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "948b875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase author-name\n",
    "author_df=author_df.withColumn('name', lower(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fae8b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+----------------+-----------+\n",
      "|author_id|citation_count|h_index|            name|paper_count|\n",
      "+---------+--------------+-------+----------------+-----------+\n",
      "|     2465|             0|      0|  kamel lecheheb|          1|\n",
      "|     4199|             0|      0|  nathan burrows|          1|\n",
      "|     6018|             0|      0|leila jalalzadeh|          1|\n",
      "|     6341|             0|      0|      v.b. singh|          3|\n",
      "|     8942|             0|      0|       siqi song|          1|\n",
      "|    17000|             0|      0|   xianzhong cui|          1|\n",
      "|    19397|             0|      0|       m. pabrai|          1|\n",
      "|    19958|             0|      0|    julien badie|          2|\n",
      "|    21607|             1|      1| evgenij dashkov|          1|\n",
      "|    24803|           480|     10| dinesh c. verma|         60|\n",
      "|    25466|            34|      1|   r. verstappen|          7|\n",
      "|    27251|             1|      1|      r. mannell|          1|\n",
      "|    28526|             0|      0|  a. m. khapayev|          3|\n",
      "|    35411|             0|      0|   chetan mittal|          3|\n",
      "|    40613|             0|      0|          jia yu|          1|\n",
      "|    45492|             1|      1|   doug w. moore|          1|\n",
      "|    46784|             0|      0|       chen meng|          2|\n",
      "|    47124|             0|      0|         jun zhu|          1|\n",
      "|    51544|             5|      0| shinya hiramoto|          2|\n",
      "|    53057|             0|      0|         xu yang|          1|\n",
      "+---------+--------------+-------+----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### drop duplicate rows\n",
    "author_df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ece8ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|author_id|count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check if there are duplicate author_ids\n",
    "author_df.groupby(['author_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145eb93",
   "metadata": {},
   "source": [
    "# Join author and paper dataframes to ensure consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4d547",
   "metadata": {},
   "source": [
    "Load and clean Author2Paper (from the supplement txt file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16366740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('index', 'Integer'), ('author_id', 'Integer'), ('paper_id', 'Integer'), ('author_position', 'Integer')]\n"
     ]
    }
   ],
   "source": [
    "### load paper_author_id csv into schema\n",
    "dtypes = pd.read_csv('./schemas/paper_author_id.csv').to_records(index=False).tolist()\n",
    "print(dtypes)\n",
    "fields = [T.StructField(dtype[0], globals()[f'{dtype[1]}Type']()) for dtype in dtypes]\n",
    "schema = StructType(fields)\n",
    "author_id_2_paper_id_df = spark.read.options(delimiter='\\t').csv('./assets/AMiner-Author2Paper.txt', header=False,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c9d84a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 42:=======>                                                  (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5192998"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are\n",
    "author_id_2_paper_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81c69330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:01:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+\n",
      "|author_id|paper_id|count|\n",
      "+---------+--------+-----+\n",
      "+---------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:=========================>                                (4 + 5) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicates between paper_id and author_id\n",
    "author_id_2_paper_id_df \\\n",
    "    .groupby(['author_id', 'paper_id']) \\\n",
    "    .count().where('count > 1') \\\n",
    "    .sort('count', ascending=False).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e84081c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the suplementary author_id_2_paper_id_df df with author_df\n",
    "author_id_2_paper_id_extended_df = author_id_2_paper_id_df.join(author_df, 'author_id', 'left').drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09d402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the author-name to keep only the surname ---> cleaning data\n",
    "author_id_2_paper_id_cleaned_df = author_id_2_paper_id_extended_df \\\n",
    "    .select( \\\n",
    "        F.col(\"paper_id\"), \\\n",
    "        F.col(\"author_id\"), \\\n",
    "        F.col(\"citation_count\"), \\\n",
    "        F.col(\"h_index\"), \\\n",
    "        F.col(\"paper_count\"), \\\n",
    "        F.trim(F.element_at(F.split(F.col(\"name\"),\" \"),-1)).alias('name') \\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad95fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join the cleaned paper_2_author_cleaned_df to unique_paper_author_cleaned_df\n",
    "final_paper_author_id_df = unique_paper_author_cleaned_df \\\n",
    "    .join(author_id_2_paper_id_cleaned_df, ['name', 'paper_id'], 'inner') \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37905ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5114137"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how many entries there are in the final dataframe\n",
    "final_paper_author_id_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ddb6aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+---------+--------------+-------+-----------+\n",
      "|           name|paper_id|author_id|citation_count|h_index|paper_count|\n",
      "+---------------+--------+---------+--------------+-------+-----------+\n",
      "|             %a|  678557|  1572031|             1|      1|          1|\n",
      "|             %a|  678759|  1571593|             4|      1|          1|\n",
      "|             %a|  678918|  1572148|             0|      0|          1|\n",
      "|&#193brah$#225m| 1745458|   525597|             0|      0|          1|\n",
      "| &#199etintemel|  278973|  1085120|             0|      0|          1|\n",
      "|  &#214zen&#231| 1471484|  1282995|             1|      1|          1|\n",
      "|  &#220st&#252n|  987083|   949192|             2|      1|          1|\n",
      "|  &#268e$#353ka| 1745459|   752703|             0|      0|          2|\n",
      "|     &#x15eahin| 1968003|  1269292|             0|      0|          4|\n",
      "|  &aacutelvarez|  904944|  1685168|             3|      1|          1|\n",
      "|       'donnell|  584385|   738552|           102|      4|         12|\n",
      "|        (adler)| 1221479|   879769|             1|      1|          1|\n",
      "|    (agadjanov)| 1799430|    21179|             3|      1|          1|\n",
      "|     (banerjee)| 1066867|   262455|             0|      0|          1|\n",
      "|      (digital)|  669048|  1695287|             0|      0|          1|\n",
      "|          (e.g.|  670148|  1605339|             0|      0|          1|\n",
      "|       (kresch)|  305322|  1132892|            15|      1|          1|\n",
      "|       (lahkim)| 1808493|    30562|             1|      1|          1|\n",
      "|         (oecd)| 1092644|  1098851|             0|      0|          1|\n",
      "|        (otani)| 1247526|   688744|             0|      0|          2|\n",
      "|     (raytheon)|  669048|  1454892|             0|      0|          1|\n",
      "|        (shitz)|  299113|   498713|            15|      3|          6|\n",
      "|        (shitz)| 1268493|   498713|            15|      3|          6|\n",
      "|        (tinni)| 1304050|   164899|             2|      1|          2|\n",
      "|          (tu+)| 1308599|   170324|             0|      0|          1|\n",
      "|         (vonu)| 1646594|  1156526|             0|      0|          3|\n",
      "|          -mohr|  612358|   743987|             0|      0|          1|\n",
      "|           2000|  673685|   419225|             0|      0|          1|\n",
      "|        ?golabi| 1080446|   294725|             0|      0|          3|\n",
      "|              a|  374109|  1546082|             0|      0|          3|\n",
      "|              a|  668431|  1034641|             0|      0|          1|\n",
      "|              a|  670709|  1535658|             0|      0|          3|\n",
      "|              a| 2028881|   923964|             0|      0|          1|\n",
      "|          a-qun| 1901651|   426124|             0|      0|          1|\n",
      "|             a.|  133334|   495516|             1|      1|          1|\n",
      "|             a.|  605487|   705673|             1|      1|          1|\n",
      "|             a.|  618307|   583071|             0|      0|          1|\n",
      "|             a.|  625862|   147892|             2|      1|          1|\n",
      "|             a.|  650139|   490874|             0|      0|          2|\n",
      "|             a.|  650139|  1604067|             2|      1|          3|\n",
      "|             a.|  650243|  1004871|             0|      0|          2|\n",
      "|             a.|  650244|  1004871|             0|      0|          2|\n",
      "|             a.|  653306|  1135625|             0|      0|          3|\n",
      "|             a.|  653351|    84457|             0|      0|          2|\n",
      "|             a.|  653359|   961600|             0|      0|          4|\n",
      "|             a.|  653366|  1220825|             0|      0|          2|\n",
      "|             a.|  666065|   705216|             0|      0|          1|\n",
      "|             a.|  666069|  1668988|             0|      0|          6|\n",
      "|             a.|  666069|   533844|             0|      0|         14|\n",
      "|             a.|  666115|  1668988|             0|      0|          6|\n",
      "|             a.|  666115|   533844|             0|      0|         14|\n",
      "|             a.|  666152|   758768|             3|      1|         19|\n",
      "|             a.|  666165|    97207|             0|      0|          2|\n",
      "|             a.|  666190|  1514336|             0|      0|          8|\n",
      "|             a.|  666213|  1339201|             0|      0|          3|\n",
      "|             a.|  666223|   343641|             0|      0|          3|\n",
      "|             a.|  666248|  1287448|             0|      0|          4|\n",
      "|             a.|  666285|  1074993|             1|      1|          4|\n",
      "|             a.|  666312|   211188|             0|      0|          4|\n",
      "|             a.|  666382|   245564|             0|      0|          3|\n",
      "|             a.|  666582|   289141|             1|      1|          1|\n",
      "|             a.|  666776|   781025|             0|      0|         16|\n",
      "|             a.|  666793|   153911|             2|      1|         14|\n",
      "|             a.|  666808|    42848|             0|      0|          5|\n",
      "|             a.|  666830|   789918|             0|      0|          9|\n",
      "|             a.|  666847|   950164|             0|      0|          5|\n",
      "|             a.|  666847|   470678|             0|      0|          7|\n",
      "|             a.|  666872|   950164|             0|      0|          5|\n",
      "|             a.|  666891|   594654|             0|      0|          9|\n",
      "|             a.|  666958|  1005067|             0|      0|          1|\n",
      "|             a.|  666964|   679509|             0|      0|          1|\n",
      "|             a.|  667019|   307007|             0|      0|          1|\n",
      "|             a.|  667031|    42138|             0|      0|         41|\n",
      "|             a.|  667038|  1588809|             0|      0|          5|\n",
      "|             a.|  667065|    42138|             0|      0|         41|\n",
      "|             a.|  667097|   459255|             0|      0|         10|\n",
      "|             a.|  667116|   758781|             0|      0|          6|\n",
      "|             a.|  667194|    42138|             0|      0|         41|\n",
      "|             a.|  667197|    42138|             0|      0|         41|\n",
      "|             a.|  667198|    42138|             0|      0|         41|\n",
      "|             a.|  667221|  1587044|             0|      0|         19|\n",
      "|             a.|  667236|    42138|             0|      0|         41|\n",
      "|             a.|  667240|  1587044|             0|      0|         19|\n",
      "|             a.|  667245|    42138|             0|      0|         41|\n",
      "|             a.|  667260|  1269204|             0|      0|          1|\n",
      "|             a.|  667260|  1587044|             0|      0|         19|\n",
      "|             a.|  667263|    42138|             0|      0|         41|\n",
      "|             a.|  667270|   502520|             0|      0|          6|\n",
      "|             a.|  667271|  1570130|             0|      0|          1|\n",
      "|             a.|  667271|  1418361|             2|      1|          7|\n",
      "|             a.|  667295|  1220838|             0|      0|          2|\n",
      "|             a.|  667310|  1465014|             0|      0|          1|\n",
      "|             a.|  667381|  1287448|             0|      0|          4|\n",
      "|             a.|  667438|  1027508|             0|      0|          9|\n",
      "|             a.|  667463|   394380|             0|      0|          7|\n",
      "|             a.|  667550|   961600|             0|      0|          4|\n",
      "|             a.|  667676|  1074993|             1|      1|          4|\n",
      "|             a.|  667804|  1074993|             1|      1|          4|\n",
      "|             a.|  667821|  1205651|             0|      0|          1|\n",
      "|             a.|  667849|   218469|             0|      0|         10|\n",
      "+---------------+--------+---------+--------------+-------+-----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_paper_author_id_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d7b6c",
   "metadata": {},
   "source": [
    "# Load and clean Affiliations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a7d4c21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/affiliations.csv, schema path: ./schemas/affiliation.csv\n",
      "Types from schema: [('affiliations', 'String'), ('paper_id', 'Integer')]\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation csv into schema\n",
    "affiliation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}affiliations.csv', f'{SCHEMAS_FOLDER}affiliation.csv')\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bab85ad4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- affiliations: string (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      "\n",
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### remove leading and trailing spaces\n",
    "affiliation_df = affiliation_df.withColumn(\"affiliations\", trim(affiliation_df.affiliations))\n",
    "\n",
    "affiliation_df.printSchema()\n",
    "affiliation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af1159c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|affiliations|paper_id|\n",
      "+------------+--------+\n",
      "|       37499|       0|\n",
      "+------------+--------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values in the affiliations column\n",
    "### we can see, that there are many rows with null affiliations\n",
    "### these rows will be cleaned up further\n",
    "null_values_affiliations=affiliation_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in affiliation_df.columns])\n",
    "print(null_values_affiliations.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9b5fdc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### This df will in the end be used to count papers per unique affiliation,\n",
    "### so if the affiliation is missing, it doesnt make sense to keep the row\n",
    "### Decision: drop all rows where affiliation is null\n",
    "affiliation_df=affiliation_df.na.drop(how=\"any\", subset=['affiliations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8504dda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------+\n",
      "|paper_id|affiliation                                           |\n",
      "+--------+------------------------------------------------------+\n",
      "|65      |The Queen's University of Belfast, Belfast, UK        |\n",
      "|65      |The Queen's University of Belfast, Belfast, UK        |\n",
      "|130     |Univ. of Karlsruhe, Karlsruhe, West Germany           |\n",
      "|195     |AERE Harwell Laboratory, Oxon, UK                     |\n",
      "|195     |Queen's Univ., Belfast, Northern Ireland              |\n",
      "|260     |University of Michigan, Ann Arbor, MI                 |\n",
      "|260     |University of Michigan, Ann Arbor, MI                 |\n",
      "|325     |Oslo politikammer, Oslo, Norway                       |\n",
      "|390     |Harvard Univ., Cambridge, MA                          |\n",
      "|390     |Boston Univ., Boston, MA                              |\n",
      "|455     |Cornell Univ., Ithaca, NY                             |\n",
      "|455     |Cornell Univ., Ithaca, NY                             |\n",
      "|520     |IBM General Technology Division, Hopewell Junction, NY|\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|520     |IBM Research Division, Yorktown Heights, NY           |\n",
      "|585     |-                                                     |\n",
      "|585     |-                                                     |\n",
      "|585     |-                                                     |\n",
      "|650     |New York Univ., New York, NY                          |\n",
      "+--------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split affiliations so we can have clean data and separate records { paper_id; affiliation }\n",
    "unique_affiliations_df = affiliation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode(F.split(F.col(\"affiliations\"),\";\")) \\\n",
    "    .alias(\"affiliation\"))\n",
    "unique_affiliations_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3195d7d4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### check for special nonsense characters \"-\" and filter them out\n",
    "### If the affiliation is missing, there is no point of keeping the rows\n",
    "unique_affiliations_df = unique_affiliations_df.where(unique_affiliations_df.affiliation != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fda3c444",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|         affiliation|\n",
      "+--------+--------------------+\n",
      "|      65|The Queen's Unive...|\n",
      "|      65|The Queen's Unive...|\n",
      "|     130|Univ. of Karlsruh...|\n",
      "|     195|AERE Harwell Labo...|\n",
      "|     195|Queen's Univ., Be...|\n",
      "|     260|University of Mic...|\n",
      "|     260|University of Mic...|\n",
      "|     325|Oslo politikammer...|\n",
      "|     390|Harvard Univ., Ca...|\n",
      "|     390|Boston Univ., Bos...|\n",
      "|     455|Cornell Univ., It...|\n",
      "|     455|Cornell Univ., It...|\n",
      "|     520|IBM General Techn...|\n",
      "|     520|IBM Research Divi...|\n",
      "|     520|IBM Research Divi...|\n",
      "|     520|IBM Research Divi...|\n",
      "|     650|New York Univ., N...|\n",
      "|     780|Xerox Palo Alto R...|\n",
      "|     780|Xerox Palo Alto R...|\n",
      "|     780|Xerox Palo Alto R...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_affiliations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f62eeaed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|paper_id|         affiliation|count|\n",
      "+--------+--------------------+-----+\n",
      "|  569905|IBM and Universit...|   91|\n",
      "| 1202294|Open Grid Forum—G...|   88|\n",
      "| 1542970|University of Ten...|   65|\n",
      "|  418817|Humanoid Robotics...|   62|\n",
      "| 1731577|IBM Semiconductor...|   59|\n",
      "|  772121|IBM Research Divi...|   52|\n",
      "| 1038111|IBM Thomas J. Wat...|   46|\n",
      "| 1241693|INFN-CNAF V.le Be...|   44|\n",
      "| 1633898|NASA Goddard Spac...|   31|\n",
      "| 1077644|Carnegie Mellon U...|   31|\n",
      "| 1210078|IMEC, Kapeldreef ...|   29|\n",
      "|  994444|Lehrstuhl fur Ope...|   29|\n",
      "| 1229219|    No Affiliations,|   29|\n",
      "|  864278|Dept. of Electr. ...|   29|\n",
      "| 1423217|Shanghai Astronom...|   28|\n",
      "|  771289|IBM Research Divi...|   28|\n",
      "|  827034|The Artist Educat...|   28|\n",
      "|  963134|D. E. Shaw Resear...|   27|\n",
      "| 1972771|LinkedIn, Inc, Mo...|   27|\n",
      "| 1625041|           Microsoft|   27|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df \\\n",
    "    .groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3fbf49b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicate rows since here we need unique affiliations\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e55ad40",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove special characters\n",
    "unique_affiliations_df = clean_special_character(unique_affiliations_df, 'affiliation')\n",
    "### remove special letters\n",
    "unique_affiliations_df = clean_special_letters(unique_affiliations_df, 'affiliation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "042f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lowercase the affiliation col values\n",
    "unique_affiliations_df = unique_affiliations_df.withColumn('affiliation', lower(col('affiliation')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b74d2b75",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------------------------------------------------+-----+\n",
      "|paper_id|affiliation                                                                                                 |count|\n",
      "+--------+------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1369204 |texas a&m university, college station, tx, usa                                                              |3    |\n",
      "|1867776 |division of circuits & systems, school of eee, nanyang technological university, singapore, singapore       |3    |\n",
      "|963171  |ut-austin, austin, tx                                                                                       |3    |\n",
      "|1681339 |the university of iowa, iowa city, ia, usa                                                                  |3    |\n",
      "|1734280 |interact, universitt karlsruhe (th), karlsruhe, germany                                                     |2    |\n",
      "|1132509 |university of glasgow, glasgow, united kingdom                                                              |2    |\n",
      "|1512856 |newcastle university, newcastle upon tyne                                                                   |2    |\n",
      "|58590   |univ. of lancaster, lancaster, uk                                                                           |2    |\n",
      "|1972979 |california institute of technology, pasadena, ca, usa                                                       |2    |\n",
      "|1556477 |university of michigan, ann arbor, mi, usa                                                                  |2    |\n",
      "|1586250 |the university of texas at austin, austin, tx                                                               |2    |\n",
      "|1073455 |transilvania university, brasov, ro                                                                         |2    |\n",
      "|3485    |univ. of pittsburgh, pa                                                                                     |2    |\n",
      "|1765132 |newcastle university, newcastle upon tyne, united kingdom                                                   |2    |\n",
      "|58759   |vanderbilt univ., nashville, tn                                                                             |2    |\n",
      "|1764484 |chung hua university, hsinchu, taiwan roc                                                                   |2    |\n",
      "|860940  |computational sciences and mathematics department, pacific northwest national laboratory, richland, wa 99352|2    |\n",
      "|1864584 |irit - university of toulouse, toulouse, france                                                             |2    |\n",
      "|423955  |universidad complutense de madrid, madrid, spain                                                            |2    |\n",
      "|1907082 |george mason university, fairfax, va, usa                                                                   |2    |\n",
      "+--------+------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows\n",
    "unique_affiliations_df.groupby(['paper_id', 'affiliation']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "855886fd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop duplicates\n",
    "unique_affiliations_df = unique_affiliations_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0083171",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### filter out affiliations that are not part of the final_paper_author_id_df\n",
    "final_affiliations_df = unique_affiliations_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('affiliation')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1855220",
   "metadata": {},
   "source": [
    "# Load and clean Publication_venues df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d25f590",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/publication_venues.csv, schema path: ./schemas/publication_venues.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('publication_venue', 'String')]\n"
     ]
    }
   ],
   "source": [
    "### load publication_venues into schema\n",
    "publication_venue_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}publication_venues.csv', f'{SCHEMAS_FOLDER}publication_venues.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "026166d7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|   publication_venue|\n",
      "+--------+--------------------+\n",
      "|      65|Information Techn...|\n",
      "|     130|Proc. of the symp...|\n",
      "|     195|ACM Transactions ...|\n",
      "|     260|Information and C...|\n",
      "|     325|Computers and pen...|\n",
      "|     390|Information and C...|\n",
      "|     455|SIAM Journal on C...|\n",
      "|     520|IBM Journal of Re...|\n",
      "|     585|Journal of the AC...|\n",
      "|     650|Theoretical Compu...|\n",
      "|     715|            Computer|\n",
      "|     780|ACM Transactions ...|\n",
      "|     845|Methods and tools...|\n",
      "|     910|Information Proce...|\n",
      "|     975|ACM Transactions ...|\n",
      "|    1040|Information Proce...|\n",
      "|    1105|ACM Transactions ...|\n",
      "|    1170|Proc. of the 2nd ...|\n",
      "|    1235|Proc. of the inte...|\n",
      "|    1300|Foundations of co...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### trim publication_venue\n",
    "publication_venue_df = publication_venue_df.withColumn( \\\n",
    "    \"publication_venue\", trim(publication_venue_df.publication_venue) \\\n",
    ")\n",
    "publication_venue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6daa39b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|paper_id|publication_venue|\n",
      "+--------+-----------------+\n",
      "|       0|              148|\n",
      "+--------+-----------------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values inside publication venues dataframe\n",
    "null_values_publication_venue = publication_venue_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in publication_venue_df.columns])\n",
    "print(null_values_publication_venue.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eef3dd2b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### drop null values \n",
    "publication_venue_df=publication_venue_df.na.drop(how=\"any\", subset=['publication_venue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61aa0c6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+\n",
      "|paper_id|publication_venue|count|\n",
      "+--------+-----------------+-----+\n",
      "+--------+-----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "publication_venue_df \\\n",
    "    .groupby(['paper_id', 'publication_venue']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a55ddef7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### join publication_venue_df with final_paper_author_id_df\n",
    "### to remove publication venues of paper ids which are not part of final_paper_author_id_df\n",
    "final_publication_venues_df = publication_venue_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('publication_venue')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6ec60",
   "metadata": {},
   "source": [
    "# Load and clean Citations df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d24ec61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/citations.csv, schema path: ./schemas/citations.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('ref_ids', 'String')]\n",
      "+--------+--------------------+\n",
      "|paper_id|             ref_ids|\n",
      "+--------+--------------------+\n",
      "|      65|                null|\n",
      "|     130|                null|\n",
      "|     195|317424;317425;317573|\n",
      "|     260|                null|\n",
      "|     325|                null|\n",
      "|     390|                null|\n",
      "|     455|                null|\n",
      "|     520|       318368;323493|\n",
      "|     585|                null|\n",
      "|     650|                null|\n",
      "|     715|                null|\n",
      "|     780|318420;319233;319...|\n",
      "|     845|                null|\n",
      "|     910|                null|\n",
      "|     975|67604;318882;3718...|\n",
      "|    1040|                null|\n",
      "|    1105|289087;318014;318...|\n",
      "|    1170|                null|\n",
      "|    1235|                null|\n",
      "|    1300|                null|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load affiliation csv into schema\n",
    "citation_df = createDFFromFileAndSchema(spark, f'{FILES_FOLDER}citations.csv', f'{SCHEMAS_FOLDER}citations.csv')\n",
    "citation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "509f0ac2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "citation_df = citation_df.withColumn(\"ref_ids\", trim(citation_df.ref_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30286e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT paper_id)|\n",
      "+------------------------+\n",
      "|                 2092356|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### show how many paper ids are present in citation_df\n",
    "citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1afe6f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+\n",
      "|paper_id|ref_ids|count|\n",
      "+--------+-------+-----+\n",
      "+--------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows (no duplicates found)\n",
    "citation_df.groupby(['paper_id', 'ref_ids']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5c54e1c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|paper_id|ref_id|\n",
      "+--------+------+\n",
      "|65      |null  |\n",
      "|130     |null  |\n",
      "|195     |317424|\n",
      "|195     |317425|\n",
      "|195     |317573|\n",
      "|260     |null  |\n",
      "|325     |null  |\n",
      "|390     |null  |\n",
      "|455     |null  |\n",
      "|520     |318368|\n",
      "|520     |323493|\n",
      "|585     |null  |\n",
      "|650     |null  |\n",
      "|715     |null  |\n",
      "|780     |318420|\n",
      "|780     |319233|\n",
      "|780     |319290|\n",
      "|780     |319579|\n",
      "|780     |320813|\n",
      "|845     |null  |\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split citations so we can have clean data and seperate records {paper_id; ref_id}\n",
    "unique_citation_df = citation_df \\\n",
    "    .select(F.col(\"paper_id\"), F.explode_outer(F.split(F.col(\"ref_ids\"),\";\")).alias(\"ref_id\"))\n",
    "unique_citation_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "691822fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT paper_id)|\n",
      "+------------------------+\n",
      "|                 2092356|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### find the number of unique papers in unique_citation_df dataframe\n",
    "unique_citation_df.select(countDistinct('paper_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32d01f0e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\", trim(unique_citation_df.ref_id))\n",
    "### change data type of ref_id to Integer\n",
    "unique_citation_df = unique_citation_df.withColumn(\"ref_id\",unique_citation_df[\"ref_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "037eb73e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- ref_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_citation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce89c12f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|paper_id|ref_id|count|\n",
      "+--------+------+-----+\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 125:===============================>                         (5 + 4) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows\n",
    "unique_citation_df.groupby(['paper_id', 'ref_id']).count().where('count > 1').sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "995da1d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|paper_id|ref_id|\n",
      "+--------+------+\n",
      "|      65|  null|\n",
      "|     130|  null|\n",
      "|     260|  null|\n",
      "|     325|  null|\n",
      "|     390|  null|\n",
      "|     455|  null|\n",
      "|     585|  null|\n",
      "|     650|  null|\n",
      "|     715|  null|\n",
      "|     845|  null|\n",
      "|     910|  null|\n",
      "|    1040|  null|\n",
      "|    1170|  null|\n",
      "|    1235|  null|\n",
      "|    1300|  null|\n",
      "|    1365|  null|\n",
      "|    1430|  null|\n",
      "|    1495|  null|\n",
      "|    1560|  null|\n",
      "|    1625|  null|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### check whether some papers have null ref_ids\n",
    "### (those papers will still be kept in the dataframe for consistency)\n",
    "unique_citation_df.filter(unique_citation_df['ref_id'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c207d516",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### clean up ref ids if their paper_id is not a part of final_paper_author_id_df\n",
    "final_citation_df = unique_citation_df \\\n",
    "    .join(final_paper_author_id_df, ['paper_id'], 'inner') \\\n",
    "    .select(F.col('paper_id'), F.col('ref_id')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066b305",
   "metadata": {},
   "source": [
    "# Load and Research_interests in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "065c387e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/parsedData/research_interests.csv, schema path: ./schemas/research_interests.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('research_interests', 'String')]\n"
     ]
    }
   ],
   "source": [
    "### load research_interests csv into schema\n",
    "research_interests_df = createDFFromFileAndSchema( \\\n",
    "    spark, f'{FILES_FOLDER}research_interests.csv', f'{SCHEMAS_FOLDER}research_interests.csv' \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "296ee220",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- research_interests: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+\n",
      "|author_id|  research_interests|\n",
      "+---------+--------------------+\n",
      "|       17|HIV disease;Inter...|\n",
      "|       34|associate polynom...|\n",
      "|       51|metadata element;...|\n",
      "|       68|Web Service;conte...|\n",
      "|       85|intermediate key;...|\n",
      "|      102|feedback loop;dif...|\n",
      "|      119|Rough Set;nomal C...|\n",
      "|      136|MATLAB toolbox;li...|\n",
      "|      153|Byzantine agreeme...|\n",
      "|      170|Ein objektorienti...|\n",
      "|      187|portable device;A...|\n",
      "|      204|Integer-valued pr...|\n",
      "|      221|stock price;stock...|\n",
      "|      238|Hypermedia Synchr...|\n",
      "|      255|computer-mediated...|\n",
      "|      272|Dijkstra method;o...|\n",
      "|      289|low-frequency act...|\n",
      "|      306|copyright process...|\n",
      "|      323|uncertain informa...|\n",
      "|      340|histology image;s...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### remove leading and trailing spaces\n",
    "research_interests_df = research_interests_df \\\n",
    "    .withColumn(\"research_interests\", trim(research_interests_df.research_interests))\n",
    "\n",
    "research_interests_df.printSchema()\n",
    "research_interests_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b967513d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|author_id|research_interests|\n",
      "+---------+------------------+\n",
      "|        0|             15398|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 128:=================================================>       (7 + 1) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for null values in the affiliations column\n",
    "research_interests_df \\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in research_interests_df.columns]).show()\n",
    "### drop null values (it is safe since we dont need research_interests for any computation)\n",
    "research_interests_df = research_interests_df.na.drop(how=\"any\", subset=['research_interests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16cf3d09",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------------+\n",
      "|author_id|research_interest                        |\n",
      "+---------+-----------------------------------------+\n",
      "|17       |HIV disease                              |\n",
      "|17       |Internet resource                        |\n",
      "|17       |World-Wide Web                           |\n",
      "|17       |clinical management                      |\n",
      "|34       |associate polynomial term                |\n",
      "|34       |bivariate polynomial                     |\n",
      "|34       |difficult computational problem          |\n",
      "|34       |novel polynomial                         |\n",
      "|34       |polynomial multiplication problem        |\n",
      "|34       |polynomial term                          |\n",
      "|34       |reachability problem                     |\n",
      "|34       |Probabilistic Reachability               |\n",
      "|34       |Reachability analysis                    |\n",
      "|34       |better time complexity                   |\n",
      "|51       |metadata element                         |\n",
      "|51       |metadata record                          |\n",
      "|51       |Dublin Core metadata                     |\n",
      "|51       |PaperBase extracts metadata              |\n",
      "|51       |Semi automated metadata extraction       |\n",
      "|51       |applicationAs metadata providers increase|\n",
      "+---------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### split research interests\n",
    "### so we can have clean data and separate records { paper_id; research_interest }\n",
    "unique_research_interests_df = research_interests_df \\\n",
    "    .select(F.col(\"author_id\"), F.explode(F.split(F.col(\"research_interests\"),\";\")) \\\n",
    "    .alias(\"research_interest\"))\n",
    "\n",
    "unique_research_interests_df.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00ef0111",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### remove leading and trailing spaces\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn(\"research_interest\", trim(unique_research_interests_df.research_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4cacff62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### clean special characters and special letters\n",
    "unique_research_interests_df = clean_special_character(unique_research_interests_df, 'research_interest')\n",
    "unique_research_interests_df = clean_special_letters(unique_research_interests_df, 'research_interest')\n",
    "### lowercase research_interests\n",
    "unique_research_interests_df = unique_research_interests_df \\\n",
    "    .withColumn('research_interest', lower(col('research_interest')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d855bc9f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:04:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:05:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:05:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 134:============>                                            (2 + 7) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+\n",
      "|author_id|   research_interest|count|\n",
      "+---------+--------------------+-----+\n",
      "|    35105| computational model|    2|\n",
      "|    35105|       ranking model|    2|\n",
      "|    53991|     virtual subnets|    2|\n",
      "|   149208|      gaas cap layer|    2|\n",
      "|   374991|      fast algorithm|    2|\n",
      "|   390545|3-d protein struc...|    2|\n",
      "|   390545|   protein structure|    2|\n",
      "|   495476|       average cache|    2|\n",
      "|   495476|    cache management|    2|\n",
      "|   825909|comprehensive glo...|    2|\n",
      "|   997050|cache timing atta...|    2|\n",
      "|  1341744|high throughput g...|    2|\n",
      "|  1341744|sample storage ma...|    2|\n",
      "|  1341744|  supplementary data|    2|\n",
      "|  1416750|  proposed algorithm|    2|\n",
      "|   390545|     model retrieval|    2|\n",
      "|   374991| multiple dielectric|    2|\n",
      "|   495476|          new router|    2|\n",
      "|    53991|  multicast protocol|    2|\n",
      "|    53991|dynamic multicast...|    2|\n",
      "+---------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 134:===============================>                         (5 + 4) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### check for duplicate rows:\n",
    "unique_research_interests_df \\\n",
    "    .groupby(['author_id', 'research_interest']) \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False).show()\n",
    "\n",
    "### drop duplicates\n",
    "unique_research_interests_df=unique_research_interests_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c32ed493",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# clean up research interests if their author id is not a part of final_paper_author_id_df\n",
    "final_research_interests_df = unique_research_interests_df \\\n",
    "    .join(final_paper_author_id_df, ['author_id'], 'inner') \\\n",
    "    .select(F.col('author_id'), F.col('research_interest')) \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10818814",
   "metadata": {},
   "source": [
    "# Run Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36310d",
   "metadata": {},
   "source": [
    "### Q1.2 Compute paper count per unique affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08f3126d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "paper_count_per_affiliation_df = final_affiliations_df \\\n",
    "    .groupBy('affiliation') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"papers_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b2ce4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "970892"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### count the number of results\n",
    "paper_count_per_affiliation_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "041807a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 198:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[636.761s][warning][gc,alloc] Executor task launch worker for task 6.0 in stage 207.0 (TID 606): Retried waiting for GCLocker too often allocating 2097154 words\n",
      "[636.789s][warning][gc,alloc] Executor task launch worker for task 6.0 in stage 207.0 (TID 606): Retried waiting for GCLocker too often allocating 2097154 words\n",
      "[636.792s][warning][gc,alloc] Executor task launch worker for task 7.0 in stage 207.0 (TID 607): Retried waiting for GCLocker too often allocating 2097154 words\n",
      "[636.800s][warning][gc,alloc] Executor task launch worker for task 7.0 in stage 207.0 (TID 607): Retried waiting for GCLocker too often allocating 2097154 words\n",
      "[636.894s][warning][gc,alloc] Executor task launch worker for task 5.0 in stage 207.0 (TID 605): Retried waiting for GCLocker too often allocating 2097154 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:08:39 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:08:39 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:08:39 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:08:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 207:======================================>                  (6 + 3) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------+------------+\n",
      "|affiliation                                                                                      |papers_count|\n",
      "+-------------------------------------------------------------------------------------------------+------------+\n",
      "|carnegie-mellon univ., pittsburgh, pa                                                            |386         |\n",
      "|ibm japan, ltd., science institute                                                               |1           |\n",
      "|univ. de sevilla, seville, spain                                                                 |1           |\n",
      "|beyond words publishing, portland, or                                                            |1           |\n",
      "|university of miami, coral gables, fl                                                            |45          |\n",
      "|baylor college of medicine                                                                       |11          |\n",
      "|univ. of alberta, edmonton                                                                       |21          |\n",
      "|technical univ., warsaw, poland                                                                  |2           |\n",
      "|univ. laval, que´bec, p.q., canada                                                               |3           |\n",
      "|c&c information research laboratories, kawasaki, japan                                           |1           |\n",
      "|univ. of torino, torino. italy                                                                   |1           |\n",
      "|itci, romania                                                                                    |1           |\n",
      "|technical univ. berlin, w. berlin, w. germany                                                    |1           |\n",
      "|dipartimento di informatica e sistemistica dell'universita degli studi di roma la sapienza, italy|1           |\n",
      "|univ. of texas, arlington                                                                        |28          |\n",
      "|computer science department, university of north dakota, grand forks, north dakota               |1           |\n",
      "|hebrew university                                                                                |58          |\n",
      "|selenia s.p.a, rome, italy                                                                       |1           |\n",
      "|univ. of patras, patras, greece                                                                  |33          |\n",
      "|univ. of maryland, baltimore and univ. of maryland, college park                                 |1           |\n",
      "+-------------------------------------------------------------------------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paper_count_per_affiliation_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc2f1",
   "metadata": {},
   "source": [
    "### Q1.1 Validate precomputed paper counts, citation (ref) counts and h-indexes (per author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb36be",
   "metadata": {},
   "source": [
    "#### How to compute h-index for a specific author\n",
    "1. Retrieve all publications of the author\n",
    "2. Calculate the number of references per publication\n",
    "3. Sort the results in descending order\n",
    "4. Find a threshold N, where N top publications have at least N references each. N is the h-index of the author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82c4fe33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 1-2 Calculate the number of references per publication\n",
    "refs_per_paper_count_df = final_citation_df \\\n",
    "    .groupBy(\"paper_id\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\",\"paper_references\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94d3e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2029225"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_per_paper_count_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d2dc42a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 264:>                (0 + 8) / 9][Stage 265:>                (0 + 0) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[768.761s][warning][gc,alloc] Executor task launch worker for task 2.0 in stage 264.0 (TID 730): Retried waiting for GCLocker too often allocating 2097154 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:10:51 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784.231s][warning][gc,alloc] Executor task launch worker for task 6.0 in stage 274.0 (TID 752): Retried waiting for GCLocker too often allocating 1048578 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:11:06 WARN TaskMemoryManager: Failed to allocate a page (8388608 bytes), try again.\n",
      "22/01/21 13:11:07 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[786.566s][warning][gc,alloc] Executor task launch worker for task 1.0 in stage 274.0 (TID 747): Retried waiting for GCLocker too often allocating 2097154 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:11:09 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN TaskMemoryManager: Failed to allocate a page (12169818 bytes), try again.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:11:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 274:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+---------+--------------+-------+-----------+----------------+\n",
      "|paper_id|        name|author_id|citation_count|h_index|paper_count|paper_references|\n",
      "+--------+------------+---------+--------------+-------+-----------+----------------+\n",
      "| 2015219|      dahlin|   541094|             0|      0|          1|             806|\n",
      "| 2015219|    kaminsky|   794803|           868|     14|         48|             806|\n",
      "|  719353|weispfenning|   631885|           559|     12|         46|             772|\n",
      "|  719353|   grabmeier|   565318|           109|      4|         13|             772|\n",
      "|  719353|    kaltofen|    84799|          1252|     21|        119|             772|\n",
      "| 1221204|        wang|  1051702|            16|      1|          1|             555|\n",
      "| 1583653|       meyer|   545269|            26|      3|         16|             527|\n",
      "| 1583653|       ebert|   521293|            61|      5|         40|             527|\n",
      "| 1583653|      kerren|   244574|           149|      7|         39|             527|\n",
      "| 1376720|       meyer|   838019|           280|     11|         39|             524|\n",
      "| 1376720|     sanders|  1602439|          1170|     18|        110|             524|\n",
      "| 1376720|      sibeyn|   811218|           199|      8|         48|             524|\n",
      "| 1221200|       hauck|   715936|          1073|     17|         82|             523|\n",
      "| 1221200|       dehon|  1062188|           948|     18|         80|             523|\n",
      "|  932477|      benini|    30559|          4815|     33|        366|             476|\n",
      "|  932477|     micheli|  1365751|          1009|     18|        115|             476|\n",
      "| 1504996|     schirra|  1217682|           260|     10|         30|             435|\n",
      "|  936367|       bartz|   100900|           252|      8|         42|             412|\n",
      "|  936367|       preim|   516029|           208|      8|         67|             412|\n",
      "| 1442657|    ringwood|   239225|            51|      3|         12|             408|\n",
      "+--------+------------+---------+--------------+-------+-----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### 3 Join [papers per author] with [references per paper] and sort the results in descending order\n",
    "author_papers_with_ref_count = final_paper_author_id_df.join(refs_per_paper_count_df, 'paper_id') \\\n",
    "    .sort(col(\"paper_references\").desc())\n",
    "\n",
    "print(author_papers_with_ref_count.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "656a90c3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### add index column to table to ease h-index calculation\n",
    "window = Window.partitionBy(author_papers_with_ref_count['author_id']) \\\n",
    "    .orderBy(desc(\"paper_references\"), desc(\"paper_id\"))\n",
    "\n",
    "indexed_grouped_papers_df = author_papers_with_ref_count.select('*', rank().over(window).alias('index'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "670dbb5c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[876.054s][warning][gc,alloc] Executor task launch worker for task 3.0 in stage 308.0 (TID 835): Retried waiting for GCLocker too often allocating 131074 words\n",
      "[876.058s][warning][gc,alloc] Executor task launch worker for task 2.0 in stage 308.0 (TID 834): Retried waiting for GCLocker too often allocating 131074 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 13:12:38 ERROR Executor: Exception in task 3.0 in stage 308.0 (TID 835)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/01/21 13:12:38 ERROR Executor: Exception in task 2.0 in stage 308.0 (TID 834)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/01/21 13:12:38 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 3.0 in stage 308.0 (TID 835),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/01/21 13:12:38 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 2.0 in stage 308.0 (TID 834),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 3.0 in stage 308.0 (TID 835) (t-193.vc-graz.ac.at executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\n",
      "22/01/21 13:12:38 ERROR TaskSetManager: Task 3 in stage 308.0 failed 1 times; aborting job\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 4.0 in stage 308.0 (TID 836) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 7.0 in stage 308.0 (TID 839) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 0.0 in stage 308.0 (TID 832) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 6.0 in stage 308.0 (TID 838) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 5.0 in stage 308.0 (TID 837) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 8.0 in stage 308.0 (TID 840) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "22/01/21 13:12:38 WARN TaskSetManager: Lost task 1.0 in stage 308.0 (TID 833) (t-193.vc-graz.ac.at executor driver): TaskKilled (Stage cancelled)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/px/khc4q1n94cnblzp3k7s518xm0000gn/T/ipykernel_23849/4148641814.py\", line 8, in <module>\n",
      "    print(h_indexed_papers.show(100, False))\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/pyspark/sql/dataframe.py\", line 502, in show\n",
      "    print(self._jdf.showString(n, int_truncate, vertical))\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\", line 1309, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/var/folders/px/khc4q1n94cnblzp3k7s518xm0000gn/T/ipykernel_23849/4148641814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_indexed_papers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_truncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(61, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_pdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m                         \u001b[0;31m# drop into debugger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36m_showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;34m'traceback'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;34m'ename'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;34m'evalue'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         }\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mgateway_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_return_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;31m# Note: technically this should return a bytestring 'str' rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1034\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_new_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\u001b[0m in \u001b[0;36m_create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             self.gateway_property, self)\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_java_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_thread_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\u001b[0m in \u001b[0;36mconnect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m                 self.socket = self.ssl_context.wrap_socket(\n\u001b[1;32m    401\u001b[0m                     self.socket, server_hostname=self.java_address)\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "h_indexed_papers = indexed_grouped_papers_df \\\n",
    "    .withColumn(\"possible_h_index\", \\\n",
    "                when( \\\n",
    "                    indexed_grouped_papers_df.index <= indexed_grouped_papers_df.paper_references, \\\n",
    "                    indexed_grouped_papers_df.index \\\n",
    "                    ).otherwise(0) \\\n",
    "                )\n",
    "print(h_indexed_papers.show(100, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8143a56",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_grouped_by_author_papers_df = h_indexed_papers.groupBy('author_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa8f6e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "h_indexed_aggregated_papers_df = h_indexed_grouped_by_author_papers_df.agg( \\\n",
    "        F.count(\"paper_id\").alias(\"validated_paper_count\"),\n",
    "        F.sum(\"paper_references\").alias(\"validated_paper_count\"),\n",
    "        F.max(\"possible_h_index\").alias(\"validated_h_index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5123f",
   "metadata": {},
   "source": [
    "#### Computed results for `validated_paper_count`, `validated_paper_count` and `validated_h_index`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b40ed9",
   "metadata": {},
   "source": [
    "__Final resulting dataframe is unique_authors_with_validated_cols_df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join the computation results with author dataframe\n",
    "### to be able to compare received values with the precomputed values\n",
    "unique_authors_with_validated_cols_df = h_indexed_aggregated_papers_df.join(author_df, 'author_id', 'inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61de01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### count the number of entries\n",
    "unique_authors_with_validated_cols_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_with_validated_cols_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac42142",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed h-indexes differ from the validated h-indexes\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_h_index\"] != unique_authors_with_validated_cols_df[\"h_index\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the info: check how many precomputed author citation counts differ from the validated citation counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_citation_count\"] != unique_authors_with_validated_cols_df[\"citation_count\"]\n",
    "unique_authors_with_validated_cols_df \\\n",
    "    .filter(filter_condition) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/py4j-0.10.9.2-src.zip/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "### For the info: check how many precomputed author paper counts differ from the validated paper counts\n",
    "filter_condition = unique_authors_with_validated_cols_df[\"validated_paper_count\"] != unique_authors_with_validated_cols_df[\"paper_count\"]\n",
    "unique_authors_with_validated_cols_df.filter(filter_condition).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a64b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79c823",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a89293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1408e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
