{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import createDFFromFileAndSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('read data through spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes from cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: ./assets/cleanedDFsData/authors.csv, schema path: ./schemas/author.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('citation_count', 'Integer'), ('h_index', 'Integer'), ('name', 'String'), ('paper_count', 'Integer')]\n",
      "File path: ./assets/cleanedDFsData/research_interests.csv, schema path: ./schemas/research_interests.csv\n",
      "Types from schema: [('author_id', 'Integer'), ('research_interests', 'String')]\n",
      "File path: ./assets/cleanedDFsData/papers.csv, schema path: ./schemas/paper.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('title', 'String'), ('year', 'Integer')]\n",
      "File path: ./assets/cleanedDFsData/paper_author.csv, schema path: ./schemas/paper_authors.csv\n",
      "Types from schema: [('authors', 'String'), ('paper_id', 'Integer')]\n",
      "File path: ./assets/cleanedDFsData/citations.csv, schema path: ./schemas/citations.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('ref_ids', 'String')]\n",
      "File path: ./assets/cleanedDFsData/affiliations.csv, schema path: ./schemas/affiliation.csv\n",
      "Types from schema: [('affiliations', 'String'), ('paper_id', 'Integer')]\n",
      "File path: ./assets/cleanedDFsData/publication_venues.csv, schema path: ./schemas/publication_venues.csv\n",
      "Types from schema: [('paper_id', 'Integer'), ('publication_venue', 'String')]\n"
     ]
    }
   ],
   "source": [
    "CLEAN_DATA_FOLDER = './assets/cleanedDFsData/'\n",
    "SCHEMAS_FOLDER = './schemas/'\n",
    "\n",
    "# here we should probably update some schemas.\n",
    "# Because those were made for the initial tables,\n",
    "# but now we have more columns with the computed values, for example.\n",
    "\n",
    "author_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}authors.csv', f'{SCHEMAS_FOLDER}author.csv')\n",
    "research_interests_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}research_interests.csv', f'{SCHEMAS_FOLDER}research_interests.csv')\n",
    "\n",
    "paper_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}papers.csv', f'{SCHEMAS_FOLDER}paper.csv')\n",
    "paper_author_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}paper_author.csv', f'{SCHEMAS_FOLDER}paper_authors.csv')\n",
    "citation_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}citations.csv', f'{SCHEMAS_FOLDER}citations.csv')\n",
    "affiliation_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}affiliations.csv', f'{SCHEMAS_FOLDER}affiliation.csv')\n",
    "publication_venue_df = createDFFromFileAndSchema(spark, f'{CLEAN_DATA_FOLDER}publication_venues.csv', f'{SCHEMAS_FOLDER}publication_venues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'research_interests'>\n",
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- research_interests: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(research_interests_df[\"research_interests\"])\n",
    "research_interests_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create String Indexers and One Hot Encoders for the research_interests_df String columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StringIndexer\n",
    "carr_indexer = StringIndexer(inputCol=\"research_interests\", outputCol=\"research_interests_index\")\n",
    "\n",
    "# Create a OneHotEncoder\n",
    "carr_encoder = OneHotEncoder(inputCol=\"research_interests_index\", outputCol=\"research_interests_fact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create String Indexers and One Hot Encoders for the research_interests_df String columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
