{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e096de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd;\n",
    "import csv;\n",
    "import numpy as np;\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "import re\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600b2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName('Read& parse text data file in pyspark')\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sqlContext = SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e0ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_KEYS_MAP = {\n",
    "    \"#index\": \"paper_id\",\n",
    "    \"#*\": \"title\",\n",
    "    \"#@\": \"authors\",\n",
    "    \"#o\": \"affiliations\",\n",
    "    \"#t\": \"year\",\n",
    "    \"#c\": \"publication_venue\",\n",
    "    \"#%\": \"ref_ids\",\n",
    "    \"#!\": \"abstract\",\n",
    "}\n",
    "PAPER_DATASET_PATH = './assets/AMiner-Paper.txt'\n",
    "\n",
    "AUTHOR_KEYS_MAP = {\n",
    "    \"#index\": \"author_id\",\n",
    "    \"#n\": \"name\",\n",
    "    \"#pc\": \"paper_count\",\n",
    "    \"#cn\": \"citation_count\",\n",
    "    \"#t\": \"research_interests\",\n",
    "    \"#hi\": \"h_index\", \n",
    "#     \"#upi\": \"u_p_index\", \n",
    "#     \"#pi\": \"p_index\"\n",
    "#     \"#a\": \"affiliations\",\n",
    "}\n",
    "AUTHOR_DATASET_PATH = './assets/AMiner-Author.txt'\n",
    "AUTHOR_2_PAPER_DATASET_PATH = './assets/AMiner-Author2Paper.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ea5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipDatasetWithIndex(datasetPath):\n",
    "    lines = sc.textFile(datasetPath).zipWithIndex()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b305f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchangeElementAtIndexToOne(index, zeroArray):\n",
    "    zeroArray[index] = 1;\n",
    "\n",
    "def doCumSumForIndexRows(lines):\n",
    "    # Find the starting row of each data entry\n",
    "    pos = lines.filter(lambda x: \"#index\" in x[0]).map(lambda x: x[1]).collect() \n",
    "    zeroArray = np.zeros(lines.count(), dtype=int)\n",
    "    for element in pos:\n",
    "        exchangeElementAtIndexToOne(element, zeroArray)\n",
    "    # Calculate cumulative sum of starting data entry indexes\n",
    "    summedArray = np.cumsum(zeroArray)\n",
    "    return summedArray;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63589899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBroarcastedTuple(x, arrayOfStartRowIndexes):\n",
    "    return (arrayOfStartRowIndexes.value[x[1]], x[0])\n",
    "\n",
    "def convertDataIntoIndexedTuples(datasetLines, cumSummedIndexRowsArray):\n",
    "    broadcastedArray = sc.broadcast(cumSummedIndexRowsArray);\n",
    "    convertedData = datasetLines.map(lambda dataLine: createBroarcastedTuple(dataLine, broadcastedArray))\n",
    "    return convertedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33beefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_get = lambda l, x, d=None: d if not l[x] else l[x] # safe getter of list values\n",
    "\n",
    "def splitIntoKeyValue(stringToSplit, keyMap):\n",
    "    formattedValue = stringToSplit \n",
    "    if type(stringToSplit) is str:\n",
    "        if len(formattedValue) > 0:\n",
    "            formattedValue = formattedValue.split(\" \", 1)\n",
    "            key = list_get(formattedValue, 0)\n",
    "            mappedKey = keyMap.get(key)\n",
    "            if (mappedKey):\n",
    "                formattedValue = { mappedKey: list_get(formattedValue, 1, '') }\n",
    "            else:\n",
    "                formattedValue = {}\n",
    "        else:\n",
    "            formattedValue = {}\n",
    "    return formattedValue\n",
    "\n",
    "def appendStringOrListIntoList(lst, elToAppend):\n",
    "    if elToAppend is not None:\n",
    "        if type(elToAppend) == str:\n",
    "            lst.append(elToAppend)\n",
    "        else:\n",
    "            lst = lst + elToAppend\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7623d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper related\n",
    "def convertPaperFeatures(dct, affiliations_data={}, papers_data={}, paper_authors_data={}, publication_venues_data={}, refs_data={}):\n",
    "    if dct.get(\"paper_id\"):\n",
    "        paper_id = dct.get(\"paper_id\")   \n",
    "        affiliations_data[\"paper_id\"] = paper_id\n",
    "        papers_data[\"paper_id\"] = paper_id\n",
    "        paper_authors_data[\"paper_id\"] = paper_id\n",
    "        publication_venues_data[\"paper_id\"] = paper_id\n",
    "        refs_data[\"paper_id\"] = paper_id\n",
    "    elif dct.get(\"affiliations\"):\n",
    "        affiliations_data[\"affiliations\"] = dct.get(\"affiliations\")\n",
    "    elif dct.get(\"ref_ids\"):\n",
    "        appendStringOrListIntoList(refs_data[\"ref_ids\"], dct.get(\"ref_ids\"))\n",
    "    elif dct.get(\"authors\"):\n",
    "        paper_authors_data[\"authors\"] = dct.get(\"authors\")\n",
    "    elif dct.get(\"title\"):\n",
    "        papers_data[\"title\"] = dct.get(\"title\")\n",
    "    elif dct.get(\"year\"):\n",
    "        papers_data[\"year\"] = dct.get(\"year\")\n",
    "    elif dct.get(\"publication_venue\"):\n",
    "        publication_venues_data[\"publication_venue\"] = dct.get(\"publication_venue\")\n",
    "        \n",
    "# Paper related\n",
    "def reducePaperFeaturesToDict(featureA='', featureB='', keyMap={}):\n",
    "    papers_data = {}\n",
    "    affiliations_data = {}\n",
    "    paper_authors_data = {}\n",
    "    publication_venues_data = {}\n",
    "    refs_data = { \"ref_ids\": [] }\n",
    "    try:        \n",
    "        splittedA = splitIntoKeyValue(featureA, keyMap);\n",
    "        splittedB = splitIntoKeyValue(featureB, keyMap);\n",
    "        \n",
    "        if (splittedA.get('papers_data')):\n",
    "            papers_data = splittedA.get('papers_data')\n",
    "            affiliations_data = splittedA.get('affiliations_data')\n",
    "            paper_authors_data = splittedA.get('paper_authors_data')\n",
    "            publication_venues_data = splittedA.get('publication_venues_data')\n",
    "            refs_data = splittedA.get('refs_data')\n",
    "        else:\n",
    "            convertPaperFeatures(splittedA, affiliations_data, papers_data, paper_authors_data, publication_venues_data, refs_data)\n",
    "        convertPaperFeatures(splittedB, affiliations_data, papers_data, paper_authors_data, publication_venues_data, refs_data)\n",
    "        return {\n",
    "            \"papers_data\": papers_data,\n",
    "            \"affiliations_data\": affiliations_data,\n",
    "            \"paper_authors_data\": paper_authors_data,\n",
    "            \"publication_venues_data\": publication_venues_data,\n",
    "            \"refs_data\": refs_data\n",
    "        }\n",
    "    except Exception as error:\n",
    "        print(\"ERROR: \", featureA, featureB, error)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aacf1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author related\n",
    "def convertAuthorFeatures(dct, authors_data={}, research_interests_data={}):\n",
    "    if dct.get(\"author_id\"):\n",
    "        author_id = dct.get(\"author_id\")   \n",
    "        authors_data[\"author_id\"] = author_id\n",
    "        research_interests_data[\"author_id\"] = author_id\n",
    "    elif dct.get(\"name\"):\n",
    "        authors_data[\"name\"] = dct.get(\"name\")\n",
    "    elif dct.get(\"paper_count\"):\n",
    "        authors_data[\"paper_count\"] = dct.get(\"paper_count\")\n",
    "    elif dct.get(\"citation_count\"):\n",
    "        authors_data[\"citation_count\"] = dct.get(\"citation_count\")\n",
    "    elif dct.get(\"research_interests\"):\n",
    "        research_interests_data[\"research_interests\"] = dct.get(\"research_interests\")\n",
    "    elif dct.get(\"h_index\"):\n",
    "        authors_data[\"h_index\"] = dct.get(\"h_index\")\n",
    "    elif dct.get(\"publication_venue\"):\n",
    "        authors_data[\"publication_venue\"] = dct.get(\"publication_venue\")\n",
    "        \n",
    "# Author related\n",
    "def reduceAuthorFeaturesToDict(featureA='', featureB='', keyMap={}):\n",
    "    authors_data = {}\n",
    "    research_interests_data = {}\n",
    "    try:        \n",
    "        splittedA = splitIntoKeyValue(featureA, keyMap);\n",
    "        splittedB = splitIntoKeyValue(featureB, keyMap);\n",
    "        \n",
    "        if (splittedA.get('authors_data')):\n",
    "            authors_data = splittedA.get('authors_data')\n",
    "            research_interests_data = splittedA.get('research_interests_data')\n",
    "        else: # If it's first reduce run, accumulator === the first item of the list. So the item should be converted\n",
    "            convertAuthorFeatures(splittedA, authors_data, research_interests_data)\n",
    "        convertAuthorFeatures(splittedB, authors_data, research_interests_data)\n",
    "        return {\n",
    "            \"authors_data\": authors_data,\n",
    "            \"research_interests_data\": research_interests_data,\n",
    "        }\n",
    "    except Exception as error:\n",
    "        print(\"ERROR: \", featureA, featureB, error)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615a9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDataIntoDicts(objects, dataKeyMap, reducer):\n",
    "    reducedObjects = objects.reduceByKey(lambda a, b: reducer(a, b, dataKeyMap))\n",
    "    print(reducedObjects.sortByKey(ascending=False).first())\n",
    "    mappedDicts = reducedObjects.map(lambda x: x[1]) # retrieve dicts from the tuples\n",
    "    return mappedDicts\n",
    "\n",
    "def convertDictsArrayIntoCSVFile(dictsArray, fileName):\n",
    "    df = sqlContext.createDataFrame(dictsArray)\n",
    "    print(df.show())\n",
    "    # Save data to csv file\n",
    "    df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946bedef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paperTextLines = zipDatasetWithIndex(PAPER_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5811092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "summedArrayOfPaperIndexRows = doCumSumForIndexRows(paperTextLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bfa835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperItemTuples = convertDataIntoIndexedTuples(paperTextLines, summedArrayOfPaperIndexRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfcac749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "[Stage 8:========================================================>(64 + 1) / 65]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2092356, {'papers_data': {'paper_id': '2092356', 'title': 'Reliability prediction through system modeling', 'year': '2013'}, 'affiliations_data': {'paper_id': '2092356', 'affiliations': 'Dept of Computer Engg IIT(BHU) Varanasi, India;Reactor Safety Division Bhabha Atomic Research Centre Dept of Atomic Energy, Govt of India;Dept of Computer Engg IIT(BHU) Varanasi, India'}, 'paper_authors_data': {'paper_id': '2092356', 'authors': 'Lalit Kumar Singh;Gopika Vinod;A. K. Tripathi'}, 'publication_venues_data': {'paper_id': '2092356', 'publication_venue': 'ACM SIGSOFT Software Engineering Notes'}, 'refs_data': {'ref_ids': ['215579', '333683', '511383', '594375', '641666', '763878', '966860', '1056157'], 'paper_id': '2092356'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paperDictsArray = convertDataIntoDicts(paperItemTuples, PAPER_KEYS_MAP, reducePaperFeaturesToDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08815e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mapPapersData(data):\n",
    "    refs_data = data[\"refs_data\"]\n",
    "    refs_data['ref_ids'] = ';'.join(refs_data['ref_ids'])\n",
    "    return refs_data\n",
    "\n",
    "papers_d = paperDictsArray.map(lambda x: x[\"papers_data\"])\n",
    "affiliations_d = paperDictsArray.map(lambda x: x[\"affiliations_data\"])\n",
    "paper_authors_d = paperDictsArray.map(lambda x: x[\"paper_authors_data\"])\n",
    "publication_venues_d = paperDictsArray.map(lambda x: x[\"publication_venues_data\"])\n",
    "paper_refs_d = paperDictsArray.map(lambda x:mapPapersData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8cf3c692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:================================================>       (56 + 8) / 65]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2092356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 63:=======================================================>(64 + 1) / 65]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(papers_d.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347d9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+\n",
      "|paper_id|               title|year|\n",
      "+--------+--------------------+----+\n",
      "|      65|Direct file organ...|1984|\n",
      "|     130|An introduction t...|1983|\n",
      "|     195|On solving almost...|1984|\n",
      "|     260|Connections betwe...|1984|\n",
      "|     325|Computers and pen...|1984|\n",
      "|     390|Relativizations c...|1984|\n",
      "|     455|On the optimum ch...|1984|\n",
      "|     520|All points addres...|1984|\n",
      "|     585|Optimum Head Sepa...|1984|\n",
      "|     650|A parallel-design...|1984|\n",
      "|     715|Computer - IEEE C...|1984|\n",
      "|     780|Experience with G...|1984|\n",
      "|     845|Code generation a...|1984|\n",
      "|     910|On estimating acc...|1984|\n",
      "|     975|A distributed alt...|1985|\n",
      "|    1040|A comparison of t...|1984|\n",
      "|    1105|Generalizing spec...|1985|\n",
      "|    1170|Real time graphic...|1984|\n",
      "|    1235|Common and uncomm...|1984|\n",
      "|    1300|Foundations of co...|1985|\n",
      "+--------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|        affiliations|paper_id|\n",
      "+--------------------+--------+\n",
      "|The Queen's Unive...|      65|\n",
      "|Univ. of Karlsruh...|     130|\n",
      "|AERE Harwell Labo...|     195|\n",
      "|University of Mic...|     260|\n",
      "|Oslo politikammer...|     325|\n",
      "|Harvard Univ., Ca...|     390|\n",
      "|Cornell Univ., It...|     455|\n",
      "|IBM General Techn...|     520|\n",
      "|               -;-;-|     585|\n",
      "|New York Univ., N...|     650|\n",
      "|                   -|     715|\n",
      "|Xerox Palo Alto R...|     780|\n",
      "|Univ. of Californ...|     845|\n",
      "|University of Bol...|     910|\n",
      "|AT & T Bell Labor...|     975|\n",
      "|Cornell Univ., It...|    1040|\n",
      "|University of Mar...|    1105|\n",
      "|Laboratoire de Ps...|    1170|\n",
      "|Yale Univ., New H...|    1235|\n",
      "|                 -;-|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             authors|paper_id|\n",
      "+--------------------+--------+\n",
      "| K Devine;F J. Smith|      65|\n",
      "|J Wolff von Guden...|     130|\n",
      "|J. K. Reid;A. Jen...|     195|\n",
      "|William G. Golson...|     260|\n",
      "|    Stein Schjolberg|     325|\n",
      "|W Ian Gasarch;Ste...|     390|\n",
      "|Sam Toueg;Özalp B...|     455|\n",
      "|Frederick H. Dill...|     520|\n",
      "|A. R. Calderbank;...|     585|\n",
      "|         Uzi Vishkin|     650|\n",
      "|      Stephen S. Yau|     715|\n",
      "|Michael D. Schroe...|     780|\n",
      "|         S L. Graham|     845|\n",
      "|D Maio;M R. Scala...|     910|\n",
      "|         Pamela Zave|     975|\n",
      "|G. Salton;E. Voor...|    1040|\n",
      "|Douglas D. Dunlop...|    1105|\n",
      "|Patrick Peruch;Vi...|    1170|\n",
      "| Robert J. Sternberg|    1235|\n",
      "|Curtis Roads;John...|    1300|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|   publication_venue|\n",
      "+--------+--------------------+\n",
      "|      65|Information Techn...|\n",
      "|     130|Proc. of the symp...|\n",
      "|     195|ACM Transactions ...|\n",
      "|     260|Information and C...|\n",
      "|     325|Computers and pen...|\n",
      "|     390|Information and C...|\n",
      "|     455|SIAM Journal on C...|\n",
      "|     520|IBM Journal of Re...|\n",
      "|     585|Journal of the AC...|\n",
      "|     650|Theoretical Compu...|\n",
      "|     715|            Computer|\n",
      "|     780|ACM Transactions ...|\n",
      "|     845|Methods and tools...|\n",
      "|     910|Information Proce...|\n",
      "|     975|ACM Transactions ...|\n",
      "|    1040|Information Proce...|\n",
      "|    1105|ACM Transactions ...|\n",
      "|    1170|Proc. of the 2nd ...|\n",
      "|    1235|Proc. of the inte...|\n",
      "|    1300|Foundations of co...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|             ref_ids|\n",
      "+--------+--------------------+\n",
      "|      65|                    |\n",
      "|     130|                    |\n",
      "|     195|317424;317425;317573|\n",
      "|     260|                    |\n",
      "|     325|                    |\n",
      "|     390|                    |\n",
      "|     455|                    |\n",
      "|     520|       318368;323493|\n",
      "|     585|                    |\n",
      "|     650|                    |\n",
      "|     715|                    |\n",
      "|     780|318420;319233;319...|\n",
      "|     845|                    |\n",
      "|     910|                    |\n",
      "|     975|67604;318882;3718...|\n",
      "|    1040|                    |\n",
      "|    1105|289087;318014;318...|\n",
      "|    1170|                    |\n",
      "|    1235|                    |\n",
      "|    1300|                    |\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "convertDictsArrayIntoCSVFile(papers_d, \"./assets/papers.csv\")\n",
    "convertDictsArrayIntoCSVFile(affiliations_d, \"./assets/affiliations.csv\")\n",
    "convertDictsArrayIntoCSVFile(paper_authors_d, \"./assets/paper_authors.csv\")\n",
    "convertDictsArrayIntoCSVFile(publication_venues_d, \"./assets/publication_venues.csv\")\n",
    "convertDictsArrayIntoCSVFile(paper_refs_d, \"./assets/paper_refs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b4f2e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Authors\n",
    "authorTextLines = zipDatasetWithIndex(AUTHOR_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfd6a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "summedArrayOfAuthorIndexRows = doCumSumForIndexRows(authorTextLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a05b5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorItemTuples = convertDataIntoIndexedTuples(authorTextLines, summedArrayOfAuthorIndexRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffb1f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, '#index 1'), (1, '#n O. Willum'), (1, '#a Res. Center for Microperipherik, Technische Univ. Berlin, Germany'), (1, '#pc 1'), (1, '#cn 0'), (1, '#hi 0'), (1, '#pi 0.0000'), (1, '#upi 0.0000'), (1, '#t new product;product group;active product;long product lifetime;old product;product generation;new technology;environmental benefit;environmental choice;environmental consequence'), (1, '')]\n"
     ]
    }
   ],
   "source": [
    "print(authorItemTuples.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e0e5de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "[Stage 73:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1712433, {'authors_data': {'author_id': '1712433', 'name': 'Andrea Gantchev', 'paper_count': '2', 'citation_count': '3', 'h_index': '1'}, 'research_interests_data': {'author_id': '1712433', 'research_interests': 'subsumption architecture;Subsumption ArchitectureThe subsumption architecture;software architecture;subsumption architectureReusable Strategies;Object-oriented design;object-oriented software design;Rodney Brooks;Software Agents;behaviour-based control;different micro-strategies'}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "authorDictsArray = convertDataIntoDicts(authorItemTuples, AUTHOR_KEYS_MAP, reduceAuthorFeaturesToDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5da9d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'authors_data': {'author_id': '17', 'name': 'J. Michael Howe', 'paper_count': '1', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '17', 'research_interests': 'HIV disease;Internet resource;World-Wide Web;clinical management'}}, {'authors_data': {'author_id': '34', 'name': 'Haitham Gabr', 'paper_count': '2', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '34', 'research_interests': 'associate polynomial term;bivariate polynomial;difficult computational problem;novel polynomial;polynomial multiplication problem;polynomial term;reachability problem;Probabilistic Reachability;Reachability analysis;better time complexity'}}, {'authors_data': {'author_id': '51', 'name': 'Emma Tonkin', 'paper_count': '8', 'citation_count': '4', 'h_index': '1'}, 'research_interests_data': {'author_id': '51', 'research_interests': 'metadata element;metadata record;Dublin Core metadata;PaperBase extracts metadata;Semi automated metadata extraction;applicationAs metadata providers increase;automated metadata extraction tool;metadata correction process;metadata revision process;metadata revision processMetRe'}}, {'authors_data': {'author_id': '68', 'name': 'Woochul Shin', 'paper_count': '4', 'citation_count': '1', 'h_index': '1'}, 'research_interests_data': {'author_id': '68', 'research_interests': 'Web Service;context information;mobile device;Web Service standard;Web technology;Web service operation;location-based GIS Web Service;location-based secured GIS Web;secured GIS Web Service;heterogeneous mobile device'}}, {'authors_data': {'author_id': '85', 'name': 'S Improta', 'paper_count': '1', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '85', 'research_interests': 'intermediate key;key layering;key rotation;system key;encryption algorithm;encryption organization;authentication procedure;message authentication;message digit substitution;telesurveillance system'}}, {'authors_data': {'author_id': '102', 'name': 'Richard Ferri', 'paper_count': '5', 'citation_count': '8', 'h_index': '2'}, 'research_interests_data': {'author_id': '102', 'research_interests': 'feedback loop;different reuse measure;reuse growth factor;software reuse;reusable code repository;reusable library component;reusable software;software development process;Heterogenous Linux;LUI6Remote Linux explainedLearn'}}, {'authors_data': {'author_id': '119', 'name': 'Qing Liu', 'paper_count': '1', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '119', 'research_interests': 'Rough Set;nomal Counter Propagation Neural;CP Neural Network;Counter Propagation Neural Network;Rough Membership Function;Rough Set theory;edge detection;Image Edge;good result'}}, {'authors_data': {'author_id': '136', 'name': 'Artur Gramacki', 'paper_count': '2', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '136', 'research_interests': 'MATLAB toolbox;linear system;linear systemsDevelopment'}}, {'authors_data': {'author_id': '153', 'name': 'Olumuyiwa Oluwasanmi', 'paper_count': '2', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '153', 'research_interests': 'Byzantine agreement;algorithms work;random bit;reliable algorithm;Random Beacon;Byzantine agreement problem;scalable byzantine agreement;classical problem;important problem;serious problem'}}, {'authors_data': {'author_id': '170', 'name': 'Josef Willenborg', 'paper_count': '1', 'citation_count': '0', 'h_index': '0'}, 'research_interests_data': {'author_id': '170', 'research_interests': 'Ein objektorientiertes System zur;tzung der Thesauruspflege'}}]\n"
     ]
    }
   ],
   "source": [
    "print(authorDictsArray.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed74803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve research interests and authors data\n",
    "authors_d = authorDictsArray.map(lambda x: x[\"authors_data\"])\n",
    "research_interests_d = authorDictsArray.map(lambda x: x[\"research_interests_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc3f39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------------+-----------+\n",
      "|author_id|h_index|                name|paper_count|\n",
      "+---------+-------+--------------------+-----------+\n",
      "|       17|      0|     J. Michael Howe|          1|\n",
      "|       34|      0|        Haitham Gabr|          2|\n",
      "|       51|      1|         Emma Tonkin|          8|\n",
      "|       68|      1|        Woochul Shin|          4|\n",
      "|       85|      0|           S Improta|          1|\n",
      "|      102|      2|       Richard Ferri|          5|\n",
      "|      119|      0|            Qing Liu|          1|\n",
      "|      136|      0|      Artur Gramacki|          2|\n",
      "|      153|      0|Olumuyiwa Oluwasanmi|          2|\n",
      "|      170|      0|    Josef Willenborg|          1|\n",
      "|      187|      0|            Qing Wei|          1|\n",
      "|      204|      1|Jurey Ivanovich Z...|          1|\n",
      "|      221|      1|             Anny Ng|          1|\n",
      "|      238|      1|    Nikos B. Pronios|          3|\n",
      "|      255|      0| Lourdes Fraga Alman|          1|\n",
      "|      272|      1|       Junji Nishino|          7|\n",
      "|      289|      0|       L. Dascalescu|          2|\n",
      "|      306|      0|    Masakazu Nishino|          1|\n",
      "|      323|      1|    Jean-Rémi Duquet|          2|\n",
      "|      340|      1|     Brian A. Canada|          2|\n",
      "+---------+-------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|author_id|  research_interests|\n",
      "+---------+--------------------+\n",
      "|       17|HIV disease;Inter...|\n",
      "|       34|associate polynom...|\n",
      "|       51|metadata element;...|\n",
      "|       68|Web Service;conte...|\n",
      "|       85|intermediate key;...|\n",
      "|      102|feedback loop;dif...|\n",
      "|      119|Rough Set;nomal C...|\n",
      "|      136|MATLAB toolbox;li...|\n",
      "|      153|Byzantine agreeme...|\n",
      "|      170|Ein objektorienti...|\n",
      "|      187|portable device;A...|\n",
      "|      204|Integer-valued pr...|\n",
      "|      221|stock price;stock...|\n",
      "|      238|Hypermedia Synchr...|\n",
      "|      255|computer-mediated...|\n",
      "|      272|Dijkstra method;o...|\n",
      "|      289|low-frequency act...|\n",
      "|      306|copyright process...|\n",
      "|      323|uncertain informa...|\n",
      "|      340|histology image;s...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.2.0/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "convertDictsArrayIntoCSVFile(authors_d, \"./assets/authors_d8.csv\")\n",
    "convertDictsArrayIntoCSVFile(research_interests_d, \"./assets/research_interests_d8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bcccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# pTextLines = zipDatasetWithIndex(AUTHOR_2_PAPER_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156699b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.                                                       \n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(pTextLines.collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0571ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = pTextLines.split(' ') #.filter(lambda x: \"#index\" in x[0]).map(lambda x: x[1]).collect() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f21d021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"index\",IntegerType(),True) \\\n",
    "      .add(\"author_id\",IntegerType(),True) \\\n",
    "      .add(\"paper_id\",IntegerType(),True) \\\n",
    "      .add(\"author_position\",StringType(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22182237",
   "metadata": {},
   "outputs": [],
   "source": [
    "readFileA2P = spark.read.options(delimiter='\\t').csv(AUTHOR_2_PAPER_DATASET_PATH, header=False,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4704954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- author_position: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readFileA2P.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d49d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------+---------------+\n",
      "|index|author_id|paper_id|author_position|\n",
      "+-----+---------+--------+---------------+\n",
      "|    1|   381617|       1|              1|\n",
      "|    2|   630546|       3|              1|\n",
      "|    3|   112127|       4|              1|\n",
      "|    4|    96116|       4|              2|\n",
      "|    5|   578328|       5|              1|\n",
      "|    6|   865779|       5|              2|\n",
      "|    7|   669143|       5|              3|\n",
      "|    8|   533344|       6|              1|\n",
      "|    9|   621167|       7|              1|\n",
      "|   10|   522333|       7|              2|\n",
      "|   11|   597188|       7|              3|\n",
      "|   12|  1396373|       8|              1|\n",
      "|   13|  1644597|       8|              2|\n",
      "|   14|   798283|       8|              3|\n",
      "|   15|   371951|       9|              1|\n",
      "|   16|   378500|      10|              1|\n",
      "|   17|   117256|      11|              1|\n",
      "|   18|   562284|      12|              1|\n",
      "|   19|     1224|      13|              1|\n",
      "|   20|  1223056|      14|              1|\n",
      "+-----+---------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readFileA2P.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fe116cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/20 11:00:59 WARN TransportChannelHandler: Exception in connection from /192.168.0.101:62797\n",
      "java.io.IOException: Operation timed out\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "readFileA2P.coalesce(1).write.option(\"header\",True).option(\"delimiter\",\",\").csv(\"paper-author.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
